{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_2bar_melody_small_data.ipynb","provenance":[{"file_id":"https://github.com/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb","timestamp":1631852135633}],"collapsed_sections":["hYaJ6dvF0v7g","R122bwRNbTus","C_TD5psbv9Ax","lEJptw-V4CEJ","RTsrpipz4cFc","moLOftFqBS-0","wM6gOe6X3hWB","8YxEHHI937Oa","mDKI2rmOk0Dv","l47dxtR82s0t","_ss6V0582zpU","0d4st_BlUBdl","6PxW0_7Z2fvb","LGIZPuZc2dIa","jcFG5aiaeobS"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bhOAxQyU0rhs"},"source":["Copyright 2017 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"hYaJ6dvF0v7g"},"source":["# MusicVAE: A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music.\n","### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n","\n","[MusicVAE](https://g.co/magenta/music-vae) learns a latent space of musical scores, providing different modes\n","of interactive musical creation, including:\n","\n","* Random sampling from the prior distribution.\n","* Interpolation between existing sequences.\n","* Manipulation of existing sequences via attribute vectors.\n","\n","Examples of these interactions can be generated below, and selections can be heard in our\n","[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n","\n","For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n","and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n","decoder, which helps the model learn longer-term structures.\n","\n","We also model the interdependencies between instruments by training multiple\n","decoders on the lowest-level embeddings of the hierarchical decoder.\n","\n","For additional details, check out our [blog post](https://g.co/magenta/music-vae) and [paper](https://goo.gl/magenta/musicvae-paper).\n","___\n","\n","This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."]},{"cell_type":"markdown","metadata":{"id":"R122bwRNbTus"},"source":["# Basic Instructions\n","\n","1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n","2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n","3. Listen to the generated samples.\n","4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"]},{"cell_type":"markdown","metadata":{"id":"ZLfb2a_12wcj"},"source":["# Environment Setup\n","Includes package installation for sequence synthesis. Will take a few minutes.\n"]},{"cell_type":"code","metadata":{"id":"PfRDVhNs3UFx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635274443951,"user_tz":360,"elapsed":65327,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"ef0e2a39-f768-4a08-dd83-044d4b230869"},"source":["#@title Setup Environment\n","#@test {\"output\": \"ignore\"}\n","\n","import glob\n","\n","BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n","\n","print('Installing dependencies...')\n","!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","!pip install -q pyfluidsynth\n","!pip install -qU magenta\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","# This is only needed for the hosted Colab environment.\n","import ctypes.util\n","orig_ctypes_util_find_library = ctypes.util.find_library\n","def proxy_find_library(lib):\n","  if lib == 'fluidsynth':\n","    return 'libfluidsynth.so.1'\n","  else:\n","    return orig_ctypes_util_find_library(lib)\n","ctypes.util.find_library = proxy_find_library\n","\n","\n","print('Importing libraries and defining some helper functions...')\n","from google.colab import files\n","import magenta.music as mm\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel\n","import numpy as np\n","import os\n","import tensorflow.compat.v1 as tf\n","\n","tf.disable_v2_behavior()\n","# tf.enable_eager_execution()\n","\n","# Necessary until pyfluidsynth is updated (>1.2.5).\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","def play(note_sequence):\n","  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n","\n","def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","                assert_same_length=True, temperature=0.5,\n","                individual_duration=4.0):\n","  \"\"\"Interpolates between a start and end sequence.\"\"\"\n","  note_sequences = model.interpolate(\n","      start_seq, end_seq,num_steps=num_steps, length=max_length,\n","      temperature=temperature,\n","      assert_same_length=assert_same_length)\n","\n","  print('Start Seq Reconstruction')\n","  play(note_sequences[0])\n","  print('End Seq Reconstruction')\n","  play(note_sequences[-1])\n","  print('Mean Sequence')\n","  play(note_sequences[num_steps // 2])\n","  print('Start -> End Interpolation')\n","  interp_seq = mm.sequences_lib.concatenate_sequences(\n","      note_sequences, [individual_duration] * len(note_sequences))\n","  play(interp_seq)\n","  mm.plot_sequence(interp_seq)\n","  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n","\n","def download(note_sequence, filename):\n","  mm.sequence_proto_to_midi_file(note_sequence, filename)\n","  files.download(filename)\n","\n","print('Done')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing dependencies...\n","Selecting previously unselected package fluid-soundfont-gm.\n","(Reading database ... 155047 files and directories currently installed.)\n","Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n","Unpacking fluid-soundfont-gm (3.1-5.1) ...\n","Selecting previously unselected package libfluidsynth1:amd64.\n","Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n","Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n","Setting up fluid-soundfont-gm (3.1-5.1) ...\n","Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","\u001b[K     |████████████████████████████████| 1.4 MB 9.8 MB/s \n","\u001b[K     |████████████████████████████████| 254 kB 64.4 MB/s \n","\u001b[K     |████████████████████████████████| 87 kB 9.2 MB/s \n","\u001b[K     |████████████████████████████████| 69 kB 10.4 MB/s \n","\u001b[K     |████████████████████████████████| 210 kB 75.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 53.1 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 67.0 MB/s \n","\u001b[K     |████████████████████████████████| 204 kB 73.3 MB/s \n","\u001b[K     |████████████████████████████████| 2.3 MB 34.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 72.8 MB/s \n","\u001b[K     |████████████████████████████████| 5.6 MB 15.5 MB/s \n","\u001b[K     |████████████████████████████████| 3.6 MB 50.0 MB/s \n","\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 367 kB 60.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 58.7 MB/s \n","\u001b[K     |████████████████████████████████| 981 kB 67.1 MB/s \n","\u001b[K     |████████████████████████████████| 366 kB 58.4 MB/s \n","\u001b[K     |████████████████████████████████| 48 kB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 79 kB 10.1 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 57.5 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 68.3 MB/s \n","\u001b[K     |████████████████████████████████| 251 kB 71.5 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 63.6 MB/s \n","\u001b[K     |████████████████████████████████| 178 kB 70.3 MB/s \n","\u001b[?25h  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Importing libraries and defining some helper functions...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Done\n"]}]},{"cell_type":"markdown","metadata":{"id":"C_TD5psbv9Ax"},"source":["# 2-Bar Drums Model\n","\n","Below are 4 pre-trained models to experiment with. The first 3 map the 61 MIDI drum \"pitches\" to a reduced set of 9 classes (bass, snare, closed hi-hat, open hi-hat, low tom, mid tom, high tom, crash cymbal, ride cymbal) for a simplified but less expressive output space. The last model uses a [NADE](http://homepages.inf.ed.ac.uk/imurray2/pub/11nade/) to represent all possible MIDI drum \"pitches\".\n","\n","* **drums_2bar_oh_lokl**: This *low* KL model was trained for more *realistic* sampling. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 0 free bits, and had a fixed beta value of 0.8. After 300k steps, the final accuracy is 0.73 and KL divergence is 11 bits.\n","* **drums_2bar_oh_hikl**: This *high* KL model was trained for *better reconstruction and interpolation*. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 96 free bits and had a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k, steps the final accuracy is 0.97 and KL divergence is 107 bits.\n","* **drums_2bar_nade_reduced**: This model outputs a multi-label \"pianoroll\" with 9 classes. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 9-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 96 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.98 and KL divergence is 110 bits.\n","* **drums_2bar_nade_full**:  The output is a multi-label \"pianoroll\" with 61 classes. A single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 61-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 0 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.90 and KL divergence is 116 bits."]},{"cell_type":"code","metadata":{"id":"0x8YTRDwv8Gk","cellView":"form"},"source":["#@title Load Pretrained Models\n","\n","drums_models = {}\n","# One-hot encoded.\n","drums_config = configs.CONFIG_MAP['cat-drums_2bar_small']\n","drums_models['drums_2bar_oh_lokl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_small.lokl.ckpt')\n","drums_models['drums_2bar_oh_hikl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_small.hikl.ckpt')\n","\n","# Multi-label NADE.\n","drums_nade_reduced_config = configs.CONFIG_MAP['nade-drums_2bar_reduced']\n","drums_models['drums_2bar_nade_reduced'] = TrainedModel(drums_nade_reduced_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_nade.reduced.ckpt')\n","drums_nade_full_config = configs.CONFIG_MAP['nade-drums_2bar_full']\n","drums_models['drums_2bar_nade_full'] = TrainedModel(drums_nade_full_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_nade.full.ckpt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEJptw-V4CEJ"},"source":["## Generate Samples"]},{"cell_type":"code","metadata":{"id":"zRUlAshMpDnR","cellView":"form"},"source":["#@title Generate 4 samples from the prior of one of the models listed above.\n","drums_sample_model = \"drums_2bar_oh_lokl\" #@param [\"drums_2bar_oh_lokl\", \"drums_2bar_oh_hikl\", \"drums_2bar_nade_reduced\", \"drums_2bar_nade_full\"]\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","drums_samples = drums_models[drums_sample_model].sample(n=4, length=32, temperature=temperature)\n","for ns in drums_samples:\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSwhxkru5mB6","cellView":"form"},"source":["#@title Optionally download generated MIDI samples.\n","for i, ns in enumerate(drums_samples):\n","  download(ns, '%s_sample_%d.mid' % (drums_sample_model, i))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTsrpipz4cFc"},"source":["## Generate Interpolations"]},{"cell_type":"code","metadata":{"id":"7cnZfjdGwwZg","cellView":"form"},"source":["#@title Option 1: Use example MIDI files for interpolation endpoints.\n","input_drums_midi_data = [\n","    tf.io.gfile.GFile(fn, mode='rb').read()\n","    for fn in sorted(tf.io.gfile.glob(BASE_DIR + '/midi/drums_2bar*.mid'))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjfyjWPtb8fV","cellView":"form"},"source":["#@title Option 2: upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_drums_midi_data = files.upload().values() or input_drums_midi_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqCJFtHYb-7A","cellView":"form"},"source":["#@title Extract drums from MIDI files. This will extract all unique 2-bar drum beats using a sliding window with a stride of 1 bar.\n","drums_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_drums_midi_data]\n","extracted_beats = []\n","for ns in drums_input_seqs:\n","  extracted_beats.extend(drums_nade_full_config.data_converter.from_tensors(\n","      drums_nade_full_config.data_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_beats):\n","  print(\"Beat\", i)\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MeAboOS1xDgE","cellView":"form"},"source":["#@title Interpolate between 2 beats, selected from those in the previous cell.\n","drums_interp_model = \"drums_2bar_oh_hikl\" #@param [\"drums_2bar_oh_lokl\", \"drums_2bar_oh_hikl\", \"drums_2bar_nade_reduced\", \"drums_2bar_nade_full\"]\n","start_beat = 0 #@param {type:\"integer\"}\n","end_beat = 1 #@param {type:\"integer\"}\n","start_beat = extracted_beats[start_beat]\n","end_beat = extracted_beats[end_beat]\n","\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","num_steps = 13 #@param {type:\"integer\"}\n","\n","drums_interp = interpolate(drums_models[drums_interp_model], start_beat, end_beat, num_steps=num_steps, temperature=temperature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nkKoQwFEcxpi","cellView":"form"},"source":["#@title Optionally download interpolation MIDI file.\n","download(drums_interp, '%s_interp.mid' % drums_interp_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"moLOftFqBS-0"},"source":["# 2-Bar Melody Model\n","\n","The pre-trained model consists of a single-layer bidirectional LSTM encoder with 2048 nodes in each direction, a 3-layer LSTM decoder with 2048 nodes in each layer, and Z with 512 dimensions. The model was given 0 free bits, and had its beta valued annealed at an exponential rate of 0.99999 from 0 to 0.43 over 200k steps. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. The final accuracy is 0.95 and KL divergence is 58 bits."]},{"cell_type":"code","metadata":{"id":"2XCPjwd6BVtm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634231003699,"user_tz":360,"elapsed":13467,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"78997b4d-6960-4c72-97c7-3ce37caa3f35"},"source":["#@title Load the pre-trained model.\n","mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n","mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n"]}]},{"cell_type":"markdown","metadata":{"id":"wM6gOe6X3hWB"},"source":["## Generate Samples"]},{"cell_type":"code","metadata":{"id":"RwXUA74cNkh0","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"ok","timestamp":1634231011208,"user_tz":360,"elapsed":7520,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"889e2a26-476a-4bf4-fe07-061a5595aa20"},"source":["#@title Generate 4 samples from the prior.\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","mel_2_samples = mel_2bar.sample(n=4, length=32, temperature=temperature)\n","for ns in mel_2_samples:\n","  play(ns)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div id=\"id_1\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_2\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_3\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_4\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ysPpEgdwm_D","executionInfo":{"status":"ok","timestamp":1634231138037,"user_tz":360,"elapsed":300,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"61dbfc8b-bfcf-4d7d-87df-8795f941f386"},"source":["type(mel_2_samples)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPeTMWzhxExr","executionInfo":{"status":"ok","timestamp":1634231177585,"user_tz":360,"elapsed":385,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"aa4b7294-b215-4dd9-966d-26ef85512678"},"source":["type(mel_2_samples[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["note_seq.protobuf.music_pb2.NoteSequence"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"MLg9dQ2D1Xpu","cellView":"form"},"source":["#@title Optionally download samples.\n","for i, ns in enumerate(mel_2_samples):\n","  download(ns, 'mel_2bar_sample_%d.mid' % i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8YxEHHI937Oa"},"source":["## Generate Interpolations"]},{"cell_type":"code","metadata":{"id":"H5wCWLMPLfYz","cellView":"form"},"source":["#@title Option 1: Use example MIDI files for interpolation endpoints.\n","input_mel_midi_data = [\n","    tf.io.gfile.GFile(fn, 'rb').read()\n","    for fn in sorted(tf.io.gfile.glob(BASE_DIR + '/midi/mel_2bar*.mid'))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hu5SeYFnNEe5","cellView":"form"},"source":["#@title Option 2: Upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_mel_midi_data = files.upload().values() or input_mel_midi_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xy4vizNUH8GJ","cellView":"form"},"source":["#@title Extract melodies from MIDI files. This will extract all unique 2-bar melodies using a sliding window with a stride of 1 bar.\n","mel_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_mel_midi_data]\n","extracted_mels = []\n","for ns in mel_input_seqs:\n","  extracted_mels.extend(\n","      mel_2bar_config.data_converter.from_tensors(\n","          mel_2bar_config.data_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_mels):\n","  print(\"Melody\", i)\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8J4vloU3Pgtz","cellView":"form"},"source":["#@title Interpolate between 2 melodies, selected from those in the previous cell.\n","start_melody = 0 #@param {type:\"integer\"}\n","end_melody = 1 #@param {type:\"integer\"}\n","start_mel = extracted_mels[start_melody]\n","end_mel = extracted_mels[end_melody]\n","\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","num_steps = 13 #@param {type:\"integer\"}\n","\n","mel_2bar_interp = interpolate(mel_2bar, start_mel, end_mel, num_steps=num_steps, temperature=temperature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZVP4JRmTCvB","cellView":"form"},"source":["#@title Optionally download interpolation MIDI file.\n","download(mel_2bar_interp, 'mel_2bar_interp.mid')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mDKI2rmOk0Dv"},"source":["# 16-bar Melody Models\n","\n","The pre-trained hierarchical model consists of a 2-layer stacked bidirectional LSTM encoder with 2048 nodes in each direction for each layer, a 16-step 2-layer LSTM \"conductor\" decoder with 1024 nodes in each layer, a 2-layer LSTM core decoder with 1024 nodes in each layer, and a Z with 512 dimensions. It was given 256 free bits, and had a fixed beta value of 0.2. After 25k steps, the final accuracy is 0.90 and KL divergence is 277 bits."]},{"cell_type":"code","metadata":{"id":"9zcfdVjjk3Pp","cellView":"form"},"source":["#@title Load the pre-trained models.\n","mel_16bar_models = {}\n","hierdec_mel_16bar_config = configs.CONFIG_MAP['hierdec-mel_16bar']\n","mel_16bar_models['hierdec_mel_16bar'] = TrainedModel(hierdec_mel_16bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_16bar_hierdec.ckpt')\n","\n","flat_mel_16bar_config = configs.CONFIG_MAP['flat-mel_16bar']\n","mel_16bar_models['baseline_flat_mel_16bar'] = TrainedModel(flat_mel_16bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_16bar_flat.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l47dxtR82s0t"},"source":["## Generate Samples"]},{"cell_type":"code","metadata":{"id":"Bptfh7C1njpV","cellView":"form"},"source":["#@title Generate 4 samples from the selected model prior.\n","mel_sample_model = \"hierdec_mel_16bar\" #@param [\"hierdec_mel_16bar\", \"baseline_flat_mel_16bar\"]\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","mel_16_samples = mel_16bar_models[mel_sample_model].sample(n=4, length=256, temperature=temperature)\n","for ns in mel_16_samples:\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4sDzwq623Ei","cellView":"form"},"source":["#@title Optionally download MIDI samples.\n","for i, ns in enumerate(mel_16_samples):\n","  download(ns, '%s_sample_%d.mid' % (mel_sample_model, i))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ss6V0582zpU"},"source":["## Generate Means"]},{"cell_type":"code","metadata":{"id":"38nwpNp_lprY","cellView":"form"},"source":["#@title Option 1: Use example MIDI files for interpolation endpoints.\n","input_mel_16_midi_data = [\n","    tf.io.gfile.GFile(fn, 'rb').read()\n","    for fn in sorted(tf.io.gfile.glob(BASE_DIR + '/midi/mel_16bar*.mid'))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-7VjVcPUpHN","cellView":"form"},"source":["#@title Option 2: upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_mel_16_midi_data = files.upload().values() or input_mel_16_midi_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-WE4Nq2OJxH","cellView":"form"},"source":["#@title Extract melodies from MIDI files. This will extract all unique 16-bar melodies using a sliding window with a stride of 1 bar.\n","mel_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_mel_16_midi_data]\n","extracted_16_mels = []\n","for ns in mel_input_seqs:\n","  extracted_16_mels.extend(\n","      hierdec_mel_16bar_config.data_converter.from_tensors(\n","          hierdec_mel_16bar_config.data_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_16_mels):\n","  print(\"Melody\", i)\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_Xp1rpTrayv","cellView":"form"},"source":["#@title Compute the reconstructions and mean of the two melodies, selected from the previous cell.\n","mel_interp_model = \"hierdec_mel_16bar\" #@param [\"hierdec_mel_16bar\", \"baseline_flat_mel_16bar\"]\n","\n","start_melody = 0 #@param {type:\"integer\"}\n","end_melody = 1 #@param {type:\"integer\"}\n","start_mel = extracted_16_mels[start_melody]\n","end_mel = extracted_16_mels[end_melody]\n","\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","\n","mel_16bar_mean = interpolate(mel_16bar_models[mel_interp_model], start_mel, end_mel, num_steps=3, max_length=256, individual_duration=32, temperature=temperature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rONYqtlLkyS2","cellView":"form"},"source":["#@title Optionally download mean MIDI file.\n","download(mel_16bar_mean, '%s_mean.mid' % mel_interp_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0d4st_BlUBdl"},"source":["#16-bar \"Trio\" Models (lead, bass, drums)\n","\n","We present two pre-trained models for 16-bar trios: a hierarchical model and a flat (baseline) model.\n","\n","The pre-trained hierarchical model consists of a 2-layer stacked bidirectional LSTM encoder with 2048 nodes in each direction for each layer, a 16-step 2-layer LSTM \"conductor\" decoder with 1024 nodes in each layer, 3 (lead, bass, drums) 2-layer LSTM core decoders with 1024 nodes in each layer, and a Z with 512 dimensions. It was given 1024 free bits, and had a fixed beta value of 0.1.  It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 50k steps, the final accuracy is 0.82 for lead, 0.87 for bass, and 0.90 for drums, and the KL divergence is 1027 bits.\n","\n","The pre-trained flat model consists of a 2-layer stacked bidirectional LSTM encoder with 2048 nodes in each direction for each layer, a 3-layer LSTM decoder with 2048 nodes in each layer, and a Z with 512 dimensions. It was given 1024 free bits, and had a fixed beta value of 0.1.  It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 50k steps, the final accuracy is 0.67 for lead, 0.66 for bass, and 0.79 for drums, and the KL divergence is 1016 bits."]},{"cell_type":"code","metadata":{"id":"FDW3h0cqUERq","cellView":"form"},"source":["#@title Load the pre-trained models.\n","trio_models = {}\n","hierdec_trio_16bar_config = configs.CONFIG_MAP['hierdec-trio_16bar']\n","trio_models['hierdec_trio_16bar'] = TrainedModel(hierdec_trio_16bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/trio_16bar_hierdec.ckpt')\n","\n","flat_trio_16bar_config = configs.CONFIG_MAP['flat-trio_16bar']\n","trio_models['baseline_flat_trio_16bar'] = TrainedModel(flat_trio_16bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/trio_16bar_flat.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6PxW0_7Z2fvb"},"source":["## Generate Samples"]},{"cell_type":"code","metadata":{"id":"XKk8rGihUR6B"},"source":["#@title Generate 4 samples from the selected model prior.\n","trio_sample_model = \"hierdec_trio_16bar\" #@param [\"hierdec_trio_16bar\", \"baseline_flat_trio_16bar\"]\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","\n","trio_16_samples = trio_models[trio_sample_model].sample(n=4, length=256, temperature=temperature)\n","for ns in trio_16_samples:\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fic5W7Z7m7Op","cellView":"form"},"source":["#@title Optionally download MIDI samples.\n","for i, ns in enumerate(trio_16_samples):\n","  download(ns, '%s_sample_%d.mid' % (trio_sample_model, i))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LGIZPuZc2dIa"},"source":["## Generate Means"]},{"cell_type":"code","metadata":{"id":"3msZzI89UU_F","cellView":"form"},"source":["#@title Option 1: Use example MIDI files for interpolation endpoints.\n","input_trio_midi_data = [\n","    tf.io.gfile.GFile(fn, 'rb').read()\n","    for fn in sorted(tf.io.gfile.glob(BASE_DIR + '/midi/trio_16bar*.mid'))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ig0w2cSUs9n","cellView":"form"},"source":["#@title Option 2: Upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_trio_midi_data = files.upload().values() or input_trio_midi_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mawDY278UZKY","cellView":"form"},"source":["#@title Extract trios from MIDI files. This will extract all unique 16-bar trios using a sliding window with a stride of 1 bar.\n","trio_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_trio_midi_data]\n","extracted_trios = []\n","for ns in trio_input_seqs:\n","  extracted_trios.extend(\n","      hierdec_trio_16bar_config.data_converter.from_tensors(\n","          hierdec_trio_16bar_config.data_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_trios):\n","  print(\"Trio\", i)\n","  play(ns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQuTQOlZW1LX","cellView":"form"},"source":["#@title Compute the reconstructions and mean of the two trios, selected from the previous cell.\n","trio_interp_model = \"hierdec_trio_16bar\" #@param [\"hierdec_trio_16bar\", \"baseline_flat_trio_16bar\"]\n","\n","start_trio = 0 #@param {type:\"integer\"}\n","end_trio = 1 #@param {type:\"integer\"}\n","start_trio = extracted_trios[start_trio]\n","end_trio = extracted_trios[end_trio]\n","\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","trio_16bar_mean = interpolate(trio_models[trio_interp_model], start_trio, end_trio, num_steps=3, max_length=256, individual_duration=32, temperature=temperature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqSklK8CU_cQ","cellView":"form"},"source":["#@title Optionally download mean MIDI file.\n","download(trio_16bar_mean, '%s_mean.mid' % trio_interp_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-DayVCbB6lR3"},"source":["# Setup\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxTwZMnQy6PI","executionInfo":{"status":"ok","timestamp":1635274495775,"user_tz":360,"elapsed":51610,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"02ef2c1e-aca8-4294-a09e-d38e8f801b30"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmBQBrs3zCQ1","executionInfo":{"status":"ok","timestamp":1635274496844,"user_tz":360,"elapsed":1075,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"619d6d13-1c9a-4957-9171-a9de5d5105f8"},"source":["%cd /content/drive/MyDrive/Thesis/Code/Magenta/magenta/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta\n"]}]},{"cell_type":"code","metadata":{"id":"09ohU4wczID4"},"source":["import datetime\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grPE9aioHiFq"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"ehndNVfZ_jp3"},"source":["## First"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRxIJClzzJAg","executionInfo":{"status":"ok","timestamp":1635262902857,"user_tz":360,"elapsed":1137084,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"9cb965ef-108a-4612-a205-489845465f78"},"source":["!python magenta/models/music_vae/music_vae_train_modified.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/train-10-16-02-plain/ \\\n","--mode=train \\\n","--examples_path=./data/tfrecord/Bo_Burnham_train.tfrecord "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","2021-10-26 15:22:51.512505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:51.558162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:51.558886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","These are the arguments====================================\n","./data/tmp/train-10-16-01-plain/train Config(model=<magenta.models.music_vae.base_model.MusicVAE object at 0x7fe3bed70810>, hparams=HParams([('batch_size', 512), ('beta_rate', 0.99999), ('clip_mode', 'global_norm'), ('conditional', True), ('control_preprocessing_rnn_size', [256]), ('dec_rnn_size', [2048, 2048, 2048]), ('decay_rate', 0.9999), ('dropout_keep_prob', 1.0), ('enc_rnn_size', [2048]), ('free_bits', 0), ('grad_clip', 1.0), ('grad_norm_clip_to_zero', 10000), ('learning_rate', 0.001), ('max_beta', 0.5), ('max_seq_len', 32), ('min_learning_rate', 1e-05), ('residual_decoder', False), ('residual_encoder', False), ('sampling_rate', 1000), ('sampling_schedule', 'inverse_sigmoid'), ('use_cudnn', False), ('z_size', 512)]), note_sequence_augmenter=<magenta.models.music_vae.data.NoteSequenceAugmenter object at 0x7fe3becf76d0>, data_converter=<magenta.models.music_vae.data.OneHotMelodyConverter object at 0x7fe3bc037ed0>, train_examples_path='./data/tfrecord/Bo_Burnham_train.tfrecord', eval_examples_path=None, tfds_name=None) <function run.<locals>.dataset_fn at 0x7fe3bbfdd170> 10 1 500  0 0 0\n","These are the arguments====================================\n","2021-10-26 15:22:51.565492: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-10-26 15:22:51.565746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:51.566394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:51.566996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:52.065713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:52.066500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:52.067130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:22:52.067681: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-10-26 15:22:52.067740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 512, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","I1026 15:22:52.085926 140618375616384 base_model.py:152] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 512, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I1026 15:22:52.091814 140618375616384 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 15:22:52.105467 140618375616384 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 15:22:52.114286 140618375616384 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I1026 15:22:52.114655 140618375616384 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1026 15:22:52.114848 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 15:22:52.141596 140618375616384 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_train.tfrecord\n","I1026 15:22:52.142030 140618375616384 data.py:1812] Reading examples from file: ./data/tfrecord/Bo_Burnham_train.tfrecord\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W1026 15:22:52.349357 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W1026 15:22:52.349739 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W1026 15:22:52.716995 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1026 15:22:53.073489 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperNextInputs/cond/GatherNd_1/Switch_grad/cond_grad/Merge_1:0\", shape=(?,), dtype=int32), values=Tensor(\"gradients/decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperNextInputs/cond/GatherNd_1/Switch_grad/cond_grad/Merge:0\", shape=(?, 602), dtype=float32), dense_shape=Tensor(\"gradients/decoder/while/BasicDecoderStep/ScheduledOutputTrainingHelperNextInputs/cond/GatherNd_1/Switch_grad/cond_grad/Merge_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I1026 15:22:59.477466 140618375616384 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W1026 15:23:00.589397 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Graph was finalized.\n","I1026 15:23:00.675135 140618375616384 monitored_session.py:247] Graph was finalized.\n","2021-10-26 15:23:00.675869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:00.677026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:00.677971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:00.678849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:00.679458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:00.679990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Running local_init_op.\n","I1026 15:23:02.047401 140618375616384 session_manager.py:531] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1026 15:23:02.117109 140618375616384 session_manager.py:534] Done running local_init_op.\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n","I1026 15:23:06.845170 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 0...\n","INFO:tensorflow:Saving checkpoints for 0 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:23:06.845664 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 0 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n","I1026 15:23:14.657024 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 0...\n","2021-10-26 15:23:19.201871: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-10-26 15:23:19.219713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:19.220334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:19.220827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:19.221387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:19.221967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 15:23:19.222459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:global_step = 0, loss = 144.05264\n","I1026 15:23:22.340544 140618375616384 basic_session_run_hooks.py:262] global_step = 0, loss = 144.05264\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 26...\n","I1026 15:24:15.497994 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 26...\n","INFO:tensorflow:Saving checkpoints for 26 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:24:15.498274 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 26 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 26...\n","I1026 15:24:23.447066 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 26...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 54...\n","I1026 15:25:16.483325 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 54...\n","INFO:tensorflow:Saving checkpoints for 54 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:25:16.483587 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 54 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 54...\n","I1026 15:25:24.035315 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 54...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 82...\n","I1026 15:26:17.082746 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 82...\n","INFO:tensorflow:Saving checkpoints for 82 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:26:17.083004 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 82 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 82...\n","I1026 15:26:24.227622 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 82...\n","INFO:tensorflow:global_step/sec: 0.458937\n","I1026 15:27:00.234647 140618375616384 basic_session_run_hooks.py:702] global_step/sec: 0.458937\n","INFO:tensorflow:global_step = 100, loss = 47.5498 (217.895 sec)\n","I1026 15:27:00.235847 140618375616384 basic_session_run_hooks.py:260] global_step = 100, loss = 47.5498 (217.895 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 110...\n","I1026 15:27:17.250056 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 110...\n","INFO:tensorflow:Saving checkpoints for 110 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:27:17.250411 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 110 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 110...\n","I1026 15:27:25.017374 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 110...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 138...\n","I1026 15:28:18.148108 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 138...\n","INFO:tensorflow:Saving checkpoints for 138 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:28:18.148374 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 138 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 138...\n","I1026 15:28:25.413100 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 138...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 166...\n","I1026 15:29:18.528712 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 166...\n","INFO:tensorflow:Saving checkpoints for 166 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:29:18.528982 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 166 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 166...\n","I1026 15:29:25.850552 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 166...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 194...\n","I1026 15:30:18.867712 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 194...\n","INFO:tensorflow:Saving checkpoints for 194 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:30:18.867968 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 194 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 194...\n","I1026 15:30:26.731847 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 194...\n","INFO:tensorflow:global_step/sec: 0.455036\n","I1026 15:30:39.997624 140618375616384 basic_session_run_hooks.py:702] global_step/sec: 0.455036\n","INFO:tensorflow:global_step = 200, loss = 40.711597 (219.763 sec)\n","I1026 15:30:39.998818 140618375616384 basic_session_run_hooks.py:260] global_step = 200, loss = 40.711597 (219.763 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 222...\n","I1026 15:31:19.789745 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 222...\n","INFO:tensorflow:Saving checkpoints for 222 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:31:19.790005 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 222 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 222...\n","I1026 15:31:26.796386 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 222...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 250...\n","I1026 15:32:19.896516 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 250...\n","INFO:tensorflow:Saving checkpoints for 250 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:32:19.896761 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 250 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 250...\n","I1026 15:32:26.949158 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 250...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 278...\n","I1026 15:33:20.067337 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 278...\n","INFO:tensorflow:Saving checkpoints for 278 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:33:20.067595 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 278 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W1026 15:33:26.630954 140618375616384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 278...\n","I1026 15:33:27.459253 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 278...\n","INFO:tensorflow:global_step/sec: 0.473435\n","I1026 15:34:11.219924 140618375616384 basic_session_run_hooks.py:702] global_step/sec: 0.473435\n","INFO:tensorflow:global_step = 300, loss = 42.16874 (211.222 sec)\n","I1026 15:34:11.221027 140618375616384 basic_session_run_hooks.py:260] global_step = 300, loss = 42.16874 (211.222 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 306...\n","I1026 15:34:20.680954 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 306...\n","INFO:tensorflow:Saving checkpoints for 306 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:34:20.681179 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 306 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 306...\n","I1026 15:34:28.359726 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 306...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 334...\n","I1026 15:35:21.528079 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 334...\n","INFO:tensorflow:Saving checkpoints for 334 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:35:21.528356 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 334 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 334...\n","I1026 15:35:29.487959 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 334...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 362...\n","I1026 15:36:22.622788 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 362...\n","INFO:tensorflow:Saving checkpoints for 362 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:36:22.623035 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 362 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 362...\n","I1026 15:36:29.888258 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 362...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 390...\n","I1026 15:37:23.077973 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 390...\n","INFO:tensorflow:Saving checkpoints for 390 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:37:23.078227 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 390 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 390...\n","I1026 15:37:31.053920 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 390...\n","INFO:tensorflow:global_step/sec: 0.45293\n","I1026 15:37:52.004764 140618375616384 basic_session_run_hooks.py:702] global_step/sec: 0.45293\n","INFO:tensorflow:global_step = 400, loss = 24.135006 (220.785 sec)\n","I1026 15:37:52.006038 140618375616384 basic_session_run_hooks.py:260] global_step = 400, loss = 24.135006 (220.785 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 418...\n","I1026 15:38:24.298859 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 418...\n","INFO:tensorflow:Saving checkpoints for 418 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:38:24.299100 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 418 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 418...\n","I1026 15:38:31.743823 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 418...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 446...\n","I1026 15:39:24.889575 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 446...\n","INFO:tensorflow:Saving checkpoints for 446 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:39:24.889828 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 446 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 446...\n","I1026 15:39:32.372423 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 446...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 474...\n","I1026 15:40:25.588886 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 474...\n","INFO:tensorflow:Saving checkpoints for 474 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:40:25.589130 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 474 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 474...\n","I1026 15:40:33.134368 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 474...\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n","I1026 15:41:22.583391 140618375616384 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 500...\n","INFO:tensorflow:Saving checkpoints for 500 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","I1026 15:41:22.583636 140618375616384 basic_session_run_hooks.py:618] Saving checkpoints for 500 into ./data/tmp/train-10-16-01-plain/train/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n","I1026 15:41:29.592572 140618375616384 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 500...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"id":"gkQRWAI-4toQ","executionInfo":{"status":"ok","timestamp":1635274671828,"user_tz":360,"elapsed":3761,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"eaab1484-4dcd-44e5-a941-f1829fb477e5"},"source":["%tensorboard --logdir ./data/tmp/train-10-16-01-plain/train/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_01iDaATlB7","executionInfo":{"status":"ok","timestamp":1634089584278,"user_tz":360,"elapsed":22969,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"c66237d4-a670-4dae-9694-be5d57e8bec1"},"source":["!tar -cvf ./data/checkpoints/train-9-24-03-plain.ckpt ./data/tmp/train-9-24-03-plain/train/model.ckpt-2000.*"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./data/tmp/train-9-24-03-plain/train/model.ckpt-2000.data-00000-of-00001\n","./data/tmp/train-9-24-03-plain/train/model.ckpt-2000.index\n","./data/tmp/train-9-24-03-plain/train/model.ckpt-2000.meta\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ITZ6g6YUDy_","executionInfo":{"status":"ok","timestamp":1634089601587,"user_tz":360,"elapsed":11071,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"87e926d1-17eb-44c4-902f-6b80f23d77ab"},"source":["mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n","mel_2bar_1 = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path = './data/checkpoints/train-9-24-03-plain.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Unbundling checkpoint.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpzq8iilly/./data/tmp/train-9-24-03-plain/train/model.ckpt-2000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"sIdWg3C2UUWb","executionInfo":{"status":"ok","timestamp":1634089703356,"user_tz":360,"elapsed":10526,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"beee963d-f37f-4f47-d121-3ed71ca54c3a"},"source":["temperature = 1.2 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","mel_2_samples = mel_2bar_1.sample(n=4, length=64, temperature=temperature)\n","for ns in mel_2_samples:\n","  play(ns)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div id=\"id_1\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_2\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_3\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_4\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"g_L5LxWpHmv1"},"source":["# Eval\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0yFtE3VaWQ0","executionInfo":{"status":"ok","timestamp":1635274619420,"user_tz":360,"elapsed":26039,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"8d472a57-1ac2-4acd-9dc1-007819791f6d"},"source":["!python magenta/models/music_vae/music_vae_train_modified.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/train-10-16-01-plain/ \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Bo_Burnham_eval.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=15 \\\n","--cache_dataset=False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","2021-10-26 18:56:37.805719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:37.977572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:37.978261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","INFO:tensorflow:Counting examples in ./data/tfrecord/Bo_Burnham_eval.tfrecord.\n","I1026 18:56:38.252236 140518046128000 data.py:1682] Counting examples in ./data/tfrecord/Bo_Burnham_eval.tfrecord.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","W1026 18:56:38.252823 140518046128000 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","INFO:tensorflow:Total examples: 15\n","I1026 18:56:38.641419 140518046128000 data.py:1700] Total examples: 15\n","=======================================\n","Batch size =  15\n","num_batches =  1\n","=======================================\n","2021-10-26 18:56:39.245969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:39.246698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:39.247296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:42.079184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:42.079971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:42.080593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:42.081192: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-10-26 18:56:42.081244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 15, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","I1026 18:56:42.142951 140518046128000 base_model.py:152] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 15, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I1026 18:56:42.147018 140518046128000 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 18:56:42.157754 140518046128000 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 18:56:42.166739 140518046128000 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I1026 18:56:42.167092 140518046128000 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","W1026 18:56:42.167209 140518046128000 lstm_utils.py:139] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1026 18:56:42.167344 140518046128000 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 18:56:42.190998 140518046128000 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n","I1026 18:56:42.191385 140518046128000 data.py:1812] Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n","DEBUG:tensorflow:next element\n","I1026 18:56:42.311163 140518046128000 music_vae_train_modified.py:117] next element\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W1026 18:56:42.321578 140518046128000 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W1026 18:56:42.321861 140518046128000 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W1026 18:56:42.677832 140518046128000 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1026 18:56:43.052232 140518046128000 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","INFO:tensorflow:Starting evaluation at 2021-10-26T18:56:43\n","I1026 18:56:43.241567 140518046128000 evaluation.py:255] Starting evaluation at 2021-10-26T18:56:43\n","INFO:tensorflow:Graph was finalized.\n","I1026 18:56:43.320939 140518046128000 monitored_session.py:247] Graph was finalized.\n","2021-10-26 18:56:43.321528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:43.322225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:43.322816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:43.323435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:43.324014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:43.324570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Restoring parameters from ./data/tmp/train-10-16-01-plain/train/model.ckpt-500\n","I1026 18:56:43.325087 140518046128000 saver.py:1298] Restoring parameters from ./data/tmp/train-10-16-01-plain/train/model.ckpt-500\n","INFO:tensorflow:Running local_init_op.\n","I1026 18:56:56.247895 140518046128000 session_manager.py:531] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1026 18:56:56.265811 140518046128000 session_manager.py:534] Done running local_init_op.\n","2021-10-26 18:56:56.882085: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-10-26 18:56:56.897991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:56.898707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:56.899267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:56.899892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:56.900474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 18:56:56.900996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Evaluation [1/1]\n","I1026 18:56:58.466072 140518046128000 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Evaluation [1/1]\n","I1026 18:56:58.466310 140518046128000 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Inference Time : 15.29684s\n","I1026 18:56:58.538629 140518046128000 evaluation.py:273] Inference Time : 15.29684s\n","INFO:tensorflow:Finished evaluation at 2021-10-26-18:56:58\n","I1026 18:56:58.538839 140518046128000 evaluation.py:276] Finished evaluation at 2021-10-26-18:56:58\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PRMI9bL4WLQh","executionInfo":{"status":"ok","timestamp":1633721764969,"user_tz":360,"elapsed":155,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"2e5922a7-2c1f-4894-de7a-df540962685b"},"source":["ls data/tmp/train-9-24-03-plain/eval_config/\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34meval\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"id":"f8-gRjooYBZ2"},"source":["!kill 1689"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"id":"j-1Mse2mxLQZ","executionInfo":{"status":"ok","timestamp":1635274742308,"user_tz":360,"elapsed":2717,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"c60a9ad7-85bf-4382-e678-c4357dba08f7"},"source":["%tensorboard --logdir ./data/tmp/train-10-16-01-plain/eval/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":908},"id":"CHjmXZ3PcWO8","executionInfo":{"status":"ok","timestamp":1635135743612,"user_tz":360,"elapsed":2783,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"339d48af-19fa-4355-ddde-8d8aa026ec25"},"source":["%tensorboard --inspect --event_file=./data/tmp/train-9-24-03-plain/eval_config/eval/events.out.tfevents.1635135572.0c8dacc34f0c"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 0).\n","Contents of stderr:\n","2021-10-25 04:22:21.881946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-25 04:22:21.890116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-25 04:22:21.890826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","Contents of stdout:\n","======================================================================\n","Processing event files... (this can take a few minutes)\n","======================================================================\n","\n","These tags are in ./data/tmp/train-9-24-03-plain/eval_config/eval/events.out.tfevents.1635135572.0c8dacc34f0c:\n","audio -\n","histograms -\n","images -\n","scalars\n","   loss\n","   losses/kl_beta\n","   losses/kl_bits\n","   losses/kl_loss\n","   losses/r_loss\n","   metrics/accuracy\n","   metrics/mean_per_class_accuracy\n","   sampling_probability\n","tensor -\n","======================================================================\n","\n","Event statistics for ./data/tmp/train-9-24-03-plain/eval_config/eval/events.out.tfevents.1635135572.0c8dacc34f0c:\n","audio -\n","graph\n","   first_step           0\n","   last_step            0\n","   max_step             0\n","   min_step             0\n","   num_steps            1\n","   outoforder_steps     []\n","histograms -\n","images -\n","scalars\n","   first_step           2000\n","   last_step            2000\n","   max_step             2000\n","   min_step             2000\n","   num_steps            1\n","   outoforder_steps     []\n","sessionlog:checkpoint -\n","sessionlog:start -\n","sessionlog:stop -\n","tensor -\n","======================================================================"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"T5sNW9f75JoR"},"source":["# Plain inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNUQsLuJ7FjI","executionInfo":{"status":"ok","timestamp":1635257311206,"user_tz":360,"elapsed":24616,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"822322c4-f199-4264-e547-3a5686cf4fd4"},"source":["!tar -xvf ./data/checkpoints/cat-mel_2bar_big.tar "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cat-mel_2bar_big.ckpt.data-00000-of-00001\n","cat-mel_2bar_big.ckpt.index\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fAWwhlL5Iu-","executionInfo":{"status":"ok","timestamp":1635259384926,"user_tz":360,"elapsed":11313,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"8122cad3-403b-4c61-8413-3582dec904d0"},"source":["!python magenta/models/music_vae/music_vae_train_checkpoint.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/cat-mel_2bar_big/ \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Bo_Burnham_eval.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=15 \\\n","--cache_dataset=False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","2021-10-26 14:42:57.861338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:57.869513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:57.870126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","INFO:tensorflow:Counting examples in ./data/tfrecord/Bo_Burnham_eval.tfrecord.\n","I1026 14:42:57.871375 140394511734656 data.py:1682] Counting examples in ./data/tfrecord/Bo_Burnham_eval.tfrecord.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","W1026 14:42:57.871703 140394511734656 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","INFO:tensorflow:Total examples: 15\n","I1026 14:42:57.938672 140394511734656 data.py:1700] Total examples: 15\n","=======================================\n","Batch size =  15\n","num_batches =  1\n","=======================================\n","2021-10-26 14:42:57.943586: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-10-26 14:42:57.943842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:57.944517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:57.945118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:58.409818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:58.410519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:58.411142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:58.411727: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-10-26 14:42:58.411778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 15, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","I1026 14:42:58.429443 140394511734656 base_model.py:152] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 15, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I1026 14:42:58.433861 140394511734656 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 14:42:58.444417 140394511734656 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 14:42:58.452964 140394511734656 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I1026 14:42:58.453317 140394511734656 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","W1026 14:42:58.453434 140394511734656 lstm_utils.py:139] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1026 14:42:58.453577 140394511734656 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1026 14:42:58.477178 140394511734656 rnn_cell_impl.py:1244] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n","I1026 14:42:58.477621 140394511734656 data.py:1812] Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n","DEBUG:tensorflow:next element\n","I1026 14:42:58.606692 140394511734656 music_vae_train_checkpoint.py:119] next element\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W1026 14:42:58.617552 140394511734656 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W1026 14:42:58.617861 140394511734656 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W1026 14:42:58.959504 140394511734656 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1026 14:42:59.292189 140394511734656 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","INFO:tensorflow:Starting evaluation at 2021-10-26T14:42:59\n","I1026 14:42:59.463801 140394511734656 evaluation.py:255] Starting evaluation at 2021-10-26T14:42:59\n","INFO:tensorflow:Graph was finalized.\n","I1026 14:42:59.533371 140394511734656 monitored_session.py:247] Graph was finalized.\n","2021-10-26 14:42:59.533943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:59.534690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:59.535271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:59.535878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:59.536457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:42:59.536999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","2021-10-26 14:42:59.537196: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","I1026 14:42:59.665291 140394511734656 saver.py:1298] Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","2021-10-26 14:42:59.703661: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:42:59.828258: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:42:59.960167: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.127207: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.259394: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.398771: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.413505: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.423546: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.423631: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.423935: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.424098: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.565503: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.569480: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.579335: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.588105: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.601092: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.630287: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.716120: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.733527: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.755045: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.766539: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.768430: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.840036: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:00.906653: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:01.097298: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:01.111871: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:01.376406: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:01.416205: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:01.416307: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:01.695766: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:02.128761: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:02.321956: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:02.523185: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-26 14:43:02.810336: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","INFO:tensorflow:Running local_init_op.\n","I1026 14:43:03.026453 140394511734656 session_manager.py:531] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1026 14:43:03.043433 140394511734656 session_manager.py:534] Done running local_init_op.\n","2021-10-26 14:43:03.581807: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-10-26 14:43:03.596551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:43:03.597207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:43:03.597761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:43:03.598530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:43:03.599128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 14:43:03.599690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","INFO:tensorflow:Evaluation [1/1]\n","I1026 14:43:04.025038 140394511734656 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Evaluation [1/1]\n","I1026 14:43:04.025314 140394511734656 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Inference Time : 4.62159s\n","I1026 14:43:04.085604 140394511734656 evaluation.py:273] Inference Time : 4.62159s\n","INFO:tensorflow:Finished evaluation at 2021-10-26-14:43:04\n","I1026 14:43:04.085803 140394511734656 evaluation.py:276] Finished evaluation at 2021-10-26-14:43:04\n"]}]},{"cell_type":"code","metadata":{"id":"Tx7_37bxDWkd"},"source":["!kill 2812"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"id":"moZp7YSjB4-G","executionInfo":{"status":"ok","timestamp":1635259387728,"user_tz":360,"elapsed":2811,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"b812101e-149d-45d6-c90a-4011144d1180"},"source":["%tensorboard --logdir ./data/tmp/cat-mel_2bar_big/eval/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcFG5aiaeobS"},"source":["# Debug Evaluation"]},{"cell_type":"code","metadata":{"id":"NkoAVenzeq5N"},"source":["import os\n","\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae import data\n","import tensorflow.compat.v1 as tf\n","import tf_slim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIQkl6g5fjQJ"},"source":["# config setup\n","config = configs.CONFIG_MAP['cat-mel_2bar_big']\n","eval_examples_path = './data/tfrecord/Bo_Burnham_eval.tfrecord'\n","# batch_size = 3\n","config_update_map = {}\n","config_update_map['eval_examples_path'] = eval_examples_path\n","config = configs.update_config(config, config_update_map)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yfkFbpUGe9YW"},"source":["# parameters\n","train_dir = \"./data/tmp/train-9-24-03-plain/eval_config/train\"\n","eval_dir = \"./data/tmp/train-9-24-03-plain/eval_config/eval\"\n","is_training = False\n","num_batches = None\n","master=''\n","\n","tf_file_reader = tf.data.TFRecordDataset\n","file_reader=tf.python_io.tf_record_iterator\n","\n","def dataset_fn():\n","  return data.get_dataset(\n","      config,\n","      tf_file_reader=tf_file_reader,\n","      is_training=is_training,\n","      cache_dataset=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5WIRs6JrmdG","executionInfo":{"status":"ok","timestamp":1635129762957,"user_tz":360,"elapsed":516,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"0331df29-7e38-4e73-84a9-e6333835b510"},"source":["num_batches = data.count_examples(\n","    config.eval_examples_path,\n","    config.tfds_name,\n","    config.data_converter,\n","    file_reader) // config.hparams.batch_size"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Total examples: 0\n"]}]},{"cell_type":"code","metadata":{"id":"GSdU2suCsOqY"},"source":["num_batches=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0sDq02WBhpFq"},"source":["# Should not be called from within the graph to avoid redundant summaries.\n","def _trial_summary(hparams, examples_path, output_dir):\n","  \"\"\"Writes a tensorboard text summary of the trial.\"\"\"\n","\n","  examples_path_summary = tf.summary.text(\n","      'examples_path', tf.constant(examples_path, name='examples_path'),\n","      collections=[])\n","\n","  hparams_dict = hparams.values()\n","\n","  # Create a markdown table from hparams.\n","  header = '| Key | Value |\\n| :--- | :--- |\\n'\n","  keys = sorted(hparams_dict.keys())\n","  lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n","  hparams_table = header + '\\n'.join(lines) + '\\n'\n","\n","  hparam_summary = tf.summary.text(\n","      'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n","\n","  with tf.Session() as sess:\n","    writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n","    writer.add_summary(examples_path_summary.eval())\n","    writer.add_summary(hparam_summary.eval())\n","    writer.close()\n","\n","\n","def _get_input_tensors(dataset, config):\n","  \"\"\"Get input tensors from dataset.\"\"\"\n","  batch_size = config.hparams.batch_size\n","  iterator = tf.data.make_one_shot_iterator(dataset)\n","  (input_sequence, output_sequence, control_sequence,\n","   sequence_length) = iterator.get_next()\n","  input_sequence.set_shape(\n","      [batch_size, None, config.data_converter.input_depth])\n","  output_sequence.set_shape(\n","      [batch_size, None, config.data_converter.output_depth])\n","  if not config.data_converter.control_depth:\n","    control_sequence = None\n","  else:\n","    control_sequence.set_shape(\n","        [batch_size, None, config.data_converter.control_depth])\n","  sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n","\n","  return {\n","      'input_sequence': input_sequence,\n","      'output_sequence': output_sequence,\n","      'control_sequence': control_sequence,\n","      'sequence_length': sequence_length\n","  }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdKOyOMRGTjH","executionInfo":{"status":"ok","timestamp":1634119326968,"user_tz":360,"elapsed":30056,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"58a170b9-3572-415b-b5ed-41ae2fe6b2d9"},"source":["!tar -xvf /content/drive/MyDrive/Code/cat-mel_2bar_big.tar"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cat-mel_2bar_big.ckpt.data-00000-of-00001\n","cat-mel_2bar_big.ckpt.index\n"]}]},{"cell_type":"code","metadata":{"id":"nwyWaKfEe3cd"},"source":["# start eval loop\n","\n","_trial_summary(\n","      config.hparams, config.eval_examples_path or config.tfds_name, eval_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJJaXgagh9B1","executionInfo":{"status":"ok","timestamp":1634120393692,"user_tz":360,"elapsed":9669,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"a38d9ebf-c39a-4121-e446-e124872acb1c"},"source":["with tf.Graph().as_default():\n","    model = config.model\n","    model.build(config.hparams,\n","                config.data_converter.output_depth,\n","                is_training=False)\n","\n","    eval_op = model.eval(\n","        **_get_input_tensors(dataset_fn().take(1), config))\n","\n","    hooks = [\n","        tf_slim.evaluation.StopAfterNEvalsHook(3),\n","        tf_slim.evaluation.SummaryAtEndHook(eval_dir)\n","    ]\n","\n","    return_op = tf_slim.evaluation.evaluate_once(\n","        logdir=eval_dir,\n","        master=master,\n","        checkpoint_path=os.path.join(train_dir, 'model.ckpt-2000'),\n","        # checkpoint_path='/content/drive/MyDrive/Code/cat-mel_2bar_big.ckpt',\n","        num_evals=1000,\n","        eval_op=eval_op,\n","        hooks=hooks)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 512, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'constant', 'sampling_rate': 1.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from constant:1.000000 to constant:1.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Starting evaluation at 2021-10-13T10:19:50\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from ./data/tmp/train-9-24-03-plain/eval_config/train/model.ckpt-2000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Inference Time : 3.89841s\n","INFO:tensorflow:Finished evaluation at 2021-10-13-10:19:53\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWJ-yov95V1G","executionInfo":{"status":"ok","timestamp":1634233380033,"user_tz":360,"elapsed":308,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"3dc91c92-99d5-44bc-8f5a-446e96db778b"},"source":["with tf.Graph().as_default():\n","  df = dataset_fn()\n","  df1 = df.take(1)\n","  git = _get_input_tensors(df1, config)\n","  inp_seq = git['input_sequence']\n","  print(type(inp_seq))\n","  print(inp_seq)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n","<class 'tensorflow.python.framework.ops.Tensor'>\n","Tensor(\"IteratorGetNext:0\", shape=(512, ?, 90), dtype=bool)\n"]}]},{"cell_type":"code","metadata":{"id":"97hfnYvG5oOB"},"source":["tf.enable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzGvKbDI6SGs","executionInfo":{"status":"ok","timestamp":1635129815706,"user_tz":360,"elapsed":286,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"7dc5b745-5932-4582-f7de-932a89c7a8c9"},"source":["tf.executing_eagerly()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5Vfgb7eE8hD","executionInfo":{"status":"ok","timestamp":1634120143040,"user_tz":360,"elapsed":220,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"c3b55e76-b828-4a4a-dcb9-9328bc628e66"},"source":["return_op == None"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9Z2c6T_H8Pe","executionInfo":{"status":"ok","timestamp":1635130156618,"user_tz":360,"elapsed":525,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"a2539b53-30d7-48e2-b1e4-0396ba6ae5b8"},"source":["df = dataset_fn()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRovQXZN8WSH","executionInfo":{"status":"ok","timestamp":1635130323297,"user_tz":360,"elapsed":307,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"584432dc-6c99-450d-90c8-20cba42ffb3b"},"source":["n = df.make_one_shot_iterator()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From <ipython-input-36-5665f39bfe2e>:1: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROwCM9OwVgPz","executionInfo":{"status":"error","timestamp":1635130353989,"user_tz":360,"elapsed":570,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"d7a95247-c12b-40ea-b6e6-ee3534c3f448"},"source":["dfi = n.get_next()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OutOfRangeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-278a0aacee0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next_as_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yEGo2VAgVuy2","executionInfo":{"status":"ok","timestamp":1635129949874,"user_tz":360,"elapsed":530,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"29915690-84f8-4b28-fff4-5015591ea3cf"},"source":["dfi"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f9582057390>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnrdmbp1VwoA","executionInfo":{"status":"error","timestamp":1635129976354,"user_tz":360,"elapsed":990,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"bb743c04-f39e-4c29-de6e-1e21721c5794"},"source":["n = dfi.next()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-9bff5c42dbfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4690\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"1uqvety8Vlyb"},"source":["for e in dfi:\n","  print(e)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1q-KOI_GR44A"},"source":["osi = df.make_one_shot_iterator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"RGaOo2IuSxhb","executionInfo":{"status":"error","timestamp":1634239996335,"user_tz":360,"elapsed":365,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"3aa93e69-6142-41ac-ed9f-2c555e136b1a"},"source":["a = osi.next()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-345024f1cfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"A2Gsf95hIBWo"},"source":["df = df.as_numpy_iterator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjVOuXfq8CU0","executionInfo":{"status":"ok","timestamp":1634234020404,"user_tz":360,"elapsed":352,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"4b2e2d6b-d8cf-43ce-b4ad-829a70069719"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f758a4400d0>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"jCvrrXc2K2FJ"},"source":["df1=df.take(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oi59313k7L9J","executionInfo":{"status":"ok","timestamp":1634234209783,"user_tz":360,"elapsed":295,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"67397aa5-63b7-4799-ebc2-ce909c738be7"},"source":["df1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<DatasetV1Adapter shapes: ((512, ?, 90), (512, ?, 90), (512, ?, 0), (512,)), types: (tf.bool, tf.bool, tf.bool, tf.int32)>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFQ9lY_c69Ur","executionInfo":{"status":"ok","timestamp":1634233911971,"user_tz":360,"elapsed":297,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"f6cac7f7-dd54-4c1c-c749-5e32111fac4f"},"source":["df1t"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f758a542a10>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"DZCyyJhz7jT4"},"source":["df1t = df1t.as_numpy_iterator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"1tlsExkd7nvz","executionInfo":{"status":"error","timestamp":1634233929291,"user_tz":360,"elapsed":394,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"5c677414-22a1-474c-f141-fc1ad0df650b"},"source":["item1 = df1t.next()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-b13be6898faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4690\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"mJRUwYzcK_Zc","executionInfo":{"status":"error","timestamp":1634233685422,"user_tz":360,"elapsed":290,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"bd06718f-9675-4782-d9b5-31fd9945f332"},"source":["git = _get_input_tensors(df1, config)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OutOfRangeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-cc2058084374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_input_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-389cd6efdec5>\u001b[0m in \u001b[0;36m_get_input_tensors\u001b[0;34m(dataset, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   (input_sequence, output_sequence, control_sequence,\n\u001b[0;32m---> 32\u001b[0;31m    sequence_length) = iterator.get_next()\n\u001b[0m\u001b[1;32m     33\u001b[0m   input_sequence.set_shape(\n\u001b[1;32m     34\u001b[0m       [batch_size, None, config.data_converter.input_depth])\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next_as_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"raQ7tMI3LFoH","executionInfo":{"status":"ok","timestamp":1634120525500,"user_tz":360,"elapsed":204,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"d007c65b-4445-41b7-f33a-7d72b33a6939"},"source":["git"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'control_sequence': None,\n"," 'input_sequence': <tf.Tensor 'IteratorGetNext_1:0' shape=(512, ?, 90) dtype=bool>,\n"," 'output_sequence': <tf.Tensor 'IteratorGetNext_1:1' shape=(512, ?, 90) dtype=bool>,\n"," 'sequence_length': <tf.Tensor 'IteratorGetNext_1:3' shape=(512,) dtype=int32>}"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"VUgDeF28x6KZ"},"source":["inp_seq = git['input_sequence']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBT7b66SyITY","executionInfo":{"status":"ok","timestamp":1634231426416,"user_tz":360,"elapsed":4,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"1c3acbdd-1f04-44bf-bd52-403d577d8cf8"},"source":["type(inp_seq)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.framework.ops.Tensor"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8wl7-n7yLG7","executionInfo":{"status":"ok","timestamp":1634231436503,"user_tz":360,"elapsed":298,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"fd924c05-0da2-4a57-f5a7-630ecf132c00"},"source":["inp_seq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'IteratorGetNext:0' shape=(512, ?, 90) dtype=bool>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"DKxgnf4-xpEr","executionInfo":{"status":"error","timestamp":1634231448371,"user_tz":360,"elapsed":372,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"bac5b081-a567-47ce-bdd6-dbfa0d9428ca"},"source":["play(inp_seq)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-12fb179476f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-5842474954e7>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(note_sequence)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluidsynth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/note_seq/notebook_utils.py\u001b[0m in \u001b[0;36mplay_sequence\u001b[0;34m(sequence, synth, sample_rate, colab_ephemeral, **synth_args)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0msynth_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msynth\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0marray_of_floats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msynth_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/note_seq/midi_synth.py\u001b[0m in \u001b[0;36mfluidsynth\u001b[0;34m(sequence, sample_rate, sf2_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mD\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msynthesized\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnote_sequence_to_pretty_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluidsynth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msf2_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msf2_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/note_seq/midi_io.py\u001b[0m in \u001b[0;36mnote_sequence_to_pretty_midi\u001b[0;34m(sequence, drop_events_n_seconds_after_last_note)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mpretty_midi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrettyMIDI\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m   \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m   \u001b[0mticks_per_quarter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticks_per_quarter\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTANDARD_PPQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0mmax_event_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ticks_per_quarter'"]}]},{"cell_type":"code","metadata":{"id":"P93VlRBzMgh-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"_nsDIgiqLK0q","executionInfo":{"status":"error","timestamp":1634120766676,"user_tz":360,"elapsed":217,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"b99b45af-2d39-47d1-a853-c976b02413ce"},"source":["with tf.Graph().as_default():\n","  ev = model.eval(git['input_sequence'], git['output_sequence'], git['sequence_length'])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-38ecbb9d84af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, input_sequence, output_sequence, sequence_length, control_sequence)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \"\"\"\n\u001b[1;32m    320\u001b[0m     metric_map, scalars_to_summarize = self._compute_model_loss(\n\u001b[0;32m--> 321\u001b[0;31m         input_sequence, output_sequence, sequence_length, control_sequence)\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscalars_to_summarize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py\u001b[0m in \u001b[0;36m_compute_model_loss\u001b[0;34m(self, input_sequence, output_sequence, sequence_length, control_sequence)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# Either encode to get `z`, or do unconditional, decoder-only.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_size\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# vae mode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       \u001b[0mq_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sequence, sequence_length, control_sequence)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0mcontrol_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     mu = tf.layers.dense(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_models.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sequence, sequence_length)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         scope=self._name_or_scope)\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Note we access the outputs (h) from the states since the backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# ouputs are reversed to the input order in the returned outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py\u001b[0m in \u001b[0;36mstack_bidirectional_dynamic_rnn\u001b[0;34m(cells_fw, cells_bw, inputs, initial_states_fw, initial_states_bw, dtype, sequence_length, parallel_iterations, time_major, scope, swap_memory)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             time_major=time_major)\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Concat the outputs to create the new input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mprev_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mbidirectional_dynamic_rnn\u001b[0;34m(cell_fw, cell_bw, inputs, sequence_length, initial_state_fw, initial_state_bw, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    445\u001b[0m           \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m           \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m           scope=fw_scope)\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# Backward direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    676\u001b[0m       \u001b[0;31m# Perform some shape validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m       with ops.control_dependencies(\n\u001b[0;32m--> 678\u001b[0;31m           [_assert_has_shape(sequence_length, [batch_size])]):\n\u001b[0m\u001b[1;32m    679\u001b[0m         sequence_length = array_ops.identity(\n\u001b[1;32m    680\u001b[0m             sequence_length, name=\"CheckSeqLen\")\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_assert_has_shape\u001b[0;34m(x, shape)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0mpacked_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       return control_flow_ops.Assert(\n\u001b[0;32m--> 670\u001b[0;31m           math_ops.reduce_all(math_ops.equal(x_shape, packed_shape)), [\n\u001b[0m\u001b[1;32m    671\u001b[0m               \u001b[0;34m\"Expected shape for Tensor %s is \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m               \u001b[0;34m\" but saw shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mincompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \"\"\"\n\u001b[0;32m-> 1864\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3217\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m   3218\u001b[0m         \u001b[0;34m\"Equal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3219\u001b[0;31m                  name=name)\n\u001b[0m\u001b[1;32m   3220\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   6172\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6173\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6174\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6175\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6176\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   6107\u001b[0m     raise ValueError(\n\u001b[1;32m   6108\u001b[0m         \u001b[0;34m\"%s must be from the same graph as %s (graphs are %s and %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6109\u001b[0;31m         (item, original_item, graph, original_graph))\n\u001b[0m\u001b[1;32m   6110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Tensor(\"encoder/cell_0/bidirectional_rnn/fw/fw/stack:0\", shape=(1,), dtype=int32) must be from the same graph as Tensor(\"Shape_6:0\", shape=(1,), dtype=int32) (graphs are <tensorflow.python.framework.ops.Graph object at 0x7f3336bff610> and <tensorflow.python.framework.ops.Graph object at 0x7f3454f95710>)."]}]}]}