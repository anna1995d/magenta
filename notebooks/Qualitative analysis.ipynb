{"cells":[{"cell_type":"markdown","metadata":{"id":"bhOAxQyU0rhs"},"source":["Copyright 2017 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"hYaJ6dvF0v7g"},"source":["# MusicVAE: A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music.\n","### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n","\n","[MusicVAE](https://g.co/magenta/music-vae) learns a latent space of musical scores, providing different modes\n","of interactive musical creation, including:\n","\n","* Random sampling from the prior distribution.\n","* Interpolation between existing sequences.\n","* Manipulation of existing sequences via attribute vectors.\n","\n","Examples of these interactions can be generated below, and selections can be heard in our\n","[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n","\n","For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n","and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n","decoder, which helps the model learn longer-term structures.\n","\n","We also model the interdependencies between instruments by training multiple\n","decoders on the lowest-level embeddings of the hierarchical decoder.\n","\n","For additional details, check out our [blog post](https://g.co/magenta/music-vae) and [paper](https://goo.gl/magenta/musicvae-paper).\n","___\n","\n","This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."]},{"cell_type":"markdown","metadata":{"id":"R122bwRNbTus"},"source":["# Basic Instructions\n","\n","1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n","2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n","3. Listen to the generated samples.\n","4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"]},{"cell_type":"markdown","metadata":{"id":"ZLfb2a_12wcj"},"source":["# Environment Setup\n","Includes package installation for sequence synthesis. Will take a few minutes.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33028,"status":"ok","timestamp":1680818900285,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"},"user_tz":360},"id":"hyJTYBrzKFtw","outputId":"8aa46d07-7096-4094-db56-4558283a375a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#@title Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3406,"status":"ok","timestamp":1680818903686,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"},"user_tz":360},"id":"UJmiphE-KI4w","outputId":"dda98bdb-7892-47d6-b48a-b52154a64d2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta\n"]}],"source":["%cd /content/drive/MyDrive/Thesis/Code/Magenta/magenta/"]},{"cell_type":"code","source":["# Install hmmlearn before downgrading Python\n","!pip install hmmlearn\n","\n","# Downgrade Python\n","!apt-get update -y\n","!apt-get install python3.8\n","!update-alternatives --set python3 /usr/bin/python3.8\n","!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n","!python get-pip.py\n","import sys\n","# This path is Colab-runtime specific, check path in other systems.\n","_ = (sys.path.append(\"/usr/local/lib/python3.8/dist-packages\"))\n","\n","\n","# Preinstall legacy packages\n","!pip install numba==0.48\n","!pip install numpy==1.23\n","!pip install packaging>=21.3\n","!pip install librosa==0.7.2\n","\n","# Install Magenta\n","# !pip install magenta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ruAwrRvIj8cN","executionInfo":{"status":"ok","timestamp":1680818106750,"user_tz":360,"elapsed":54548,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"}},"outputId":"d5bda068-e7ed-48ed-f8c0-71eceb284e6a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hmmlearn\n","  Downloading hmmlearn-0.2.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (217 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.2/217.2 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.22.4)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.10.1)\n","Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.1)\n","Installing collected packages: hmmlearn\n","Successfully installed hmmlearn-0.2.8\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [972 kB]\n","Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n","Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n","Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n","Get:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n","Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,590 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,324 kB]\n","Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n","Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,199 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.3 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,069 kB]\n","Fetched 10.6 MB in 3s (3,463 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python3.8 is already the newest version (3.8.10-0ubuntu1~20.04.7).\n","python3.8 set to manually installed.\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n","update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 2513k  100 2513k    0     0  27.5M      0 --:--:-- --:--:-- --:--:-- 27.5M\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pip\n","  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setuptools\n","  Downloading setuptools-67.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wheel\n","  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","magenta 2.1.3 requires absl-py, which is not installed.\n","magenta 2.1.3 requires dm-sonnet, which is not installed.\n","magenta 2.1.3 requires dopamine-rl<=3.0.1, which is not installed.\n","magenta 2.1.3 requires imageio, which is not installed.\n","magenta 2.1.3 requires librosa<0.8.0,>=0.6.2, which is not installed.\n","magenta 2.1.3 requires matplotlib>=1.5.3, which is not installed.\n","magenta 2.1.3 requires mido==1.2.6, which is not installed.\n","magenta 2.1.3 requires mir_eval>=0.4, which is not installed.\n","magenta 2.1.3 requires note-seq, which is not installed.\n","magenta 2.1.3 requires numba<0.50, which is not installed.\n","magenta 2.1.3 requires numpy, which is not installed.\n","magenta 2.1.3 requires Pillow>=3.4.2, which is not installed.\n","magenta 2.1.3 requires pretty_midi>=0.2.6, which is not installed.\n","magenta 2.1.3 requires pygtrie>=2.3, which is not installed.\n","magenta 2.1.3 requires python-rtmidi<1.2,>=1.1, which is not installed.\n","magenta 2.1.3 requires scikit-image, which is not installed.\n","magenta 2.1.3 requires scipy>=0.18.1, which is not installed.\n","magenta 2.1.3 requires six>=1.12.0, which is not installed.\n","magenta 2.1.3 requires sk-video, which is not installed.\n","magenta 2.1.3 requires sox>=1.3.7, which is not installed.\n","magenta 2.1.3 requires tensor2tensor, which is not installed.\n","magenta 2.1.3 requires tensorflow, which is not installed.\n","magenta 2.1.3 requires tensorflow-datasets, which is not installed.\n","magenta 2.1.3 requires tensorflow-probability, which is not installed.\n","magenta 2.1.3 requires tf_slim, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pip-23.0.1 setuptools-67.6.1 wheel-0.40.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting numba==0.48\n","  Downloading numba-0.48.0-1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy>=1.15\n","  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llvmlite<0.32.0,>=0.31.0dev0\n","  Downloading llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.48) (67.6.1)\n","Installing collected packages: llvmlite, numpy, numba\n","Successfully installed llvmlite-0.31.0 numba-0.48.0 numpy-1.24.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting numpy==1.23\n","  Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.24.2\n","    Uninstalling numpy-1.24.2:\n","      Successfully uninstalled numpy-1.24.2\n","Successfully installed numpy-1.23.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting librosa==0.7.2\n","  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting audioread>=2.0.0\n","  Downloading audioread-3.0.0.tar.gz (377 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2) (1.23.0)\n","Collecting scipy>=1.0.0\n","  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n","  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting joblib>=0.12\n","  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting decorator>=3.0.0\n","  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","Collecting six>=1.3\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting resampy>=0.2.2\n","  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2) (0.48.0)\n","Collecting soundfile>=0.9.0\n","  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa==0.7.2) (67.6.1)\n","Collecting numba>=0.43.0\n","  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting importlib-metadata\n","  Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n","Collecting numba>=0.43.0\n","  Downloading numba-0.56.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.56.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setuptools\n","  Downloading setuptools-59.8.0-py3-none-any.whl (952 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.8/952.8 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numba>=0.43.0\n","  Downloading numba-0.56.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.55.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.55.1-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.55.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.54.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy>=1.15.0\n","  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numba>=0.43.0\n","  Downloading numba-0.54.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.53.1-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading numba-0.53.0-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n","Collecting resampy>=0.2.2\n","  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Collecting cffi>=1.0\n","  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.7/442.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pycparser\n","  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: librosa, audioread\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612900 sha256=fae7d24d0d44006cf89882425a37f52a6afd252ad0305c813ff18af6199fbbb9\n","  Stored in directory: /root/.cache/pip/wheels/11/f0/b0/a8f9944f274bbc0f0159f2268f43dadcfa1cfe50a9007d8e1f\n","  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23706 sha256=8bcb3c6245bb0faf9312edd20bf3eab23837eca6a253c6986bfbd7f32d3c2c14\n","  Stored in directory: /root/.cache/pip/wheels/0a/ed/be/49df2538fca496690a024a4374455584d65c2afd6fc3d6e9c7\n","Successfully built librosa audioread\n","Installing collected packages: threadpoolctl, six, scipy, pycparser, joblib, decorator, audioread, scikit-learn, resampy, cffi, soundfile, librosa\n","Successfully installed audioread-3.0.0 cffi-1.15.1 decorator-5.1.1 joblib-1.2.0 librosa-0.7.2 pycparser-2.21 resampy-0.3.1 scikit-learn-1.2.2 scipy-1.10.1 six-1.16.0 soundfile-0.12.1 threadpoolctl-3.1.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cffi","six"]}}},"metadata":{}}]},{"cell_type":"code","source":["!update-alternatives --install /usr/bin/python python /usr/bin/python3.8 1"],"metadata":{"id":"vSvn8gObiPXx","executionInfo":{"status":"ok","timestamp":1680818022160,"user_tz":360,"elapsed":2,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!update-alternatives --list python\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpFLq1daiM43","executionInfo":{"status":"ok","timestamp":1680818022611,"user_tz":360,"elapsed":452,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"}},"outputId":"5e5cfcbe-9ced-482e-eaf0-3cd9a623aa86"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3.8\n"]}]},{"cell_type":"code","source":["!sudo update-alternatives --config python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUvxzgVAijTk","executionInfo":{"status":"ok","timestamp":1680818028151,"user_tz":360,"elapsed":5542,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"}},"outputId":"389494f6-4fbc-460f-fd3c-298afcdfb11d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["There is 1 choice for the alternative python (providing /usr/bin/python).\n","\n","  Selection    Path                Priority   Status\n","------------------------------------------------------------\n","  0            /usr/bin/python3.8   1         auto mode\n","* 1            /usr/bin/python3.8   1         manual mode\n","\n","Press <enter> to keep the current choice[*], or type selection number: ^C\n"]}]},{"cell_type":"code","source":["!sudo update-alternatives --set python /usr/bin/python3.8\n"],"metadata":{"id":"MfWMoZZHioek","executionInfo":{"status":"ok","timestamp":1680818028151,"user_tz":360,"elapsed":10,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680818028151,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"},"user_tz":360},"id":"jZQB5zbs9z0n","outputId":"0beaf5b8-6b84-41f6-de2d-fc3b343e7fac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.9.16\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPMTW_jSiBuT","outputId":"496db348-21af-453b-b656-4c7b84697fd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.12.0\n"]}],"source":["!pip uninstall tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0tafO4RiLd_"},"outputs":[],"source":["!pip install tensorflow==2.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-0vItw_iVs-"},"outputs":[],"source":["!pip install nvidia-tensorrt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tS27OO3yFpZJ"},"outputs":[],"source":["!pip install -qU google-cloud note-seq==0.0.2 pyfluidsynth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgcq1pxyWlc0"},"outputs":[],"source":["import glob\n","\n","BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n","\n","print('Installing dependencies...')\n","!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","!pip install -q pyfluidsynth\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","# This is only needed for the hosted Colab environment.\n","import ctypes.util\n","orig_ctypes_util_find_library = ctypes.util.find_library\n","def proxy_find_library(lib):\n","  if lib == 'fluidsynth':\n","    return 'libfluidsynth.so.1'\n","  else:\n","    return orig_ctypes_util_find_library(lib)\n","ctypes.util.find_library = proxy_find_library\n","\n","\n","print('Importing libraries and defining some helper functions...')\n","from google.colab import files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BzXWDx0WyTq"},"outputs":[],"source":["!pip install tensor2tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIkRFjrRW9DE"},"outputs":[],"source":["!pip install note_seq"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kS-rICWXA42","outputId":"9e765aed-5972-451c-abfa-043289ad505f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/drive/MyDrive/University%20of%20Alberta/Thesis/Code/Magenta/magenta\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting absl-py\n","  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dm-sonnet\n","  Downloading dm_sonnet-2.0.1-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.4/268.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dopamine-rl<=3.0.1\n","  Downloading dopamine_rl-3.0.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting imageio\n","  Downloading imageio-2.27.0-py3-none-any.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: librosa<0.8.0,>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.3) (0.7.2)\n","Collecting matplotlib>=1.5.3\n","  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mido==1.2.6\n","  Downloading mido-1.2.6-py2.py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mir_eval>=0.4\n","  Downloading mir_eval-0.7.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting note-seq\n","  Downloading note_seq-0.0.5-py3-none-any.whl (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numba<0.50 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.3) (0.48.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.3) (1.23.0)\n","Collecting Pillow>=3.4.2\n","  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pretty_midi>=0.2.6\n","  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pygtrie>=2.3\n","  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n","Collecting python-rtmidi<1.2,>=1.1\n","  Downloading python-rtmidi-1.1.2.tar.gz (204 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.5/204.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting scikit-image\n","  Downloading scikit_image-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.3) (1.10.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.3) (1.16.0)\n","Collecting sk-video\n","  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sox>=1.3.7\n","  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n","Collecting tensor2tensor\n","  Downloading tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow\n","  Downloading tensorflow-2.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-datasets\n","  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-probability\n","  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.3) (0.40.0)\n","Collecting gym>=0.10.5\n","  Downloading gym-0.26.2.tar.gz (721 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting gin-config>=0.1.1\n","  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opencv-python>=3.4.1.15\n","  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.8.0,>=0.6.2->magenta==2.1.3) (0.3.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.8.0,>=0.6.2->magenta==2.1.3) (5.1.1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.8.0,>=0.6.2->magenta==2.1.3) (3.0.0)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.8/dist-packages (from librosa<0.8.0,>=0.6.2->magenta==2.1.3) (1.2.0)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.8.0,>=0.6.2->magenta==2.1.3) (1.2.2)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.8.0,>=0.6.2->magenta==2.1.3) (0.12.1)\n","Collecting python-dateutil>=2.7\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting contourpy>=1.0.1\n","  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.3->magenta==2.1.3) (23.0)\n","Collecting pyparsing>=2.3.1\n","  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler>=0.10\n","  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n","Collecting importlib-resources>=3.2.0\n","  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting future\n","  Downloading future-0.18.3.tar.gz (840 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba<0.50->magenta==2.1.3) (0.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba<0.50->magenta==2.1.3) (67.6.1)\n","Collecting tabulate>=0.7.5\n","  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n","Collecting dm-tree>=0.1.1\n","  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt>=1.11.1\n","  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting intervaltree>=2.1.0\n","  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting IPython\n","  Downloading ipython-8.12.0-py3-none-any.whl (796 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.4/796.4 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting protobuf>=4.21.2\n","  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas>=0.18.1\n","  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bokeh>=0.12.0\n","  Downloading bokeh-3.1.0-py3-none-any.whl (8.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting attrs\n","  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lazy_loader>=0.1\n","  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n","Collecting networkx>=2.8\n","  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy>=0.18.1\n","  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyWavelets>=1.1.1\n","  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tifffile>=2019.7.26\n","  Downloading tifffile-2023.3.21-py3-none-any.whl (218 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py\n","  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mesh-tensorflow\n","  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tqdm\n","  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flask\n","  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bz2file\n","  Downloading bz2file-0.98.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting oauth2client\n","  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gunicorn\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypng\n","  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-gan\n","  Downloading tensorflow_gan-2.1.0-py2.py3-none-any.whl (367 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sympy\n","  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-api-python-client\n","  Downloading google_api_python_client-2.84.0-py2.py3-none-any.whl (11.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gevent\n","  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kfac\n","  Downloading kfac-0.2.4-py2.py3-none-any.whl (193 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-probability\n","  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.4/981.4 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cloudpickle>=0.6.1\n","  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.13,>=2.12.0\n","  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.13,>=2.12\n","  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting termcolor>=1.1.0\n","  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n","Collecting typing-extensions>=3.6.6\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jax>=0.3.15\n","  Downloading jax-0.4.8.tar.gz (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting wrapt>=1.11.1\n","  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting libclang>=13.0.0\n","  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting promise\n","  Downloading promise-2.3.tar.gz (19 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting psutil\n","  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Collecting etils[enp,epath]>=0.9.0\n","  Downloading etils-1.2.0-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting array-record\n","  Downloading array_record-0.2.0-py38-none-any.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-metadata\n","  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting click\n","  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Jinja2>=2.9\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tornado>=5.1\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xyzservices>=2021.09.1\n","  Downloading xyzservices-2023.2.0-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyYAML>=3.10\n","  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting zipp\n","  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n","Collecting importlib-metadata>=4.8.0\n","  Using cached importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n","Collecting gym-notices>=0.0.4\n","  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n","Collecting sortedcontainers<3.0,>=2.0\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Collecting ml-dtypes>=0.0.3\n","  Downloading ml_dtypes-0.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.0/155.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytz>=2020.1\n","  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tzdata>=2022.1\n","  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi>=2017.4.17\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.9/195.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna<4,>=2.5\n","  Downloading idna-3.4-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.8.0,>=0.6.2->magenta==2.1.3) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.9.0->librosa<0.8.0,>=0.6.2->magenta==2.1.3) (1.15.1)\n","Collecting werkzeug>=1.0.1\n","  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.17.2-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting markdown>=2.6.8\n","  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itsdangerous>=2.0\n","  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n","Collecting greenlet>=2.0.0\n","  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.5/618.5 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting zope.event\n","  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n","Collecting zope.interface\n","  Downloading zope.interface-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n","  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httplib2<1dev,>=0.15.0\n","  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n","  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n","Collecting uritemplate<5,>=3.0.1\n","  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n","Collecting pickleshare\n","  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n","Collecting traitlets>=5\n","  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting matplotlib-inline\n","  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n","Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n","  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting stack-data\n","  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n","Collecting backcall\n","  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n","Collecting pexpect>4.3\n","  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jedi>=0.16\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygments>=2.4.0\n","  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py\n","  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kfac\n","  Downloading kfac-0.2.3-py2.py3-none-any.whl (191 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading kfac-0.2.2-py2.py3-none-any.whl (191 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading kfac-0.2.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyasn1-modules>=0.0.5\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyasn1>=0.1.7\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rsa>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting mpmath>=0.19\n","  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typeguard>=2.7\n","  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n","Collecting tensorflow-hub>=0.2\n","  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-metadata\n","  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.11.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.10.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.8.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.7.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.6.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.5.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.4.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.2.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.1.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-1.0.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.30.0-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.29.0-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.28.0-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.27.0-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.26.0-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.25.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.24.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_metadata-0.23.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting googleapis-common-protos\n","  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-metadata\n","  Downloading tensorflow_metadata-0.22.2-py2.py3-none-any.whl (32 kB)\n","  Downloading tensorflow_metadata-0.22.1-py2.py3-none-any.whl (31 kB)\n","  Downloading tensorflow_metadata-0.22.0-py2.py3-none-any.whl (31 kB)\n","  Downloading tensorflow_metadata-0.21.2-py2.py3-none-any.whl (31 kB)\n","  Downloading tensorflow_metadata-0.21.1-py2.py3-none-any.whl (31 kB)\n","  Downloading tensorflow_metadata-0.21.0-py2.py3-none-any.whl (30 kB)\n","  Downloading tensorflow_metadata-0.15.2-py2.py3-none-any.whl (29 kB)\n","  Downloading tensorflow_metadata-0.15.1-py2.py3-none-any.whl (29 kB)\n","  Downloading tensorflow_metadata-0.15.0-py2.py3-none-any.whl (27 kB)\n","  Downloading tensorflow_metadata-0.14.0-py2.py3-none-any.whl (27 kB)\n","  Downloading tensorflow_metadata-0.13.0-py3-none-any.whl (25 kB)\n","  Downloading tensorflow_metadata-0.12.1-py2.py3-none-any.whl (25 kB)\n","INFO: pip is looking at multiple versions of tensorflow-gan to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-gan\n","  Downloading tensorflow_gan-2.0.0-py2.py3-none-any.whl (365 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.2/365.2 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-addons to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of sympy to determine which version is compatible with other requirements. This could take a while.\n","Collecting sympy\n","  Downloading sympy-1.11-py3-none-any.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of pypng to determine which version is compatible with other requirements. This could take a while.\n","Collecting pypng\n","  Downloading pypng-0.0.21-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of pydub to determine which version is compatible with other requirements. This could take a while.\n","Collecting pydub\n","  Downloading pydub-0.25.0-py2.py3-none-any.whl (32 kB)\n","INFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n","Collecting psutil\n","  Downloading psutil-5.9.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.6/295.6 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of promise to determine which version is compatible with other requirements. This could take a while.\n","Collecting promise\n","  Downloading promise-2.2.1.tar.gz (19 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of oauth2client to determine which version is compatible with other requirements. This could take a while.\n","Collecting oauth2client\n","  Downloading oauth2client-4.1.2-py2.py3-none-any.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of mesh-tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting mesh-tensorflow\n","  Downloading mesh_tensorflow-0.1.20-py3-none-any.whl (385 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.19-py3-none-any.whl (366 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.4/366.4 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.18-py3-none-any.whl (361 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.5/361.5 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.17-py3-none-any.whl (342 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.8/342.8 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.16-py3-none-any.whl (305 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.8/305.8 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.15-py3-none-any.whl (305 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.8/305.8 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.14-py3-none-any.whl (306 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of mesh-tensorflow to determine which version is compatible with other requirements. This could take a while.\n","  Downloading mesh_tensorflow-0.1.13-py3-none-any.whl (292 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.4/292.4 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.12-py2.py3-none-any.whl (282 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.3/282.3 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.11-py2.py3-none-any.whl (282 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.2/282.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.10-py2.py3-none-any.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.5/280.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.9-py2.py3-none-any.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.9/272.9 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading mesh_tensorflow-0.1.8-py2.py3-none-any.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.7-py2.py3-none-any.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.5/271.5 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.6-py2.py3-none-any.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.1/271.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.5-py2.py3-none-any.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.0/271.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.4-py2.py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.3-py2.py3-none-any.whl (222 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.2-py2.py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ortools\n","  Downloading ortools-9.6.2534-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mesh-tensorflow\n","  Downloading mesh_tensorflow-0.1.1-py2.py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.3/224.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.1.0-py2.py3-none-any.whl (221 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.0.5-py2.py3-none-any.whl (95 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mesh_tensorflow-0.0.4-py2.py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of kfac to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n","Collecting IPython\n","  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 kB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of gunicorn to determine which version is compatible with other requirements. This could take a while.\n","Collecting gunicorn\n","  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n","Collecting google-api-python-client\n","  Downloading google_api_python_client-2.83.0-py2.py3-none-any.whl (11.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of gevent to determine which version is compatible with other requirements. This could take a while.\n","Collecting gevent\n","  Downloading gevent-22.10.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n","Collecting future\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n","Collecting flask\n","  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n","Collecting click\n","  Downloading click-8.1.2-py3-none-any.whl (96 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of bz2file to determine which version is compatible with other requirements. This could take a while.\n","Collecting bz2file\n","  Downloading bz2file-0.95.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n","Collecting attrs\n","  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of array-record to determine which version is compatible with other requirements. This could take a while.\n","Collecting array-record\n","  Downloading array_record-0.1.0-py38-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of wrapt to determine which version is compatible with other requirements. This could take a while.\n","Collecting wrapt>=1.11.1\n","  Downloading wrapt-1.14.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n","Collecting typing-extensions>=3.6.6\n","  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n","INFO: pip is looking at multiple versions of tifffile to determine which version is compatible with other requirements. This could take a while.\n","Collecting tifffile>=2019.7.26\n","  Downloading tifffile-2023.3.15-py3-none-any.whl (218 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.6/218.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of array-record to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of termcolor to determine which version is compatible with other requirements. This could take a while.\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n","INFO: pip is looking at multiple versions of tensorflow-io-gcs-filesystem to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorboard<2.13,>=2.12\n","  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: pip is looking at multiple versions of tabulate to determine which version is compatible with other requirements. This could take a while.\n","Collecting tabulate>=0.7.5\n","  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n","INFO: pip is looking at multiple versions of soundfile to determine which version is compatible with other requirements. This could take a while.\n","Collecting soundfile>=0.9.0\n","  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n","INFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n","Collecting scikit-learn!=0.19.0,>=0.14.0\n","  Using cached scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n","INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n","Collecting resampy>=0.2.2\n","  Using cached resampy-0.4.2-py3-none-any.whl (3.1 MB)\n","INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n","Collecting requests\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of pywavelets to determine which version is compatible with other requirements. This could take a while.\n","Collecting PyWavelets>=1.1.1\n","  Downloading PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n","Collecting pyparsing>=2.3.1\n","  Downloading pyparsing-3.0.8-py3-none-any.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n","Collecting protobuf>=4.21.2\n","  Downloading protobuf-4.22.0-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.11-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.10-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.9-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.8-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.7-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n","  Downloading protobuf-4.21.6-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n","Collecting pandas>=0.18.1\n","  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n","Collecting packaging>=20.0\n","  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n","INFO: pip is looking at multiple versions of opt-einsum to determine which version is compatible with other requirements. This could take a while.\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n","Collecting opencv-python>=3.4.1.15\n","  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n","Collecting networkx>=2.8\n","  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n","Collecting llvmlite<0.32.0,>=0.31.0dev0\n","  Using cached llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n","INFO: pip is looking at multiple versions of libclang to determine which version is compatible with other requirements. This could take a while.\n","Collecting libclang>=13.0.0\n","  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of lazy-loader to determine which version is compatible with other requirements. This could take a while.\n","Collecting lazy_loader>=0.1\n","  Downloading lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n","INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n","Collecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of keras to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n","Collecting joblib>=0.12\n","  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n","INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","Collecting jax>=0.3.15\n","  Downloading jax-0.4.7.tar.gz (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of intervaltree to determine which version is compatible with other requirements. This could take a while.\n","Collecting intervaltree>=2.1.0\n","  Downloading intervaltree-3.0.2.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of importlib-resources to determine which version is compatible with other requirements. This could take a while.\n","Collecting importlib-resources>=3.2.0\n","  Downloading importlib_resources-5.11.1-py3-none-any.whl (35 kB)\n","INFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n","Collecting h5py\n","  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of gym to determine which version is compatible with other requirements. This could take a while.\n","Collecting gym>=0.10.5\n","  Downloading gym-0.26.1.tar.gz (719 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.9/719.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n","Collecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of google-pasta to determine which version is compatible with other requirements. This could take a while.\n","Collecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.1.8-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of gin-config to determine which version is compatible with other requirements. This could take a while.\n","Collecting gin-config>=0.1.1\n","  Downloading gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of gast to determine which version is compatible with other requirements. This could take a while.\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","INFO: pip is looking at multiple versions of fonttools to determine which version is compatible with other requirements. This could take a while.\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.39.2-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of flatbuffers to determine which version is compatible with other requirements. This could take a while.\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n","INFO: pip is looking at multiple versions of etils[enp,epath] to determine which version is compatible with other requirements. This could take a while.\n","Collecting etils[enp,epath]>=0.9.0\n","  Downloading etils-1.1.1-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of dm-tree to determine which version is compatible with other requirements. This could take a while.\n","Collecting dm-tree>=0.1.1\n","  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n","Collecting decorator>=3.0.0\n","  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n","Collecting cycler>=0.10\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n","Collecting contourpy>=1.0.1\n","  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.0/296.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n","Collecting cloudpickle>=0.6.1\n","  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n","INFO: pip is looking at multiple versions of bokeh to determine which version is compatible with other requirements. This could take a while.\n","Collecting bokeh>=0.12.0\n","  Downloading bokeh-3.0.3-py3-none-any.whl (16.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of audioread to determine which version is compatible with other requirements. This could take a while.\n","Collecting audioread>=2.0.0\n","  Using cached audioread-3.0.0-py3-none-any.whl\n","INFO: pip is looking at multiple versions of astunparse to determine which version is compatible with other requirements. This could take a while.\n","Collecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.2-py2.py3-none-any.whl (12 kB)\n","INFO: pip is looking at multiple versions of wheel to determine which version is compatible with other requirements. This could take a while.\n","Collecting wheel\n","  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n","INFO: pip is looking at multiple versions of tf-slim to determine which version is compatible with other requirements. This could take a while.\n","Collecting tf_slim\n","  Downloading tf_slim-1.0-py2.py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-datasets\n","  Downloading tensorflow_datasets-4.8.3-py3-none-any.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.8.2-py3-none-any.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-datasets\n","  Downloading tensorflow_datasets-4.8.1-py3-none-any.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tf-slim to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tensorflow_datasets-4.8.0-py3-none-any.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.7.0-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tensorflow_datasets-4.5.1-py3-none-any.whl (4.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.5.0-py3-none-any.whl (4.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.3.0-py3-none-any.whl (3.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.2.0-py3-none-any.whl (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading tensorflow_datasets-4.1.0-py3-none-any.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.0.1-py3-none-any.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-4.0.0-py3-none-any.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-3.2.0-py3-none-any.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-3.1.0-py3-none-any.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-3.0.0-py3-none-any.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-2.1.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-2.0.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.3.2-py3-none-any.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.3.1-py3-none-any.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.3.0-py3-none-any.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.2.0-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.1.0-py3-none-any.whl (933 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.5/933.5 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.0.2-py3-none-any.whl (682 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.9/682.9 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow_datasets-1.0.1-py3-none-any.whl (400 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.8/400.8 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow\n","  Downloading tensorflow-2.11.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.2/588.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow\n","  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow\n","  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow\n","  Downloading tensorflow-2.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers<2,>=1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting keras<2.10.0,>=2.9.0rc0\n","  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0rc0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of keras-preprocessing to determine which version is compatible with other requirements. This could take a while.\n","Collecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.1-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n","  Downloading keras-2.9.0rc2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-gan to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tensorflow-addons to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of sympy to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of pypng to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of pydub to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of promise to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of oauth2client to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of kfac to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of gunicorn to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of gevent to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of bz2file to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of wrapt to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tifffile to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of termcolor to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tensorflow-io-gcs-filesystem to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tabulate to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of soundfile to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of pywavelets to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of opt-einsum to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of libclang to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of lazy-loader to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of keras to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of intervaltree to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of importlib-resources to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of gym to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of google-pasta to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of gin-config to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of gast to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of fonttools to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of flatbuffers to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of etils[enp,epath] to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of dm-tree to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of bokeh to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of audioread to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of astunparse to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of wheel to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of keras-preprocessing to determine which version is compatible with other requirements. This could take a while.\n","Collecting protobuf>=4.21.2\n","  Downloading protobuf-4.21.5-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.4-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.3-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n"]}],"source":["!pip install -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDesg4X8_XXs"},"outputs":[],"source":["!pip install fluidsynth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXJuhzx4XSEd"},"outputs":[],"source":["import magenta.music as mm\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel\n","import numpy as np\n","import os\n","import tensorflow.compat.v1 as tf\n","\n","tf.disable_v2_behavior()\n","# tf.enable_eager_execution()\n","\n","# Necessary until pyfluidsynth is updated (>1.2.5).\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","def play(note_sequence):\n","  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n","\n","def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","                assert_same_length=True, temperature=0.5,\n","                individual_duration=4.0):\n","  \"\"\"Interpolates between a start and end sequence.\"\"\"\n","  note_sequences = model.interpolate(\n","      start_seq, end_seq,num_steps=num_steps, length=max_length,\n","      temperature=temperature,\n","      assert_same_length=assert_same_length)\n","\n","  print('Start Seq Reconstruction')\n","  play(note_sequences[0])\n","  print('End Seq Reconstruction')\n","  play(note_sequences[-1])\n","  print('Mean Sequence')\n","  play(note_sequences[num_steps // 2])\n","  print('Start -> End Interpolation')\n","  interp_seq = mm.sequences_lib.concatenate_sequences(\n","      note_sequences, [individual_duration] * len(note_sequences))\n","  play(interp_seq)\n","  mm.plot_sequence(interp_seq)\n","  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n","\n","def download(note_sequence, filename):\n","  mm.sequence_proto_to_midi_file(note_sequence, filename)\n","  files.download(filename)\n","\n","print('Done')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BR4m5TTKLYB"},"outputs":[],"source":["from datetime import datetime\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFKuwPzoFjrM"},"outputs":[],"source":["from glob import glob"]},{"cell_type":"markdown","metadata":{"id":"7i0PL335NHUL"},"source":["# Notes\n","\n","A few important functions are:\n","\n","\n","*   \n","```\n","# tf.train.list_variables(checkpoint_path)\n","```\n","This will list every variable in the checkpoint including tensors. \n","\n","\n","*   \n","```\n","# tf.train.load_checkpoint(path).get_variable_to_shape_map()\n","```\n","\n","\n","*   \n","```\n","from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n","print_tensors_in_checkpoint_file(path, all_tensors=True, tensor_name=name)\n","```\n","This will print all or a specific tensor and their values in checkpoint.\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8YTLvCs4EdNQ"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlhK2soXE8t4"},"outputs":[],"source":["import sys\n","import copy\n","from magenta.models.music_vae import music_vae_mcts_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rGC0QBaOtF5P"},"outputs":[],"source":["# enable deterministic behaviour to debug\n","# may make operations slower\n","import random\n","seed = 1\n","random.seed(seed)\n","np.random.seed(seed)\n","tf.set_random_seed(1)\n","# tf.config.experimental.enable_op_determinism()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXOE0AloEfYs"},"outputs":[],"source":["# Experiment config \n","config_name = 'cat-mel_2bar_big'\n","mode = 'train' # mode = {train | eval}\n","finetune = 'True' # if mode==train, finetune = {True | False}\n","# if finetune==True, a comma-separated list of variable names to be finetuned\n","# or 'last_layer' or 'all'.\n","trainable_vars = 'all' \n","num_steps = '2000'\n","batch_size = '32'\n","learning_rate = '0.001'\n","\n","run_dir = './data/mcts/CE_MCTS'\n","train_example_path = './data/tfrecord/Persian/persian_100_v1/fold_4_train.tfrecord'\n","eval_example_path = './data/tfrecord/Persian/persian_100_v1/fold_4_test.tfrecord'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGDE3OH3f0Bx"},"outputs":[],"source":["# Add datetime info to run_dir\n","run_dir += datetime.now().strftime('-%y-%m-%d-%H-%M/')\n","print(\"New run_dir is: \", run_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rme7Rj6GAeF5"},"outputs":[],"source":["run_dir = './data/mcts/CE_MCTS-23-02-15-02-37/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXmtBnBeQDTA"},"outputs":[],"source":["# run_dir = './data/mcts/CE_MCTS-23-02-05-07-36/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TM181GJ8iSk5"},"outputs":[],"source":["# train_example_path = './data/tfrecord/Video_game.tfrecord'\n","# eval_example_path = './data/tfrecord/Video_game.tfrecord'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8t2faPhKmkfH"},"outputs":[],"source":["mel_2bar_big_ckpt_path = '/content/drive/MyDrive/Code/cat-mel_2bar_big.ckpt'\n","save_path = './data/mcts/ckpt_test'\n","log_path = os.path.join(run_dir, 'log.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwJDaH82sLp5"},"outputs":[],"source":["import logging\n","log = logging.getLogger()\n","if not os.path.exists(run_dir):\n","    os.makedirs(run_dir)\n","fh = logging.FileHandler(log_path)\n","log.addHandler(fh)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wgZqPnG_3Mvb"},"outputs":[],"source":["MODEL_VARIABLES = [\n","    'decoder/multi_rnn_cell/cell_0/lstm_cell/bias',\n","    'decoder/multi_rnn_cell/cell_0/lstm_cell/kernel',\n","    'decoder/multi_rnn_cell/cell_1/lstm_cell/bias',\n","    'decoder/multi_rnn_cell/cell_1/lstm_cell/kernel',\n","    'decoder/multi_rnn_cell/cell_2/lstm_cell/bias',\n","    'decoder/multi_rnn_cell/cell_2/lstm_cell/kernel',\n","    'decoder/output_projection/bias',\n","    'decoder/output_projection/kernel',\n","    'decoder/z_to_initial_state/bias',\n","    'decoder/z_to_initial_state/kernel',\n","    'encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias',\n","    'encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel',\n","    'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias',\n","    'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel',\n","    'encoder/mu/bias',\n","    'encoder/mu/kernel',\n","    'encoder/sigma/bias',\n","    'encoder/sigma/kernel',\n","    'global_step'\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I7SUwu6fX-o"},"outputs":[],"source":["# Importing gc module\n","import gc\n"," \n","# Returns the number of\n","# objects it has collected\n","# and deallocated\n","# collected = gc.collect()\n"," \n","# # Prints Garbage collector\n","# # as 0 object\n","# print(\"Garbage collector: collected\",\n","#           \"%d objects.\" % collected)"]},{"cell_type":"markdown","metadata":{"id":"7PEj5FjUmMPS"},"source":["# Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kxGYFlYXKcPq"},"outputs":[],"source":["def checkpoint_to_variable_list(ckpt_path):\n","  # tf.keras.backend.clear_session()\n","  ckpt_reader = tf.train.load_checkpoint(ckpt_path)\n","  name_shape_list = tf.train.list_variables(ckpt_path)\n","\n","  tf.reset_default_graph()\n","  var_list = list()\n","  var_names = list()\n","  for name, _ in name_shape_list:\n","    if name in MODEL_VARIABLES:\n","      # print(name)\n","      var_list.append(ckpt_reader.get_tensor(name))\n","      var_names.append(name)\n","\n","  return var_names, var_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMbTpe5dMa65"},"outputs":[],"source":["def variable_list_to_checkpoint(var_names, variable_list, save_path):\n","  tf_vars = list()\n","  for val, name in zip(variable_list, var_names):\n","    if name == 'global_step':\n","      tf_vars.append(tf.Variable(val, name=name, dtype=tf.int64))\n","    else:\n","      tf_vars.append(tf.Variable(val, name=name, dtype=tf.float32))\n","\n","  saver = tf.train.Saver(tf_vars)\n","  sess = tf.Session()\n","  sess.run(tf.global_variables_initializer())\n","  saver.save(sess, save_path)\n","  tf.keras.backend.clear_session()"]},{"cell_type":"markdown","metadata":{"id":"KiByVxyorZPl"},"source":["# CE-MCTS\n"]},{"cell_type":"markdown","metadata":{"id":"yKW3A9t-vahE"},"source":["## CE Neighbor Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJHfYu8OkP2A"},"outputs":[],"source":["# Conceptual expansion neighborhood no. 0\n","# Multiplying alpha by random number in range [-2, 2] for an index in a layer\n","\n","def neighbor_0(weights, alphas):\n","  model_weights = weights.copy()\n","  model_alphas = alphas.copy()\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.divide(model_weights[i], model_alphas[i])\n","\n","  idxa = random.randint(0, len(model_weights) - 1)\n","  current_layer = model_weights[idxa]\n","  idxb = random.randint(0, current_layer.shape[0] - 1)\n","  x = np.random.uniform(-2,2)\n","\n","  if len(current_layer.shape)==1:\n","    model_alphas[idxa][idxb] *= x \n","  else:\n","    for i in range(current_layer.shape[1]):\n","      model_alphas[idxa][idxb][i] *= x\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.multiply(model_weights[i], model_alphas[i])\n","\n","  return model_weights, model_alphas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cuBTG18vmO2"},"outputs":[],"source":["# Conceptual expansion neighborhood no. 1\n","# Multiplying alpha by random number in range [-2, 2] for a layer\n","\n","def neighbor_1(weights, alphas):\n","  model_weights = weights.copy()\n","  model_alphas = alphas.copy()\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.divide(model_weights[i], model_alphas[i])\n","\n","  layer_idx = random.randint(0, len(model_weights) - 1)\n","  current_layer = model_weights[layer_idx]\n","  \n","  x = np.random.uniform(-2,2) * np.ones(shape=current_layer.shape)\n","  model_alphas[layer_idx] = np.multiply(model_alphas[layer_idx], x)\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.multiply(model_weights[i], model_alphas[i])\n","\n","  return model_weights, model_alphas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ET9RdTfeMGfu"},"outputs":[],"source":["# Conceptual expansion neighborhood no. 2\n","# Replace a random f with another random f\n","# The weights must contain at least two layers of the same shape. \n","# (To be more efficient for each layer, there should be at least another layer with the same shape.)\n","\n","def neighbor_2(weights, alphas):\n","  model_weights = weights.copy()\n","  model_alphas = alphas.copy()\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.divide(model_weights[i], model_alphas[i])\n","\n","  flag = True\n","  while flag:\n","    source_idx = random.randint(0, len(model_weights) - 1)\n","    idx_choices = [idx for idx in range(len(model_weights)) \n","                  if (idx != source_idx and \n","                      model_weights[idx].shape == model_weights[source_idx].shape)]\n","    if len(idx_choices):\n","      flag = False\n","      \n","  target_idx = np.random.choice(idx_choices)\n","  model_weights[target_idx] = model_weights[source_idx]\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.multiply(model_weights[i], model_alphas[i])\n","  \n","  return model_weights, model_alphas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q290L6NR_9rw"},"outputs":[],"source":["# Conceptual expansion neighborhood no. 3\n","# Add a random f and alpha to a random target f and alpha\n","# The weights must contain at least two layers of the same shape. \n","# (To be more efficient for each layer, there should be at least another layer with the same shape.)\n","\n","def neighbor_3(weights, alphas):\n","  model_weights = weights.copy()\n","  model_alphas = alphas.copy()\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.divide(model_weights[i], model_alphas[i])\n","\n","  flag = True\n","  while flag:\n","    source_idx = random.randint(0, len(model_weights) - 1)\n","    source_layer = model_weights[source_idx]\n","    source_alpha = model_alphas[source_idx]\n","\n","    idx_choices = [idx for idx in range(len(model_weights)) \n","                  if (idx != source_idx and \n","                      model_weights[idx].shape == source_layer.shape)]\n","    if len(idx_choices):\n","      flag = False\n","      \n","  target_idx = np.random.choice(idx_choices)\n","  model_weights[target_idx] += source_layer\n","  model_alphas[target_idx] += source_alpha\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.multiply(model_weights[i], model_alphas[i])\n","\n","  return model_weights, model_alphas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilp4pN16JCsc"},"outputs":[],"source":["# Conceptual expansion neighborhood no. 4\n","# Swap two random f and alpha\n","# The weights must contain at least two layers of the same shape. \n","# (To be more efficient for each layer, there should be at least another layer with the same shape.)\n","\n","def neighbor_4(weights, alphas):\n","  model_weights = weights.copy()\n","  model_alphas = alphas.copy()\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.divide(model_weights[i], model_alphas[i])\n","\n","  flag = True\n","  while flag:\n","    source_idx = random.randint(0, len(model_weights) - 1)\n","    idx_choices = [idx for idx in range(len(model_weights)) \n","                  if (idx != source_idx and \n","                      model_weights[idx].shape == model_weights[source_idx].shape)]\n","    if len(idx_choices):\n","      flag = False\n","      \n","  target_idx = np.random.choice(idx_choices)\n","\n","  # swap\n","  model_weights[source_idx], model_weights[target_idx] = model_weights[target_idx], model_weights[source_idx]\n","  model_alphas[source_idx], model_alphas[target_idx] = model_alphas[target_idx], model_alphas[source_idx]\n","\n","  for i in range(len(model_weights)): \n","    model_weights[i] = np.multiply(model_weights[i], model_alphas[i])\n","\n","  return model_weights, model_alphas"]},{"cell_type":"markdown","metadata":{"id":"92TNIIs2rsRN"},"source":["## MCTS Node Class"]},{"cell_type":"markdown","metadata":{"id":"9Teff9Srr1qa"},"source":["The difference in our code is that we work with different checkpoints.\n","\n","**Caveat:** The memory might become an issue. Might want to use some hacks to not load everything."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkww85YqsjK6"},"outputs":[],"source":["# MCTS Node\n","class MCTSNode:\n","  def __init__(self, idx, ckpt_path, alpha_values=None, fitness_score=None, \n","               parent=None, child_nodes=list()):\n","    self.idx = idx                        # To keep track of nodes\n","    self.ckpt_path = ckpt_path            # Checkpoint path for the model corresponding to the node\n","    # self.f_values = f_values              # List of the weights for each layer\n","    self.alpha_values = alpha_values      # Model alpha values\n","    self.fitness_score = fitness_score    # Absolute model score\n","    self.cummulative_score = None         # Score calculated during the backprop\n","    self.parent = parent                  # Parent node info\n","    self.child_nodes = child_nodes        # List of all childs to the current node\n","\n","    if not fitness_score:\n","      self.set_fitness()\n","\n","    if not alpha_values:\n","      self.alpha_values = list()\n","      for name, shape in tf.train.list_variables(self.ckpt_path):\n","        if name in MODEL_VARIABLES:\n","          self.alpha_values.append(np.ones(shape))\n","  \n","  def add_child(self, child):\n","    self.child_nodes.append(child)\n","  \n","  # str representation of the node is: Model id <index>\n","  def __repr__(self):\n","    return repr('Node id ' + str(self.idx))\n","  \n","  # update cummmulative score\n","  def update_cummulative_score(self, cummulative_score):\n","    self.cummulative_score = cummulative_score\n","\n","  # returns model accuracy on training data (Q: loss vs accuracy)\n","  def set_fitness(self):\n","    # with open(os.path.abspath(log_path), mode='a+') as sys.stdout:\n","    res = music_vae_mcts_train.run(\n","            run_dir=run_dir,\n","            config=config_name,\n","            mode='eval',\n","            hparams='batch_size=1',\n","            cache_dataset=False,\n","            examples_path=train_example_path,\n","            ckpt_path=self.ckpt_path,\n","            log='FATAL',\n","            seed=seed\n","          )\n","\n","    self.fitness_score = res['metrics/accuracy']\n","\n","  def create_neighbor_node(self, id=0):\n","    save_path = os.path.join(run_dir + f'ckpt/ckpt_{id}')\n","    names, vars = checkpoint_to_variable_list(self.ckpt_path) #load source variables\n","    # remove 'global_step' from the variables since we want to keep it unchanged\n","    gs_idx = names.index('global_step')\n","    global_step = vars.pop(gs_idx)\n","    names.pop(gs_idx)\n","\n","    choice = np.random.randint(1, 5)\n","    if choice == 1:\n","      print(\"node generated: neighbor type 1\")\n","      vars, alphas = neighbor_1(vars, self.alpha_values)\n","    elif choice == 2:\n","      print(\"node generated: neighbor type 2\")\n","      vars, alphas = neighbor_2(vars, self.alpha_values)\n","    elif choice == 3:\n","      print(\"node generated: neighbor type 3\")\n","      vars, alphas = neighbor_3(vars, self.alpha_values)\n","    elif choice == 4:\n","      print(\"node generated: neighbor type 4\")\n","      vars, alphas = neighbor_4(vars, self.alpha_values)\n","\n","    # add 'global_step' back in\n","    names.append('global_step')\n","    vars.append(global_step)\n","\n","    variable_list_to_checkpoint(names, vars, save_path)\n","\n","    # create the new node\n","    neighbor_node = MCTSNode(id, save_path, alpha_values=alphas, parent=self, child_nodes = list())\n","    # print(f\"node {neighbor_node} was created as a neighbor to {self}\")\n","    self.add_child(neighbor_node)\n","    print(f\"new noded added to the children of {self} --> {self.child_nodes}\")\n","    del names, vars, alphas\n","    # garbage collect\n","    collected = gc.collect()\n","    print(\"Garbage collector: collected\",\n","          \"%d objects.\" % collected)\n","\n","    return neighbor_node\n","  \n","  def display_tree(self, root):\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"cz15AmXnY13H"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sYtuw99vqqo"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bb-VC4e5mlHo"},"outputs":[],"source":["# helper functions\n","\n","# delete an unwanted tree\n","def delete_tree(root):\n","    if root:\n","      print(f\"Deleting {root} tree ...\")\n","      for child in root.child_nodes:\n","          delete_tree(child)\n","      del root\n","      gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBtpFhZClETe"},"outputs":[],"source":["def explore(rollout_idx, depth, HEAD, best_node, best_fitness, top_models):\n","  explore = True\n","  print(f'Creating a new branch to {HEAD}\\t rollout: {rollout_idx}, depth level: {depth}')\n","  # create a new neighbor from HEAD and with HEAD as its parent\n","  current = HEAD.create_neighbor_node(root_id)\n","\n","\n","  # check against the best node\n","  if current.fitness_score > best_fitness:\n","    best_node = current\n","    best_fitness = current.fitness_score\n","    top_models.pop(0)\n","    top_models.append(copy.copy(best_node))\n","  else:\n","    for i in range(models_to_keep-1 , -1, -1):\n","      if top_models[i]==0 or current.fitness_score > top_models[i].fitness_score:\n","        top_models.insert(i+1, copy.copy(current))\n","        top_models.pop(0)\n","        break\n","\n","\n","\n","  # make the current node, the HEAD node\n","  HEAD = current\n","  # print(f\"Head is {HEAD}\")\n","\n","  print(f'The current node: {HEAD}, fitness: {current.fitness_score} ==> parent node: {HEAD.parent}')\n","  return HEAD, best_node, best_fitness, top_models\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lg3des1tmVcc"},"outputs":[],"source":["def exploit(rollout_idx, depth, HEAD):\n","  print(f'Exploiting nodes at {HEAD} \\t rollout: {rollout_idx}, depth: {depth}')\n","\n","  # pick the child with the best fitness score\n","  best_score = - np.inf\n","  next_node = None\n","  leaf_nodes = list()\n","  \n","  for node in HEAD.child_nodes:\n","    if node.cummulative_score: \n","      if node.cummulative_score > best_score:\n","        best_Score = node.cummulative_score\n","        next_node = node\n","    else: # node is a leaf\n","      leaf_nodes.append(node)\n","\n","  if len(leaf_nodes):\n","    next_node = random.choice(leaf_nodes)\n","    print(f'A random leaf {next_node} has been chosen.')\n","  else:\n","    print(f'There are no leafs. The child with the best cummulative score {next_node} was chosen.')\n","\n","  HEAD = next_node\n","  del leaf_nodes\n","  gc.collect()\n","\n","  return HEAD\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cx7eLGGqvzqC"},"outputs":[],"source":["def update_cummulative_score(HEAD):\n","  tmp_head = HEAD.parent\n","  while tmp_head and tmp_head != root:\n","    print(f'Update {tmp_head} commulative score.')\n","    tmp_head.update_cummulative_score(\n","        tmp_head.fitness_score + \n","        discount_factor * tmp_head.child_nodes[-1].fitness_score\n","    )\n","    tmp_head = tmp_head.parent\n","\n","  del tmp_head"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCt1uLoywzKU"},"outputs":[],"source":["def change_root_to_best(root, best_node):\n","  previous_root = root\n","  root = best_node \n","\n","  if root.parent!= None:\n","    print(20*'*' + \" Deleting previous root tree... \")\n","    root.parent.child_nodes.remove(root)\n","    root.parent = None\n","    delete_tree(previous_root)\n","  else:\n","    print(\"The root is the best node!\")\n","\n","  return root"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7OSJdxRpZnGy"},"outputs":[],"source":["# Setup and variables\n","num_generations = 10 #10\n","no_of_rollouts = 10 #20\n","rollout_length = 5 #10\n","discount_factor = 0.3\n","epsilon = 0.5\n","\n","# setup the root of the MCTS tree\n","root_id = 1\n","root = MCTSNode(idx=1, ckpt_path=mel_2bar_big_ckpt_path)\n","root_fitness = root.fitness_score\n","HEAD = None\n","# all_nodes = [root_node] # To keep track of all of the nodes\n","\n","# setup best node\n","best_node = root\n","best_fitness = root.fitness_score # represents loss\n","models_to_keep = 10\n","top_models = models_to_keep * [0]\n","\n","# limit the number of models created\n","limit = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZX4e8jwHqP2"},"outputs":[],"source":["best_fitness"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89uItWxRfWRM"},"outputs":[],"source":["# start iterations\n","for gen in range(num_generations):\n","  if root_id == limit:\n","    break\n","  print(33*'=' + f' Generation {gen} ' + 33*'=')\n","  for rollout_idx in range(no_of_rollouts):\n","    if root_id == limit:\n","      break\n","    print(f'Rollout no {rollout_idx} ---> best node: {best_node} with fitness {best_fitness}. root={root}')\n","    HEAD = root         # used to traverse the tree\n","    explore_mode = False     # selecting explore/exploit\n","\n","    for depth in range(rollout_length):\n","      if root_id == limit:\n","        break\n","      print(50 * '-')\n","      if gen == 0 and rollout_idx == 0:\n","        # at the very beginning we want to create a branch\n","        explore_mode = True\n","      p = random.uniform(0, 1)\n","      if explore_mode == False and p < epsilon: # exploit\n","        HEAD = exploit(rollout_idx, depth, HEAD)\n","      else: # explore by adding a chain of rollouts / extend to branch to depth length\n","        explore_mode = True\n","        root_id += 1\n","        HEAD, best_node, best_fitness, top_models = explore(rollout_idx, depth, HEAD, best_node, best_fitness, top_models)\n","        gc.collect()\n","\n","    if explore:\n","      update_cummulative_score(HEAD)\n","\n","  # choose the best node as new root\n","  previous_root = root\n","  root = best_node \n","\n","  if root.parent!= None:\n","    print(20*'*' + \" Deleting previous root tree... \")\n","    root.parent.child_nodes.remove(root)\n","    root.parent = None\n","    delete_tree(previous_root)\n","  else:\n","    print(\"The root is the best node!\")\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7typeyIyFIZt"},"outputs":[],"source":["print(top_models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrc9QoHn-bU9"},"outputs":[],"source":["for m in top_models:\n","  print(m.idx, m.fitness_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJaDPByraG2n"},"outputs":[],"source":["best_fitness"]},{"cell_type":"markdown","metadata":{"id":"ZYd2nu36tG_E"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TImCOYiL-onK"},"outputs":[],"source":["for m in top_models:\n","  res = music_vae_mcts_train.run(\n","            run_dir=run_dir,\n","            config=config_name,\n","            mode='eval',\n","            hparams='batch_size=1',\n","            cache_dataset=False,\n","            examples_path=eval_example_path,\n","            ckpt_path=m.ckpt_path,\n","            log='FATAL',\n","            seed=seed\n","          )\n","  accuracy = res['metrics/accuracy']\n","  print(f\"Model: {m} \\t train accuracy: {(m.fitness_score * 100):5.3} \\t test accuracy: {(accuracy * 100):5.3}\")\n"]},{"cell_type":"markdown","metadata":{"id":"TbWZijRcYqDP"},"source":["# Generate Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSxuBYF7Y56F"},"outputs":[],"source":["gen_node = top_models[6]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQHl_dLBYtIH"},"outputs":[],"source":["path = os.path.abspath(gen_node.ckpt_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kVdzxeQHaW-H"},"outputs":[],"source":["path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bi9CwEhyUFkG"},"outputs":[],"source":["./data/mcts/CE_MCTS-23-02-15-02-37/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbBbXou8QrYh"},"outputs":[],"source":["path = '/content/drive/MyDrive/Magenta/magenta/data/mcts/CE_MCTS-23-02-15-02-37/ckpt/ckpt_68'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6E9icdjeaOv"},"outputs":[],"source":["config=configs.CONFIG_MAP[config_name]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_yTBN-F_eUJ"},"outputs":[],"source":["model = TrainedModel(config=config,\n","                     batch_size=4,\n","                     checkpoint_dir_or_path=mel_2bar_big_ckpt_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fkf3z4ilZPHo"},"outputs":[],"source":["#@title Random Samples\n","\n","temperature = 0.96 #@param {type:\"slider\", min:0.01, max:1.5, step:0.01}\n","seqs = model.sample(n=4, length=128, temperature=temperature)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63YeRV7GZV_r"},"outputs":[],"source":["for i in range(4):\n","  download(seqs[i], f\"note_seq_{i}.mid\")"]},{"cell_type":"markdown","metadata":{"id":"ykwdffYAOGaT"},"source":["# Extra Checkpoint Checks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mM7sPyXXkb03"},"outputs":[],"source":["var_name = 'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel'\n","# var_name = 'decoder/output_projection/kernel'\n","\n","checkpoint_path = '/content/drive/MyDrive/Code/cat-mel_2bar_big.ckpt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7whOfumfk4e"},"outputs":[],"source":["Old_ckpt = tf.train.load_checkpoint(checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1m2MTGsWfrWN"},"outputs":[],"source":["import tensorflow as tf\n","tf.reset_default_graph()\n","w1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')\n","w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')\n","saver = tf.train.Saver()\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","saver.save(sess, './data/test/my_test_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0TyHtdWk4qss"},"outputs":[],"source":["print(tf.get_default_session())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hD1dBRxNj0SF"},"outputs":[],"source":["test_ckpt_reader = tf.train.load_checkpoint('./data/test/my_test_model')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m23MEG7lkXgF"},"outputs":[],"source":["tf.train.list_variables('./data/test/my_test_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjOjUGeTkj27"},"outputs":[],"source":["test_ckpt_reader.get_tensor('w1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HfsWP8Ik5BI"},"outputs":[],"source":["test_ckpt_reader.get_tensor('w1_1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WFjqfGjstzD"},"outputs":[],"source":["Old_A = tf.train.load_checkpoint(checkpoint_path).get_tensor(var_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq8ESgv_tGx_"},"outputs":[],"source":["New_A = tf.train.load_checkpoint(run_dir + 'train/model.ckpt-100').get_tensor(var_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZDCRgXHN5Fj"},"outputs":[],"source":["Old_A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNwKIPGhN00A"},"outputs":[],"source":["New_A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmKO4l0WVnjE"},"outputs":[],"source":["(New_A==Old_A).all()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7O2aDkwy9EN"},"outputs":[],"source":["tf.train.list_variables(checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeM-7gsXntq0"},"outputs":[],"source":["from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FfQgroSq2ga"},"outputs":[],"source":["print_tensors_in_checkpoint_file('/content/drive/MyDrive/Magenta/magenta/data/tmp/persian-finetune-11-21-01/train/model.ckpt-500', all_tensors=True, tensor_name='decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NJEITeemzdp"},"outputs":[],"source":["tf.train.load_checkpoint('/content/drive/MyDrive/Code/cat-mel_2bar_big.ckpt').get_variable_to_shape_map()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["ykwdffYAOGaT"],"provenance":[{"file_id":"1sS4UdgbZuA6UZ8TsEhIzjvpWKjUzjZhR","timestamp":1654145223876},{"file_id":"16AX4Vi5OEoC5-cL-xzkFd7RTnU374Npg","timestamp":1654143733819},{"file_id":"10quRLW1a-C_S7ZLdmvayCoFDjoPYKORM","timestamp":1648864879948},{"file_id":"https://github.com/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb","timestamp":1631852135633}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}