{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of TBN.ipynb","provenance":[{"file_id":"https://github.com/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb","timestamp":1631852135633}],"collapsed_sections":["hYaJ6dvF0v7g","R122bwRNbTus"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bhOAxQyU0rhs"},"source":["Copyright 2017 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"hYaJ6dvF0v7g"},"source":["# MusicVAE: A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music.\n","### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n","\n","[MusicVAE](https://g.co/magenta/music-vae) learns a latent space of musical scores, providing different modes\n","of interactive musical creation, including:\n","\n","* Random sampling from the prior distribution.\n","* Interpolation between existing sequences.\n","* Manipulation of existing sequences via attribute vectors.\n","\n","Examples of these interactions can be generated below, and selections can be heard in our\n","[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n","\n","For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n","and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n","decoder, which helps the model learn longer-term structures.\n","\n","We also model the interdependencies between instruments by training multiple\n","decoders on the lowest-level embeddings of the hierarchical decoder.\n","\n","For additional details, check out our [blog post](https://g.co/magenta/music-vae) and [paper](https://goo.gl/magenta/musicvae-paper).\n","___\n","\n","This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."]},{"cell_type":"markdown","metadata":{"id":"R122bwRNbTus"},"source":["# Basic Instructions\n","\n","1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n","2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n","3. Listen to the generated samples.\n","4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"]},{"cell_type":"markdown","metadata":{"id":"ZLfb2a_12wcj"},"source":["# Environment Setup\n","Includes package installation for sequence synthesis. Will take a few minutes.\n"]},{"cell_type":"code","metadata":{"id":"PfRDVhNs3UFx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632502522087,"user_tz":360,"elapsed":73344,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"f3171111-cb33-4c9c-e3f2-62eb9a2412b3"},"source":["#@title Setup Environment\n","#@test {\"output\": \"ignore\"}\n","\n","import glob\n","\n","BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n","\n","print('Installing dependencies...')\n","!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","!pip install -q pyfluidsynth\n","!pip install -qU magenta\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","# This is only needed for the hosted Colab environment.\n","import ctypes.util\n","orig_ctypes_util_find_library = ctypes.util.find_library\n","def proxy_find_library(lib):\n","  if lib == 'fluidsynth':\n","    return 'libfluidsynth.so.1'\n","  else:\n","    return orig_ctypes_util_find_library(lib)\n","ctypes.util.find_library = proxy_find_library\n","\n","\n","print('Importing libraries and defining some helper functions...')\n","from google.colab import files\n","import magenta.music as mm\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel\n","import numpy as np\n","import os\n","import tensorflow.compat.v1 as tf\n","\n","tf.disable_v2_behavior()\n","\n","# Necessary until pyfluidsynth is updated (>1.2.5).\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","def play(note_sequence):\n","  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n","\n","def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","                assert_same_length=True, temperature=0.5,\n","                individual_duration=4.0):\n","  \"\"\"Interpolates between a start and end sequence.\"\"\"\n","  note_sequences = model.interpolate(\n","      start_seq, end_seq,num_steps=num_steps, length=max_length,\n","      temperature=temperature,\n","      assert_same_length=assert_same_length)\n","\n","  print('Start Seq Reconstruction')\n","  play(note_sequences[0])\n","  print('End Seq Reconstruction')\n","  play(note_sequences[-1])\n","  print('Mean Sequence')\n","  play(note_sequences[num_steps // 2])\n","  print('Start -> End Interpolation')\n","  interp_seq = mm.sequences_lib.concatenate_sequences(\n","      note_sequences, [individual_duration] * len(note_sequences))\n","  play(interp_seq)\n","  mm.plot_sequence(interp_seq)\n","  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n","\n","def download(note_sequence, filename):\n","  mm.sequence_proto_to_midi_file(note_sequence, filename)\n","  files.download(filename)\n","\n","print('Done')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing dependencies...\n","Selecting previously unselected package fluid-soundfont-gm.\n","(Reading database ... 155013 files and directories currently installed.)\n","Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n","Unpacking fluid-soundfont-gm (3.1-5.1) ...\n","Selecting previously unselected package libfluidsynth1:amd64.\n","Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n","Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n","Setting up fluid-soundfont-gm (3.1-5.1) ...\n","Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","\u001b[K     |████████████████████████████████| 1.4 MB 7.1 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 72.3 MB/s \n","\u001b[K     |████████████████████████████████| 2.3 MB 36.5 MB/s \n","\u001b[K     |████████████████████████████████| 254 kB 75.1 MB/s \n","\u001b[K     |████████████████████████████████| 3.6 MB 63.2 MB/s \n","\u001b[K     |████████████████████████████████| 69 kB 10.1 MB/s \n","\u001b[K     |████████████████████████████████| 210 kB 68.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 62.5 MB/s \n","\u001b[K     |████████████████████████████████| 87 kB 9.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 62.3 MB/s \n","\u001b[K     |████████████████████████████████| 204 kB 70.7 MB/s \n","\u001b[K     |████████████████████████████████| 5.6 MB 14.9 MB/s \n","\u001b[K     |████████████████████████████████| 20.2 MB 1.7 MB/s \n","\u001b[K     |████████████████████████████████| 981 kB 70.1 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 19.4 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 71.7 MB/s \n","\u001b[K     |████████████████████████████████| 366 kB 79.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 61.4 MB/s \n","\u001b[K     |████████████████████████████████| 79 kB 10.5 MB/s \n","\u001b[K     |████████████████████████████████| 48 kB 6.6 MB/s \n","\u001b[K     |████████████████████████████████| 367 kB 74.4 MB/s \n","\u001b[K     |████████████████████████████████| 251 kB 67.7 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 71.1 MB/s \n","\u001b[K     |████████████████████████████████| 178 kB 75.9 MB/s \n","\u001b[?25h  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Importing libraries and defining some helper functions...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Done\n"]}]},{"cell_type":"code","metadata":{"id":"5_FZshAiN3Es","executionInfo":{"status":"ok","timestamp":1632490103470,"user_tz":360,"elapsed":11,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["import os\n","import re\n","import tarfile\n","import tempfile"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Scy3DTX4B5L0","executionInfo":{"status":"ok","timestamp":1632490744238,"user_tz":360,"elapsed":123,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["from magenta.models.music_vae import data\n","import tf_slim"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzYp74Bn9YFw","executionInfo":{"status":"ok","timestamp":1632490138460,"user_tz":360,"elapsed":34998,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"e99483fc-5a60-405c-814b-01837f9a2115"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBHlK58Z9bT2","executionInfo":{"status":"ok","timestamp":1632490138653,"user_tz":360,"elapsed":199,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"5d6f10f4-d419-4041-831f-0fdcc46668dc"},"source":["%cd /content/drive/MyDrive/Magenta/magenta"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1KPdTL1Qxr1axhsrKGYsHmrgaYhBBxUzi/Magenta/magenta\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZvfVYl7DXjt","executionInfo":{"status":"ok","timestamp":1632490139499,"user_tz":360,"elapsed":848,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"9096d91d-67d0-490b-cd8f-c995fe962d26"},"source":["ls data/checkpoints/"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["cat-mel_2bar_big.tar\n"]}]},{"cell_type":"markdown","metadata":{"id":"moLOftFqBS-0"},"source":["# 2-Bar Melody Model\n","\n","The pre-trained model consists of a single-layer bidirectional LSTM encoder with 2048 nodes in each direction, a 3-layer LSTM decoder with 2048 nodes in each layer, and Z with 512 dimensions. The model was given 0 free bits, and had its beta valued annealed at an exponential rate of 0.99999 from 0 to 0.43 over 200k steps. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. The final accuracy is 0.95 and KL divergence is 58 bits."]},{"cell_type":"markdown","metadata":{"id":"ZnwRuUVs91SI"},"source":["# Create and load model"]},{"cell_type":"code","metadata":{"id":"SgyIKG9f9_IM","executionInfo":{"status":"ok","timestamp":1632491098023,"user_tz":360,"elapsed":239,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["# Parameters\n","config_name = 'cat-mel_2bar_big'\n","checkpoint_dir_or_path= '/content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.tar'\n","batch_size = 512\n","var_name_substitutions = None\n","\n","# train params \n","train_dir = '/content/drive/MyDrive/Magenta/magenta/data/tmp/train-9-24-01/train/'\n","cache_dataset = True\n","tf_file_reader = tf.data.TFRecordDataset\n","train_example_path = '/content/drive/MyDrive/Magenta/magenta/data/tfrecord/Bo_Burnham_train.tfrecord'\n","eval_example_path = '/content/drive/MyDrive/Magenta/magenta/data/tfrecord/Bo_Burnham_eval.tfrecord'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYRo3YIjDlUg","executionInfo":{"status":"ok","timestamp":1632490452942,"user_tz":360,"elapsed":209,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"6a3cdfcd-ebad-451d-cc94-5717fabff142"},"source":["config = configs.CONFIG_MAP[config_name]\n","if tf.gfile.IsDirectory(checkpoint_dir_or_path):\n","  checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir_or_path)\n","else:\n","  checkpoint_path = checkpoint_dir_or_path\n","config.hparams.batch_size = batch_size\n","\n","with tf.Graph().as_default():\n","  model = config.model\n","  model.build(\n","      config.hparams,\n","      config.data_converter.output_depth,\n","      is_training=True\n","  )"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 512, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"]}]},{"cell_type":"code","metadata":{"id":"5AucJbAOIAX0","executionInfo":{"status":"ok","timestamp":1632490463492,"user_tz":360,"elapsed":214,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["# Input placeholders\n","temperature = tf.placeholder(tf.float32, shape=())\n","\n","if config.hparams.z_size:\n","  z_input = tf.placeholder(\n","      tf.float32, shape=[batch_size, config.hparams.z_size]\n","  )\n","else:\n","  z_input = None\n","\n","if config.data_converter.control_depth > 0:\n","  c_input = tf.placeholder(\n","      tf.float32, shape=[None, config.data_converter.control_depth]\n","  )\n","else:\n","  c_input = None\n","\n","inputs = tf.placeholder(\n","    tf.float32,\n","    shape=[batch_size, None, config.data_converter.input_depth]\n",")\n","controls = tf.placeholder(\n","    tf.float32,\n","    shape=[batch_size, None, config.data_converter.control_depth]\n",")\n","inputs_length = tf.placeholder(\n","    tf.int32,\n","    shape=[batch_size] + list(config.data_converter.length_shape)\n",")\n","max_length = tf.placeholder(tf.int32, shape=())"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5T0DFCaIKi62","executionInfo":{"status":"ok","timestamp":1632490466510,"user_tz":360,"elapsed":768,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"627e1ce9-c17b-49f5-d179-3539656293a6"},"source":["# Output placeholders\n","outputs, decoder_results = model.sample(\n","    batch_size,\n","    max_length,\n","    z=z_input,\n","    c_input=c_input,\n","    temperature=temperature\n",")\n","\n","if config.hparams.z_size:\n","  q_z = model.encode(inputs, inputs_length, controls)\n","  mu = q_z.loc\n","  mu = q_z.scale.diag\n","  z = q_z.sample()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n"]}]},{"cell_type":"code","metadata":{"id":"Y77yjv7WNAH-","executionInfo":{"status":"ok","timestamp":1632490468337,"user_tz":360,"elapsed":6,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["var_map = None\n","if var_name_substitutions is not None:\n","  var_map = {}\n","  for v in tf.global_variables():\n","    var_namr = v.name[:-2]  # Strip ':0' suffix\n","    for pattern, substitution in var_name_substitutions:\n","      var_name = re.sub(pattern, substitution, var_name)\n","    if var_name != v.name[:-2]:\n","      tf.logging.info('Renaming `%s` to `%s`.', v.name[:-2], var_name)\n","    var_map[var_name] = v"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxB6AoQ2Ocao","executionInfo":{"status":"ok","timestamp":1632490499924,"user_tz":360,"elapsed":29771,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"b52836f7-0f6b-452d-b1a5-c7a7acd32b92"},"source":[" # Restore graph\n","sess = tf.Session()\n","saver = tf.train.Saver(var_map)\n","if (os.path.exists(checkpoint_path) and\n","    tarfile.is_tarfile(checkpoint_path)):\n","  tf.logging.info('Unbundling checkpoint.')\n","  with tempfile.TemporaryDirectory() as temp_dir:\n","    tar = tarfile.open(checkpoint_path)\n","    tar.extractall(temp_dir)\n","    # Assume only a single checkpoint is in the directory.\n","    for name in tar.getnames():\n","      if name.endswith('.index'):\n","        checkpoint_path = os.path.join(temp_dir, name[0:-6])\n","        break\n","    saver.restore(sess, checkpoint_path)\n","else:\n","  saver.restore(sess, checkpoint_path)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Unbundling checkpoint.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpv35wwzje/cat-mel_2bar_big.ckpt\n"]}]},{"cell_type":"markdown","metadata":{"id":"VxUFsYHJSqZP"},"source":["# Start Training"]},{"cell_type":"code","metadata":{"id":"TKC9frOoA0OV","executionInfo":{"status":"ok","timestamp":1632490500370,"user_tz":360,"elapsed":4,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["def _get_input_tensors(dataset, config):\n","  \"\"\"Get input tensors from dataset.\"\"\"\n","  batch_size = config.hparams.batch_size\n","  iterator = tf.data.make_one_shot_iterator(dataset)\n","  (input_sequence, output_sequence, control_sequence,\n","   sequence_length) = iterator.get_next()\n","  input_sequence.set_shape(\n","      [batch_size, None, config.data_converter.input_depth])\n","  output_sequence.set_shape(\n","      [batch_size, None, config.data_converter.output_depth])\n","  if not config.data_converter.control_depth:\n","    control_sequence = None\n","  else:\n","    control_sequence.set_shape(\n","        [batch_size, None, config.data_converter.control_depth])\n","  sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n","\n","  return {\n","      'input_sequence': input_sequence,\n","      'output_sequence': output_sequence,\n","      'control_sequence': control_sequence,\n","      'sequence_length': sequence_length\n","  }"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qmz2GRX9BNvY","executionInfo":{"status":"ok","timestamp":1632490939213,"user_tz":360,"elapsed":121,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["  def dataset_fn(is_training):\n","    return data.get_dataset(\n","        config,\n","        tf_file_reader=tf_file_reader,\n","        is_training=is_training,\n","        cache_dataset=cache_dataset)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwbQJiNnDHux","executionInfo":{"status":"ok","timestamp":1632491445823,"user_tz":360,"elapsed":130,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["config_update_map = {}\n","config_update_map['train_examples_path'] = train_example_path\n","config_update_map['eval_examples_path'] = eval_example_path\n","\n","config = configs.update_config(config, config_update_map)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"TN3K-ZSzSjl1","executionInfo":{"status":"ok","timestamp":1632490855123,"user_tz":360,"elapsed":483,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["tf.gfile.MakeDirs(train_dir)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":708},"id":"3y4dFLeUCait","executionInfo":{"status":"error","timestamp":1632491664303,"user_tz":360,"elapsed":569,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"37021256-0d62-40e6-96ff-571c61680aac"},"source":["with tf.Graph().as_default():\n","  optimizer = model.train(**_get_input_tensors(dataset_fn(is_training=True), config))"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reading examples from file: /content/drive/MyDrive/Magenta/magenta/data/tfrecord/Bo_Burnham_train.tfrecord\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-ebb1cd23073f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_get_input_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_sequence, output_sequence, sequence_length, control_sequence)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     _, scalars_to_summarize = self._compute_model_loss(\n\u001b[0;32m--> 291\u001b[0;31m         input_sequence, output_sequence, sequence_length, control_sequence)\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py\u001b[0m in \u001b[0;36m_compute_model_loss\u001b[0;34m(self, input_sequence, output_sequence, sequence_length, control_sequence)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# Either encode to get `z`, or do unconditional, decoder-only.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_size\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# vae mode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       \u001b[0mq_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sequence, sequence_length, control_sequence)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0mcontrol_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     mu = tf.layers.dense(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_models.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sequence, sequence_length)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         scope=self._name_or_scope)\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Note we access the outputs (h) from the states since the backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# ouputs are reversed to the input order in the returned outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py\u001b[0m in \u001b[0;36mstack_bidirectional_dynamic_rnn\u001b[0;34m(cells_fw, cells_bw, inputs, initial_states_fw, initial_states_bw, dtype, sequence_length, parallel_iterations, time_major, scope, swap_memory)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             time_major=time_major)\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Concat the outputs to create the new input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mprev_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mbidirectional_dynamic_rnn\u001b[0;34m(cell_fw, cell_bw, inputs, sequence_length, initial_state_fw, initial_state_bw, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    445\u001b[0m           \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m           \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m           scope=fw_scope)\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# Backward direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    892\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2814\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2816\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2296\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2298\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2299\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         expand_composites=True)\n\u001b[1;32m   2222\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2224\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2766\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2767\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2768\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2769\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0mcall_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           skip_conditionals=True)\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[0;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;31m# steps.  This is faster when max_seq_len is equal to the number of unrolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# (which is typical for dynamic_rnn).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;31m# Keras RNN cells only accept state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_attrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    764\u001b[0m                   self._compute_dtype_object):\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m   1331\u001b[0m                                       [-1, cell.state_size])\n\u001b[1;32m   1332\u001b[0m           \u001b[0mcur_state_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0mcur_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m         \u001b[0mnew_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \"\"\"\n\u001b[1;32m   1156\u001b[0m     return self._call_wrapped_cell(\n\u001b[0;32m-> 1157\u001b[0;31m         inputs, state, cell_call_fn=self.cell.__call__, scope=scope)\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_wrapper_impl.py\u001b[0m in \u001b[0;36m_call_wrapped_cell\u001b[0;34m(self, inputs, state, cell_call_fn, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m       inputs = self._dropout(inputs, \"input\", self._recurrent_input_noise,\n\u001b[1;32m    268\u001b[0m                              self._input_keep_prob)\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_should_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_keep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0;31m# Identify which subsets of the state to perform dropout on and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     return tf.layers.Layer.__call__(\n\u001b[0;32m--> 619\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    764\u001b[0m                   self._compute_dtype_object):\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:775 call  *\n        (_, cs, _, _, _, _, h) = _lstm_block_cell(\n    /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:573 _lstm_block_cell  *\n        b=b,\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py:404 wrapper  **\n        return f(**kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_rnn_ops.py:900 lstm_block_cell\n        name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:330 _apply_op_helper\n        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:6174 _get_graph_from_inputs\n        _assert_same_graph(original_graph_element, graph_element)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:6109 _assert_same_graph\n        (item, original_item, graph, original_graph))\n\n    ValueError: Tensor(\"encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel:0\", shape=(2138, 8192), dtype=float32_ref) must be from the same graph as Tensor(\"encoder/cell_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3:0\", shape=(512, 90), dtype=float32) (graphs are <tensorflow.python.framework.ops.Graph object at 0x7f23dc545750> and <tensorflow.python.framework.ops.Graph object at 0x7f22ebe8b410>).\n"]}]},{"cell_type":"code","metadata":{"id":"KKRD5dqLFJ7C","executionInfo":{"status":"ok","timestamp":1632491581306,"user_tz":360,"elapsed":132,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"source":["tf.reset_default_graph()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jM3AESYDFLyW","executionInfo":{"status":"ok","timestamp":1632491590261,"user_tz":360,"elapsed":177,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"a8dbd47a-f206-459c-80ef-0ba262e4a438"},"source":["model"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<magenta.models.music_vae.base_model.MusicVAE at 0x7f23dc5fae90>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"z64xVU_EBCCt"},"source":["optimizer = model.train(**_get_input_tensors(dataset_fn(), config))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7Qmjb0jTY7K"},"source":["def train(train_dir,\n","          config,\n","          dataset_fn,\n","          checkpoints_to_keep=5,\n","          keep_checkpoint_every_n_hours=1,\n","          num_steps=None,\n","          master='',\n","          num_sync_workers=0,\n","          num_ps_tasks=0,\n","          task=0):\n","  print(\"These are the arguments====================================\")\n","  print(train_dir,\n","          config,\n","          dataset_fn,\n","          checkpoints_to_keep,\n","          keep_checkpoint_every_n_hours,\n","          num_steps,\n","          master,\n","          num_sync_workers,\n","          num_ps_tasks,\n","          task)\n","          #100 1 200000  0 0 0\n","  print(\"These are the arguments====================================\")\n","  \"\"\"Train loop.\"\"\"\n","  tf.gfile.MakeDirs(train_dir)\n","  is_chief = (task == 0)\n","  if is_chief:\n","    _trial_summary(\n","        config.hparams, config.train_examples_path or config.tfds_name,\n","        train_dir)\n","  with tf.Graph().as_default():\n","    with tf.device(tf.train.replica_device_setter(\n","        num_ps_tasks, merge_devices=True)):\n","\n","      model = config.model\n","      model.build(config.hparams,\n","                  config.data_converter.output_depth,\n","                  is_training=True)\n","\n","      optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n","\n","      hooks = []\n","      if num_sync_workers:\n","        optimizer = tf.train.SyncReplicasOptimizer(\n","            optimizer,\n","            num_sync_workers)\n","        hooks.append(optimizer.make_session_run_hook(is_chief))\n","\n","      grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n","      global_norm = tf.global_norm(grads)\n","      tf.summary.scalar('global_norm', global_norm)\n","\n","      if config.hparams.clip_mode == 'value':\n","        g = config.hparams.grad_clip\n","        clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n","      elif config.hparams.clip_mode == 'global_norm':\n","        clipped_grads = tf.cond(\n","            global_norm < config.hparams.grad_norm_clip_to_zero,\n","            lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n","                grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n","            lambda: [tf.zeros(tf.shape(g)) for g in grads])\n","      else:\n","        raise ValueError(\n","            'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n","      train_op = optimizer.apply_gradients(\n","          list(zip(clipped_grads, var_list)),\n","          global_step=model.global_step,\n","          name='train_step')\n","\n","      logging_dict = {'global_step': model.global_step,\n","                      'loss': model.loss}\n","\n","      hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n","      if num_steps:\n","        hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n","\n","      scaffold = tf.train.Scaffold(\n","          saver=tf.train.Saver(\n","              max_to_keep=checkpoints_to_keep,\n","              keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours))\n","      tf_slim.training.train(\n","          train_op=train_op,\n","          logdir=train_dir,\n","          scaffold=scaffold,\n","          hooks=hooks,\n","          save_checkpoint_secs=60,\n","          master=master,\n","          is_chief=is_chief)\n","\n","\n","def evaluate(train_dir,\n","             eval_dir,\n","             config,\n","             dataset_fn,\n","             num_batches,\n","             master=''):\n","  \"\"\"Evaluate the model repeatedly.\"\"\"\n","  tf.gfile.MakeDirs(eval_dir)\n","\n","  _trial_summary(\n","      config.hparams, config.eval_examples_path or config.tfds_name, eval_dir)\n","  with tf.Graph().as_default():\n","    model = config.model\n","    model.build(config.hparams,\n","                config.data_converter.output_depth,\n","                is_training=False)\n","\n","    eval_op = model.eval(\n","        **_get_input_tensors(dataset_fn().take(num_batches), config))\n","\n","    hooks = [\n","        tf_slim.evaluation.StopAfterNEvalsHook(num_batches),\n","        tf_slim.evaluation.SummaryAtEndHook(eval_dir)\n","    ]\n","    tf_slim.evaluation.evaluate_repeatedly(\n","        train_dir,\n","        eval_ops=eval_op,\n","        hooks=hooks,\n","        eval_interval_secs=60,\n","        master=master)"],"execution_count":null,"outputs":[]}]}