{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb","timestamp":1631852135633}],"collapsed_sections":["hYaJ6dvF0v7g","R122bwRNbTus"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bhOAxQyU0rhs"},"source":["Copyright 2017 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"hYaJ6dvF0v7g"},"source":["# MusicVAE: A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music.\n","### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n","\n","[MusicVAE](https://g.co/magenta/music-vae) learns a latent space of musical scores, providing different modes\n","of interactive musical creation, including:\n","\n","* Random sampling from the prior distribution.\n","* Interpolation between existing sequences.\n","* Manipulation of existing sequences via attribute vectors.\n","\n","Examples of these interactions can be generated below, and selections can be heard in our\n","[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n","\n","For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n","and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n","decoder, which helps the model learn longer-term structures.\n","\n","We also model the interdependencies between instruments by training multiple\n","decoders on the lowest-level embeddings of the hierarchical decoder.\n","\n","For additional details, check out our [blog post](https://g.co/magenta/music-vae) and [paper](https://goo.gl/magenta/musicvae-paper).\n","___\n","\n","This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."]},{"cell_type":"markdown","metadata":{"id":"R122bwRNbTus"},"source":["# Basic Instructions\n","\n","1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n","2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n","3. Listen to the generated samples.\n","4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"]},{"cell_type":"markdown","metadata":{"id":"ZLfb2a_12wcj"},"source":["# Environment Setup\n","Includes package installation for sequence synthesis. Will take a few minutes.\n"]},{"cell_type":"code","metadata":{"id":"PfRDVhNs3UFx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637952884711,"user_tz":420,"elapsed":62091,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"4552adcc-66cb-4bc4-fcfd-60a3b4219d05"},"source":["#@title Setup Environment\n","#@test {\"output\": \"ignore\"}\n","\n","import glob\n","\n","BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n","\n","print('Installing dependencies...')\n","!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","!pip install -q pyfluidsynth\n","!pip install -qU magenta\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","# This is only needed for the hosted Colab environment.\n","import ctypes.util\n","orig_ctypes_util_find_library = ctypes.util.find_library\n","def proxy_find_library(lib):\n","  if lib == 'fluidsynth':\n","    return 'libfluidsynth.so.1'\n","  else:\n","    return orig_ctypes_util_find_library(lib)\n","ctypes.util.find_library = proxy_find_library\n","\n","\n","print('Importing libraries and defining some helper functions...')\n","from google.colab import files\n","import magenta.music as mm\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel\n","import numpy as np\n","import os\n","import tensorflow.compat.v1 as tf\n","\n","tf.disable_v2_behavior()\n","# tf.enable_eager_execution()\n","\n","# Necessary until pyfluidsynth is updated (>1.2.5).\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","def play(note_sequence):\n","  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n","\n","def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","                assert_same_length=True, temperature=0.5,\n","                individual_duration=4.0):\n","  \"\"\"Interpolates between a start and end sequence.\"\"\"\n","  note_sequences = model.interpolate(\n","      start_seq, end_seq,num_steps=num_steps, length=max_length,\n","      temperature=temperature,\n","      assert_same_length=assert_same_length)\n","\n","  print('Start Seq Reconstruction')\n","  play(note_sequences[0])\n","  print('End Seq Reconstruction')\n","  play(note_sequences[-1])\n","  print('Mean Sequence')\n","  play(note_sequences[num_steps // 2])\n","  print('Start -> End Interpolation')\n","  interp_seq = mm.sequences_lib.concatenate_sequences(\n","      note_sequences, [individual_duration] * len(note_sequences))\n","  play(interp_seq)\n","  mm.plot_sequence(interp_seq)\n","  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n","\n","def download(note_sequence, filename):\n","  mm.sequence_proto_to_midi_file(note_sequence, filename)\n","  files.download(filename)\n","\n","print('Done')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing dependencies...\n","Selecting previously unselected package fluid-soundfont-gm.\n","(Reading database ... 155222 files and directories currently installed.)\n","Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n","Unpacking fluid-soundfont-gm (3.1-5.1) ...\n","Selecting previously unselected package libfluidsynth1:amd64.\n","Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n","Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n","Setting up fluid-soundfont-gm (3.1-5.1) ...\n","Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","\u001b[K     |████████████████████████████████| 1.4 MB 13.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 60.0 MB/s \n","\u001b[K     |████████████████████████████████| 3.6 MB 54.7 MB/s \n","\u001b[K     |████████████████████████████████| 254 kB 61.2 MB/s \n","\u001b[K     |████████████████████████████████| 204 kB 71.5 MB/s \n","\u001b[K     |████████████████████████████████| 210 kB 56.9 MB/s \n","\u001b[K     |████████████████████████████████| 87 kB 8.4 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 58.2 MB/s \n","\u001b[K     |████████████████████████████████| 2.3 MB 58.3 MB/s \n","\u001b[K     |████████████████████████████████| 69 kB 9.4 MB/s \n","\u001b[K     |████████████████████████████████| 5.6 MB 23.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 44.6 MB/s \n","\u001b[K     |████████████████████████████████| 20.2 MB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 367 kB 63.2 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 56.8 MB/s \n","\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n","\u001b[K     |████████████████████████████████| 48 kB 6.2 MB/s \n","\u001b[K     |████████████████████████████████| 366 kB 65.9 MB/s \n","\u001b[K     |████████████████████████████████| 981 kB 31.3 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 52.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 53.8 MB/s \n","\u001b[K     |████████████████████████████████| 251 kB 68.7 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 71.0 MB/s \n","\u001b[K     |████████████████████████████████| 178 kB 82.1 MB/s \n","\u001b[?25h  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Importing libraries and defining some helper functions...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Done\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxTwZMnQy6PI","executionInfo":{"status":"ok","timestamp":1637953000609,"user_tz":420,"elapsed":25787,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"e0242d27-2e9b-4e32-9af2-f0765aba71da"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmBQBrs3zCQ1","executionInfo":{"status":"ok","timestamp":1637953155864,"user_tz":420,"elapsed":987,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"9302322d-e032-4848-ab76-71d4a4e85e89"},"source":["%cd /content/drive/MyDrive/Thesis/Code/Magenta/magenta/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta\n"]}]},{"cell_type":"code","metadata":{"id":"09ohU4wczID4"},"source":["import datetime\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"moLOftFqBS-0"},"source":["# 2-Bar Melody Model\n","\n","The pre-trained model consists of a single-layer bidirectional LSTM encoder with 2048 nodes in each direction, a 3-layer LSTM decoder with 2048 nodes in each layer, and Z with 512 dimensions. The model was given 0 free bits, and had its beta valued annealed at an exponential rate of 0.99999 from 0 to 0.43 over 200k steps. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. The final accuracy is 0.95 and KL divergence is 58 bits."]},{"cell_type":"code","metadata":{"id":"2XCPjwd6BVtm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637942368173,"user_tz":420,"elapsed":6233,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"a518c46a-ab95-4773-896e-7bc7a5163f7e"},"source":["#@title Load the pre-trained model.\n","mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n","mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n"]}]},{"cell_type":"markdown","metadata":{"id":"wM6gOe6X3hWB"},"source":["## Generate Samples"]},{"cell_type":"code","metadata":{"id":"RwXUA74cNkh0","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"ok","timestamp":1635524271337,"user_tz":360,"elapsed":2697,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"ae65c209-1b4b-41a6-c4ba-f1ad9e806786"},"source":["#@title Generate 4 samples from the prior.\n","temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","mel_2_samples = mel_2bar.sample(n=4, length=32, temperature=temperature)\n","for ns in mel_2_samples:\n","  play(ns)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div id=\"id_2\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_3\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_4\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_5\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ysPpEgdwm_D","executionInfo":{"status":"ok","timestamp":1634231138037,"user_tz":360,"elapsed":300,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"61dbfc8b-bfcf-4d7d-87df-8795f941f386"},"source":["type(mel_2_samples)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPeTMWzhxExr","executionInfo":{"status":"ok","timestamp":1634231177585,"user_tz":360,"elapsed":385,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"aa4b7294-b215-4dd9-966d-26ef85512678"},"source":["type(mel_2_samples[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["note_seq.protobuf.music_pb2.NoteSequence"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"MLg9dQ2D1Xpu","cellView":"form"},"source":["#@title Optionally download samples.\n","for i, ns in enumerate(mel_2_samples):\n","  download(ns, 'mel_2bar_sample_%d.mid' % i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lntpoXwH9QW"},"source":["# Fine-tuned 2-Bar Melody Model\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_01iDaATlB7","executionInfo":{"status":"ok","timestamp":1635495894572,"user_tz":360,"elapsed":36835,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"1853b6f4-234c-4bdc-dc5c-221c0a3642d5"},"source":["# !tar -cvf ./data/checkpoints/train-10-26-03-finetune-1000.ckpt ./data/tmp/train-10-26-03-finetune/model.ckpt-1000.*"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./data/tmp/train-10-26-03-finetune/model.ckpt-1000.data-00000-of-00001\n","./data/tmp/train-10-26-03-finetune/model.ckpt-1000.index\n","./data/tmp/train-10-26-03-finetune/model.ckpt-1000.meta\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qzevd33IBUn","executionInfo":{"status":"ok","timestamp":1637355150208,"user_tz":420,"elapsed":26654,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"e8784a27-235f-4fbd-f875-09fe77feb804"},"source":["mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n","mel_2bar_finetune = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path = './data/checkpoints/train-10-26-03-finetune-1000.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Unbundling checkpoint.\n","INFO:tensorflow:Restoring parameters from /tmp/tmp35birp51/./data/tmp/train-10-26-03-finetune/model.ckpt-1000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RcbuYEcfeI5","executionInfo":{"status":"ok","timestamp":1637347158132,"user_tz":420,"elapsed":18333,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"62d12845-d958-490f-9a5e-c4b0beda8939"},"source":["!python magenta/models/music_vae/music_vae_train_checkpoint.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/Horror_eval/ \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Horror.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=15 \\\n","--cache_dataset=False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","INFO:tensorflow:Counting examples in ./data/tfrecord/Horror.tfrecord.\n","I1119 18:39:08.710342 140547612485504 data.py:1682] Counting examples in ./data/tfrecord/Horror.tfrecord.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","W1119 18:39:08.710736 140547612485504 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","INFO:tensorflow:Total examples: 55\n","I1119 18:39:08.961197 140547612485504 data.py:1700] Total examples: 55\n","=======================================\n","Batch size =  15\n","num_batches =  3\n","=======================================\n","2021-11-19 18:39:09.686119: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 15, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","I1119 18:39:09.718082 140547612485504 base_model.py:152] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 15, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I1119 18:39:09.723296 140547612485504 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1119 18:39:09.735431 140547612485504 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1119 18:39:09.745571 140547612485504 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I1119 18:39:09.746026 140547612485504 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","W1119 18:39:09.746197 140547612485504 lstm_utils.py:139] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1119 18:39:09.746386 140547612485504 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1119 18:39:09.774765 140547612485504 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Horror.tfrecord\n","I1119 18:39:09.775268 140547612485504 data.py:1812] Reading examples from file: ./data/tfrecord/Horror.tfrecord\n","DEBUG:tensorflow:next element\n","I1119 18:39:09.943169 140547612485504 music_vae_train_checkpoint.py:119] next element\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W1119 18:39:09.957947 140547612485504 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W1119 18:39:09.958297 140547612485504 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W1119 18:39:10.420700 140547612485504 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1119 18:39:10.916346 140547612485504 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","INFO:tensorflow:Starting evaluation at 2021-11-19T18:39:11\n","I1119 18:39:11.192687 140547612485504 evaluation.py:255] Starting evaluation at 2021-11-19T18:39:11\n","INFO:tensorflow:Graph was finalized.\n","I1119 18:39:11.308953 140547612485504 monitored_session.py:247] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","I1119 18:39:11.384433 140547612485504 saver.py:1399] Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","INFO:tensorflow:Running local_init_op.\n","I1119 18:39:15.657829 140547612485504 session_manager.py:531] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1119 18:39:15.691393 140547612485504 session_manager.py:534] Done running local_init_op.\n","INFO:tensorflow:Evaluation [1/1]\n","I1119 18:39:17.982145 140547612485504 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Evaluation [1/3]\n","I1119 18:39:17.982413 140547612485504 evaluation.py:167] Evaluation [1/3]\n","INFO:tensorflow:Inference Time : 6.88485s\n","I1119 18:39:18.077802 140547612485504 evaluation.py:273] Inference Time : 6.88485s\n","INFO:tensorflow:Finished evaluation at 2021-11-19-18:39:18\n","I1119 18:39:18.078040 140547612485504 evaluation.py:276] Finished evaluation at 2021-11-19-18:39:18\n"]}]},{"cell_type":"code","metadata":{"id":"dphBiUiLfyjt"},"source":["%tensorboard --logdir ./data/tmp/Horror_eval/eval/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0FwXRsugIUc","executionInfo":{"status":"ok","timestamp":1649306825532,"user_tz":360,"elapsed":9,"user":{"displayName":"Anahita Doosti Sanjani","userId":"11525648660123849199"}},"outputId":"c9954625-b171-4f06-f785-70324f9b3b67"},"source":["!python magenta/models/music_vae/music_vae_train_checkpoint.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/Video_game_eval/ \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Video_game.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=3 \\\n","--cache_dataset=False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file 'magenta/models/music_vae/music_vae_train_checkpoint.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"giIHQHV2gUpm"},"source":["%tensorboard --logdir ./data/tmp/Video_game_eval/eval/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-F2NCYL8ghNe","executionInfo":{"status":"ok","timestamp":1637953339278,"user_tz":420,"elapsed":16126,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"8297d925-2f1f-47cc-c627-d31f946713e5"},"source":["!python magenta/models/music_vae/music_vae_train_checkpoint.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/Persian2_eval \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Persian2_eval.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=2 \\\n","--cache_dataset=False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","INFO:tensorflow:Counting examples in ./data/tfrecord/Persian2_eval.tfrecord.\n","I1126 19:02:06.715785 140408579069824 data.py:1682] Counting examples in ./data/tfrecord/Persian2_eval.tfrecord.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","W1126 19:02:06.716178 140408579069824 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","INFO:tensorflow:Total examples: 5\n","I1126 19:02:06.773588 140408579069824 data.py:1700] Total examples: 5\n","=======================================\n","Batch size =  2\n","num_batches =  2\n","=======================================\n","2021-11-26 19:02:07.327743: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 2, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","I1126 19:02:07.346711 140408579069824 base_model.py:152] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 2, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I1126 19:02:07.351378 140408579069824 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1126 19:02:07.362133 140408579069824 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1126 19:02:07.370547 140408579069824 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I1126 19:02:07.370929 140408579069824 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","W1126 19:02:07.371052 140408579069824 lstm_utils.py:139] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1126 19:02:07.371189 140408579069824 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1126 19:02:07.394880 140408579069824 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Persian2_eval.tfrecord\n","I1126 19:02:07.395274 140408579069824 data.py:1812] Reading examples from file: ./data/tfrecord/Persian2_eval.tfrecord\n","DEBUG:tensorflow:next element\n","I1126 19:02:07.519552 140408579069824 music_vae_train_checkpoint.py:119] next element\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W1126 19:02:07.530333 140408579069824 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W1126 19:02:07.530636 140408579069824 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W1126 19:02:07.880167 140408579069824 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1126 19:02:08.229323 140408579069824 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","INFO:tensorflow:Starting evaluation at 2021-11-26T19:02:08\n","I1126 19:02:08.336253 140408579069824 evaluation.py:255] Starting evaluation at 2021-11-26T19:02:08\n","INFO:tensorflow:Graph was finalized.\n","I1126 19:02:08.405260 140408579069824 monitored_session.py:247] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","I1126 19:02:08.530301 140408579069824 saver.py:1399] Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","INFO:tensorflow:Running local_init_op.\n","I1126 19:02:14.303462 140408579069824 session_manager.py:531] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1126 19:02:14.324518 140408579069824 session_manager.py:534] Done running local_init_op.\n","INFO:tensorflow:Evaluation [1/1]\n","I1126 19:02:16.097843 140408579069824 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Evaluation [1/2]\n","I1126 19:02:16.098069 140408579069824 evaluation.py:167] Evaluation [1/2]\n","INFO:tensorflow:Inference Time : 8.91642s\n","I1126 19:02:17.252877 140408579069824 evaluation.py:273] Inference Time : 8.91642s\n","INFO:tensorflow:Finished evaluation at 2021-11-26-19:02:17\n","I1126 19:02:17.253117 140408579069824 evaluation.py:276] Finished evaluation at 2021-11-26-19:02:17\n"]}]},{"cell_type":"code","metadata":{"id":"U_xAH5wO81SQ"},"source":["!kill 2391"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-ZM0_rvgwyR"},"source":["%tensorboard --logdir ./data/tmp/Persian2_eval/eval/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"musouo2ng7OY","executionInfo":{"status":"ok","timestamp":1637352995683,"user_tz":420,"elapsed":13899,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"795ae2b3-c174-48a6-ebd1-2fa659eebfc3"},"source":["!python magenta/models/music_vae/music_vae_train_checkpoint.py \\\n","--config=cat-mel_2bar_big \\\n","--run_dir=./data/tmp/Pop_eval/ \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Pop.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=3 \\\n","--cache_dataset=False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n","Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n","  from numba.decorators import jit as optional_jit\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","INFO:tensorflow:Counting examples in ./data/tfrecord/Pop.tfrecord.\n","I1119 20:16:29.130543 140218699954048 data.py:1682] Counting examples in ./data/tfrecord/Pop.tfrecord.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","W1119 20:16:29.130940 140218699954048 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/data.py:1683: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","INFO:tensorflow:Total examples: 49\n","I1119 20:16:29.756917 140218699954048 data.py:1700] Total examples: 49\n","=======================================\n","Batch size =  3\n","num_batches =  16\n","=======================================\n","2021-11-19 20:16:30.477837: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 3, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","I1119 20:16:30.504036 140218699954048 base_model.py:152] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 3, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I1119 20:16:30.509149 140218699954048 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1119 20:16:30.520996 140218699954048 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1119 20:16:30.530343 140218699954048 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I1119 20:16:30.530787 140218699954048 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","W1119 20:16:30.530945 140218699954048 lstm_utils.py:139] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1119 20:16:30.531167 140218699954048 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W1119 20:16:30.560437 140218699954048 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Pop.tfrecord\n","I1119 20:16:30.561030 140218699954048 data.py:1812] Reading examples from file: ./data/tfrecord/Pop.tfrecord\n","DEBUG:tensorflow:next element\n","I1119 20:16:30.732320 140218699954048 music_vae_train_checkpoint.py:119] next element\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W1119 20:16:30.749711 140218699954048 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W1119 20:16:30.750336 140218699954048 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W1119 20:16:31.242841 140218699954048 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1119 20:16:31.710432 140218699954048 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","INFO:tensorflow:Starting evaluation at 2021-11-19T20:16:31\n","I1119 20:16:31.874145 140218699954048 evaluation.py:255] Starting evaluation at 2021-11-19T20:16:31\n","INFO:tensorflow:Graph was finalized.\n","I1119 20:16:31.972372 140218699954048 monitored_session.py:247] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","I1119 20:16:32.047225 140218699954048 saver.py:1399] Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n","INFO:tensorflow:Running local_init_op.\n","I1119 20:16:35.132816 140218699954048 session_manager.py:531] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1119 20:16:35.160453 140218699954048 session_manager.py:534] Done running local_init_op.\n","INFO:tensorflow:Evaluation [1/1]\n","I1119 20:16:36.155204 140218699954048 evaluation.py:167] Evaluation [1/1]\n","INFO:tensorflow:Evaluation [1/16]\n","I1119 20:16:36.155507 140218699954048 evaluation.py:167] Evaluation [1/16]\n","INFO:tensorflow:Inference Time : 4.42452s\n","I1119 20:16:36.298877 140218699954048 evaluation.py:273] Inference Time : 4.42452s\n","INFO:tensorflow:Finished evaluation at 2021-11-19-20:16:36\n","I1119 20:16:36.299096 140218699954048 evaluation.py:276] Finished evaluation at 2021-11-19-20:16:36\n"]}]},{"cell_type":"code","metadata":{"id":"UTpGviKX18uX"},"source":["%tensorboard --logdir ./data/tmp/Pop_eval/eval/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-bT0ulxO-lX"},"source":["# Data Setup (Horror)"]},{"cell_type":"code","metadata":{"id":"_ndFE5GYWhfb"},"source":["tf.enable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PK8ify-aPQv3"},"source":["from magenta.models.music_vae import data\n","from magenta.models.music_vae import data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v76TkHL-PEof"},"source":["data_path = './data/tfrecord/Bo_Burnham_train.tfrecord'\n","tf_file_reader = tf.data.TFRecordDataset\n","file_reader = tf.python_io.tf_record_iterator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXSzZcOURO2Q"},"source":["mel_2bar_config = configs.update_config(mel_2bar_config, dict(eval_examples_path=data_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHvrCOmUT_mA"},"source":["mel_2bar_config.hparams.batch_size = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bMGRDM-8QKgw","executionInfo":{"status":"ok","timestamp":1637355232226,"user_tz":420,"elapsed":194,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"ce578ea6-c202-4ccf-b57c-270baa1d5ca7"},"source":["dataset = data.get_dataset(\n","    mel_2bar_config,\n","    tf_file_reader=tf_file_reader,\n","    is_training=False,\n","    cache_dataset=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_train.tfrecord\n"]}]},{"cell_type":"code","metadata":{"id":"_w2hY2uTTH8d"},"source":["dataset = dataset.take(-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8qegDjNbFAo","executionInfo":{"status":"ok","timestamp":1637355235682,"user_tz":420,"elapsed":6,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"872474f8-194a-442f-fc04-765c52961e37"},"source":["dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset shapes: ((1, ?, 90), (1, ?, 90), (1, ?, 0), (1,)), types: (tf.bool, tf.bool, tf.bool, tf.int32)>"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"C9Cm_GLTURip"},"source":["batch_size = mel_2bar_config.hparams.batch_size\n","iterator = tf.data.make_one_shot_iterator(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rM2Y6m_62bvv"},"source":["input_seqs, output_seqs, control_seqs, sequence_lengths = [], [], [], []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScGmNo6I2nwP"},"source":["for i, o, c, sl in iterator:\n","  input_seqs.append(mel_2bar_config.data_converter.from_tensors(i)[0])\n","  # input_seqs.append(i)\n","  sequence_lengths.append(sl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtBeL4sy75Cv","executionInfo":{"status":"ok","timestamp":1637355240929,"user_tz":420,"elapsed":217,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"32ff398a-ada0-4130-e750-0702ad45cb20"},"source":["len(input_seqs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["39"]},"metadata":{},"execution_count":141}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wwFoqWt4t41k","executionInfo":{"status":"ok","timestamp":1637355243277,"user_tz":420,"elapsed":1409,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"2d191abc-636d-408b-84fe-017dc829864d"},"source":["input_seqs_new = list()\n","for i in input_seqs:\n","  try:\n","    a, b, c = mel_2bar.encode([i])\n","  except:\n","    print(\"invalid\")\n","  else:\n","    input_seqs_new.append(i)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["invalid\n","invalid\n","invalid\n"]}]},{"cell_type":"markdown","metadata":{"id":"A1hy_Jrf8CVK"},"source":["# Reconstruction"]},{"cell_type":"code","metadata":{"id":"SobeqCss8IqC"},"source":["# plain model\n","z1, mu1, sigma1 = mel_2bar.encode(input_seqs_new)\n","z1 = [z1[i] for i in range(z1.shape[0])]\n","output_seqs1 = mel_2bar.decode(z1, length=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5hleuQH-SQI"},"source":["# fine-tuned model\n","z2, mu2, sigma2 = mel_2bar_finetune.encode(input_seqs_new)\n","z2 = [z2[i] for i in range(z2.shape[0])]\n","output_seqs2 = mel_2bar_finetune.decode(z2, length=32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oIrM_m2n_xQs"},"source":["# Comparison"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ae2cAbN-_7uN","executionInfo":{"status":"ok","timestamp":1637355290301,"user_tz":420,"elapsed":38299,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"fc4f2aa7-0567-4d8a-992e-ce550b21864f"},"source":["for i in range(0, len(input_seqs_new)):\n","  print(\"Sample {}: \".format(i+1))\n","  play(input_seqs_new[i])\n","  print(\"Plain: \")\n","  play(output_seqs1[i])\n","  print(\"Fine-tune: \")\n","  play(output_seqs2[i])\n","  print(\"----------------------------------\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_558\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_559\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_560\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 2: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_561\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_562\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_563\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 3: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_564\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_565\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_566\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 4: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_567\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_568\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_569\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 5: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_570\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_571\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_572\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 6: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_573\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_574\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_575\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 7: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_576\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_577\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_578\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 8: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_579\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_580\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_581\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 9: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_582\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_583\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_584\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 10: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_585\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_586\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_587\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 11: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_588\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_589\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_590\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 12: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_591\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_592\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_593\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 13: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_594\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_595\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_596\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 14: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_597\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_598\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_599\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 15: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_600\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_601\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_602\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 16: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_603\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_604\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_605\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 17: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_606\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_607\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_608\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 18: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_609\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_610\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_611\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 19: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_612\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_613\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_614\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 20: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_615\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_616\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_617\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 21: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_618\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_619\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_620\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 22: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_621\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_622\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_623\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 23: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_624\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_625\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_626\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 24: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_627\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_628\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_629\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 25: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_630\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_631\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_632\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 26: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_633\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_634\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_635\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 27: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_636\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_637\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_638\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 28: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_639\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_640\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_641\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 29: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_642\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_643\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_644\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 30: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_645\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_646\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_647\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 31: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_648\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_649\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_650\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 32: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_651\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_652\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_653\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 33: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_654\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_655\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_656\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 34: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_657\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_658\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_659\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 35: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_660\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_661\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_662\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Sample 36: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_663\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Plain: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_664\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tune: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_665\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"EKYW2xv7Ckqo"},"source":["# Sampling"]},{"cell_type":"markdown","metadata":{"id":"LgMZy2CZCwYa"},"source":["## plain"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"pSU-QyR5Cm2N","executionInfo":{"status":"ok","timestamp":1635528296644,"user_tz":360,"elapsed":4495,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"1da010b1-72bd-49f1-924a-03a6f5a66b0d"},"source":["#@title Generate 4 samples from the prior.\n","temperature = 1 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","mel_2_samples = mel_2bar.sample(n=4, length=128, temperature=temperature)\n","for ns in mel_2_samples:\n","  play(ns)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div id=\"id_226\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_227\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_228\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_229\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"kVEag3kuC0L3"},"source":["## finetune"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"PQBgUwYuCt0u","executionInfo":{"status":"ok","timestamp":1635528299536,"user_tz":360,"elapsed":52,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"e06701ea-86b0-4315-a954-57b5dd4102d8"},"source":["#@title Generate 4 samples from the prior.\n","temperature = 1 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","mel_2_samples_finetune = mel_2bar_finetune.sample(n=4, length=128, temperature=temperature)\n","for ns in mel_2_samples_finetune:\n","  play(ns)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div id=\"id_230\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_231\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_232\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id=\"id_233\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]}]}