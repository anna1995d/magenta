{"cells":[{"cell_type":"markdown","metadata":{"id":"bhOAxQyU0rhs"},"source":["Copyright 2017 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"hYaJ6dvF0v7g"},"source":["# MusicVAE: A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music.\n","### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n","\n","[MusicVAE](https://g.co/magenta/music-vae) learns a latent space of musical scores, providing different modes\n","of interactive musical creation, including:\n","\n","* Random sampling from the prior distribution.\n","* Interpolation between existing sequences.\n","* Manipulation of existing sequences via attribute vectors.\n","\n","Examples of these interactions can be generated below, and selections can be heard in our\n","[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n","\n","For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n","and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n","decoder, which helps the model learn longer-term structures.\n","\n","We also model the interdependencies between instruments by training multiple\n","decoders on the lowest-level embeddings of the hierarchical decoder.\n","\n","For additional details, check out our [blog post](https://g.co/magenta/music-vae) and [paper](https://goo.gl/magenta/musicvae-paper).\n","___\n","\n","This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."]},{"cell_type":"markdown","metadata":{"id":"R122bwRNbTus"},"source":["# Basic Instructions\n","\n","1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n","2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n","3. Listen to the generated samples.\n","4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"]},{"cell_type":"markdown","metadata":{"id":"ZLfb2a_12wcj"},"source":["# Environment Setup\n","Includes package installation for sequence synthesis. Will take a few minutes.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32129,"status":"ok","timestamp":1644240220623,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"JxTwZMnQy6PI","outputId":"93c64a2a-8493-40ca-c7b8-b44d0a803aae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#@title Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":732,"status":"ok","timestamp":1644240221349,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"FmBQBrs3zCQ1","outputId":"0e2f97de-ea30-4bf9-dd62-cea628e07c78"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta\n"]}],"source":["%cd /content/drive/MyDrive/Thesis/Code/Magenta/magenta/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51939,"status":"ok","timestamp":1644240273285,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"PtFszgD_THiQ","outputId":"cca99991-82af-4e11-f08e-1828ef1a5995"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing dependencies...\n","Selecting previously unselected package fluid-soundfont-gm.\n","(Reading database ... 155113 files and directories currently installed.)\n","Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n","Unpacking fluid-soundfont-gm (3.1-5.1) ...\n","Selecting previously unselected package libfluidsynth1:amd64.\n","Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n","Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n","Setting up fluid-soundfont-gm (3.1-5.1) ...\n","Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Collecting tensor2tensor\n","  Downloading tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.19.5)\n","Collecting tensorflow-probability==0.7.0\n","  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 60.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.0.1)\n","Collecting gevent\n","  Downloading gevent-21.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 60.5 MB/s \n","\u001b[?25hCollecting mesh-tensorflow\n","  Downloading mesh_tensorflow-0.1.19-py3-none-any.whl (366 kB)\n","\u001b[K     |████████████████████████████████| 366 kB 68.6 MB/s \n","\u001b[?25hCollecting gunicorn\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.4.1)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 51.7 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.0.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.62.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (3.1.0)\n","Collecting kfac\n","  Downloading kfac-0.2.3-py2.py3-none-any.whl (191 kB)\n","\u001b[K     |████████████████████████████████| 191 kB 65.8 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.16.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.2.30)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.3)\n","Collecting pypng\n","  Downloading pypng-0.0.21-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.12.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (2.23.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.5.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (7.1.2)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 66.8 MB/s \n","\u001b[?25hRequirement already satisfied: dopamine-rl in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.0.5)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.1.4)\n","Collecting tensorflow-gan\n","  Downloading tensorflow_gan-2.1.0-py2.py3-none-any.whl (367 kB)\n","\u001b[K     |████████████████████████████████| 367 kB 71.4 MB/s \n","\u001b[?25hCollecting bz2file\n","  Downloading bz2file-0.98.tar.gz (11 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.7.1)\n","Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (4.4.2)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor) (1.5.0)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (1.1.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->tensor2tensor) (2.0.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent->tensor2tensor) (57.4.0)\n","Requirement already satisfied: greenlet<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from gevent->tensor2tensor) (1.1.2)\n","Collecting zope.interface\n","  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 70.3 MB/s \n","\u001b[?25hCollecting zope.event\n","  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.0.4)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (3.0.1)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.35.0)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.26.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client->tensor2tensor) (21.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client->tensor2tensor) (3.17.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client->tensor2tensor) (1.54.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client->tensor2tensor) (2018.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client->tensor2tensor) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client->tensor2tensor) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client->tensor2tensor) (4.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client->tensor2tensor) (3.0.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client->tensor2tensor) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (3.0.4)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->tensor2tensor) (1.5.2)\n","Collecting kfac\n","  Downloading kfac-0.2.2-py2.py3-none-any.whl (191 kB)\n","\u001b[K     |████████████████████████████████| 191 kB 74.2 MB/s \n","\u001b[?25h  Downloading kfac-0.2.0-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 74.1 MB/s \n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->tensor2tensor) (1.2.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tensor2tensor) (2.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (5.4.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.6.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (21.4.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.1.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.1.6)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.3.4)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->tensor2tensor) (3.7.0)\n","Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gan->tensor2tensor) (0.12.0)\n","Building wheels for collected packages: bz2file\n","  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6882 sha256=85972af67e47372efaeb64dcab8c71925c5bf5b17b3bafcb0e8d5e9d7408f95a\n","  Stored in directory: /root/.cache/pip/wheels/85/ce/8d/b5f76b602b16a8a39f2ded74189cf5f09fc4a87bea16c54a8b\n","Successfully built bz2file\n","Installing collected packages: zope.interface, zope.event, tensorflow-probability, tf-slim, tensorflow-gan, tensorflow-addons, pypng, mesh-tensorflow, kfac, gunicorn, gevent, bz2file, tensor2tensor\n","  Attempting uninstall: tensorflow-probability\n","    Found existing installation: tensorflow-probability 0.15.0\n","    Uninstalling tensorflow-probability-0.15.0:\n","      Successfully uninstalled tensorflow-probability-0.15.0\n","Successfully installed bz2file-0.98 gevent-21.12.0 gunicorn-20.1.0 kfac-0.2.0 mesh-tensorflow-0.1.19 pypng-0.0.21 tensor2tensor-1.15.7 tensorflow-addons-0.15.0 tensorflow-gan-2.1.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.4.0\n","Collecting note_seq\n","  Downloading note_seq-0.0.3-py3-none-any.whl (210 kB)\n","\u001b[K     |████████████████████████████████| 210 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from note_seq) (1.0.0)\n","Requirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from note_seq) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from note_seq) (1.19.5)\n","Requirement already satisfied: bokeh>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from note_seq) (2.3.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from note_seq) (3.17.3)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from note_seq) (1.4.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from note_seq) (21.4.0)\n","Collecting pretty-midi>=0.2.6\n","  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from note_seq) (5.5.0)\n","Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from note_seq) (1.3.5)\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: librosa>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from note_seq) (0.8.1)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (3.13)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (3.10.0.2)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (21.3)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (5.1.1)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (7.1.2)\n","Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (2.11.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note_seq) (2.8.2)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from intervaltree>=2.1.0->note_seq) (2.4.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=0.12.0->note_seq) (2.0.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (1.6.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (2.1.9)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (4.4.2)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (0.10.3.post1)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (1.1.0)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (0.51.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (0.2.2)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->note_seq) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.2->note_seq) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.2->note_seq) (0.34.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=0.12.0->note_seq) (3.0.7)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->note_seq) (2018.9)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.2->note_seq) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.2->note_seq) (2.23.0)\n","Collecting mido>=1.1.16\n","  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.6->note_seq) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (1.24.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.2->note_seq) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.6.2->note_seq) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.2->note_seq) (2.21)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->note_seq) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->note_seq) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->note_seq) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->note_seq) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->note_seq) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->note_seq) (1.0.18)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->note_seq) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->note_seq) (0.7.0)\n","Building wheels for collected packages: pretty-midi\n","  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591955 sha256=428b59b23c52fd66702d25c69dc957de83c80c9a1ecdd2dbee74c04fc57b21ea\n","  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n","Successfully built pretty-midi\n","Installing collected packages: mido, pydub, pretty-midi, note-seq\n","Successfully installed mido-1.2.10 note-seq-0.0.3 pretty-midi-0.2.9 pydub-0.25.1\n"]}],"source":["#@title Initial Imports\n","import glob\n","\n","BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n","\n","print('Installing dependencies...')\n","!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","!pip install -q pyfluidsynth\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","# This is only needed for the hosted Colab environment.\n","import ctypes.util\n","orig_ctypes_util_find_library = ctypes.util.find_library\n","def proxy_find_library(lib):\n","  if lib == 'fluidsynth':\n","    return 'libfluidsynth.so.1'\n","  else:\n","    return orig_ctypes_util_find_library(lib)\n","ctypes.util.find_library = proxy_find_library\n","\n","!pip install tensor2tensor\n","!pip install note_seq"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CV4xm3PIUSsY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644240292311,"user_tz":420,"elapsed":19036,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"f4c3ceb1-99ea-40e2-b8e8-b3c94bd86e2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/drive/MyDrive/University%20of%20Alberta/Thesis/Code/Magenta/magenta\n","Installing collected packages: magenta\n","  Running setup.py develop for magenta\n","Successfully installed magenta\n"]}],"source":["!pip install --upgrade --no-deps --force-reinstall -e ."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16207,"status":"ok","timestamp":1644240308501,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"PfRDVhNs3UFx","outputId":"cf919ade-8236-4eb3-de78-9b71da92ec66","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Importing libraries and defining some helper functions...\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Done\n"]}],"source":["#@title Imports and Helpers\n","# #@title Setup Environment\n","# #@test {\"output\": \"ignore\"}\n","\n","# import glob\n","\n","# BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n","\n","# print('Installing dependencies...')\n","# !apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","# !pip install -q pyfluidsynth\n","# # !pip install -qU magenta\n","# !pip install -e .\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","# This is only needed for the hosted Colab environment.\n","# import ctypes.util\n","# orig_ctypes_util_find_library = ctypes.util.find_library\n","# def proxy_find_library(lib):\n","#   if lib == 'fluidsynth':\n","#     return 'libfluidsynth.so.1'\n","#   else:\n","#     return orig_ctypes_util_find_library(lib)\n","# ctypes.util.find_library = proxy_find_library\n","\n","\n","print('Importing libraries and defining some helper functions...')\n","from google.colab import files\n","import magenta.music as mm\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel\n","import numpy as np\n","import os\n","import tensorflow.compat.v1 as tf\n","\n","tf.disable_v2_behavior()\n","# tf.enable_eager_execution()\n","\n","# Necessary until pyfluidsynth is updated (>1.2.5).\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","def play(note_sequence):\n","  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n","\n","def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","                assert_same_length=True, temperature=0.5,\n","                individual_duration=4.0):\n","  \"\"\"Interpolates between a start and end sequence.\"\"\"\n","  note_sequences = model.interpolate(\n","      start_seq, end_seq,num_steps=num_steps, length=max_length,\n","      temperature=temperature,\n","      assert_same_length=assert_same_length)\n","\n","  print('Start Seq Reconstruction')\n","  play(note_sequences[0])\n","  print('End Seq Reconstruction')\n","  play(note_sequences[-1])\n","  print('Mean Sequence')\n","  play(note_sequences[num_steps // 2])\n","  print('Start -> End Interpolation')\n","  interp_seq = mm.sequences_lib.concatenate_sequences(\n","      note_sequences, [individual_duration] * len(note_sequences))\n","  play(interp_seq)\n","  mm.plot_sequence(interp_seq)\n","  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n","\n","def download(note_sequence, filename):\n","  mm.sequence_proto_to_midi_file(note_sequence, filename)\n","  files.download(filename)\n","\n","print('Done')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"09ohU4wczID4","executionInfo":{"status":"ok","timestamp":1644240308502,"user_tz":420,"elapsed":8,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"outputs":[],"source":["import datetime\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"moLOftFqBS-0"},"source":["# 2-Bar Melody Model\n","\n","The pre-trained model consists of a single-layer bidirectional LSTM encoder with 2048 nodes in each direction, a 3-layer LSTM decoder with 2048 nodes in each layer, and Z with 512 dimensions. The model was given 0 free bits, and had its beta valued annealed at an exponential rate of 0.99999 from 0 to 0.43 over 200k steps. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. The final accuracy is 0.95 and KL divergence is 58 bits."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11266,"status":"ok","timestamp":1644240319761,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"2XCPjwd6BVtm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a286865-add9-4f47-f11f-b8fc47a8ef6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'mel_mode': 'skyline1'}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/base_model.py:206: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt\n"]}],"source":["#@title Load the pre-trained model.\n","mel_2bar_config_sky1 = configs.CONFIG_MAP['cat-mel_2bar_big_sky1']\n","mel_2bar_config_sky1.data_converter._min_unique_pitches = 1\n","mel_2bar_base = TrainedModel(mel_2bar_config_sky1, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"]},{"cell_type":"markdown","metadata":{"id":"wM6gOe6X3hWB"},"source":["## Generate Samples"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1644240319763,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"RwXUA74cNkh0"},"outputs":[],"source":["# #@title Generate 4 samples from the prior.\n","# temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n","# mel_2_samples = mel_2bar.sample(n=4, length=32, temperature=temperature)\n","# for ns in mel_2_samples:\n","#   play(ns)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MLg9dQ2D1Xpu","executionInfo":{"status":"ok","timestamp":1644240319765,"user_tz":420,"elapsed":22,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"outputs":[],"source":["# #@title Optionally download samples.\n","# for i, ns in enumerate(mel_2_samples):\n","#   download(ns, 'mel_2bar_sample_%d.mid' % i)"]},{"cell_type":"code","source":["!python magenta/models/music_vae/music_vae_train_modified.py \\\n","--config=cat-mel_2bar_big_sky1 \\\n","--run_dir=./data/tmp/Persian_problematic/revised_sky1 \\\n","--mode=eval \\\n","--examples_path=./data/tfrecord/Persian/persian_revised.tfrecord \\\n","--log=DEBUG \\\n","--hparams=batch_size=1 \\\n","--cache_dataset=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOfj29iZPKCb","executionInfo":{"status":"ok","timestamp":1644240330077,"user_tz":420,"elapsed":10333,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"dc74e521-bd25-4509-f2d5-b6d1faa16b8d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","INFO:tensorflow:Counting examples in ./data/tfrecord/Persian/persian_revised.tfrecord.\n","I0207 13:25:25.371279 140521708918656 data.py:1695] Counting examples in ./data/tfrecord/Persian/persian_revised.tfrecord.\n","WARNING:tensorflow:From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/data.py:1696: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","W0207 13:25:25.371661 140521708918656 deprecation.py:347] From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/data.py:1696: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n","unique pitches 7\n","unique pitches 8\n","-------------\n","\n","-------------\n","\n","unique pitches 9\n","unique pitches 9\n","unique pitches 7\n","unique pitches 9\n","unique pitches 9\n","-------------\n","\n","-------------\n","\n","unique pitches 10\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 9\n","-------------\n","\n","-------------\n","\n","unique pitches 4\n","unique pitches 7\n","unique pitches 7\n","unique pitches 7\n","unique pitches 7\n","-------------\n","\n","-------------\n","\n","unique pitches 6\n","unique pitches 8\n","-------------\n","\n","-------------\n","\n","unique pitches 7\n","-------------\n","\n","-------------\n","\n","unique pitches 6\n","-------------\n","\n","-------------\n","\n","unique pitches 3\n","-------------\n","\n","-------------\n","\n","unique pitches 5\n","-------------\n","\n","-------------\n","\n","INFO:tensorflow:Total examples: 45\n","I0207 13:25:25.982389 140521708918656 data.py:1713] Total examples: 45\n","=======================================\n","Batch size =  1\n","num_batches =  45\n","=======================================\n","2022-02-07 13:25:27.037526: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'mel_mode': 'skyline1'}\n","I0207 13:25:27.068363 140521708918656 base_model.py:153] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n","{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'mel_mode': 'skyline1'}\n","INFO:tensorflow:\n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","I0207 13:25:27.073871 140521708918656 lstm_models.py:79] \n","Encoder Cells (bidirectional):\n","  units: [2048]\n","\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W0207 13:25:27.113667 140521708918656 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W0207 13:25:27.129512 140521708918656 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:\n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","I0207 13:25:27.130178 140521708918656 lstm_models.py:225] \n","Decoder Cells:\n","  units: [2048, 2048, 2048]\n","\n","WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","W0207 13:25:27.130375 140521708918656 lstm_utils.py:139] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n","WARNING:tensorflow:From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0207 13:25:27.130637 140521708918656 deprecation.py:347] From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","W0207 13:25:27.182673 140521708918656 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Persian/persian_revised.tfrecord\n","I0207 13:25:27.183512 140521708918656 data.py:1825] Reading examples from file: ./data/tfrecord/Persian/persian_revised.tfrecord\n","DEBUG:tensorflow:next element\n","I0207 13:25:27.432916 140521708918656 music_vae_train_modified.py:117] next element\n","WARNING:tensorflow:From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","W0207 13:25:27.443869 140521708918656 deprecation.py:347] From /content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W0207 13:25:27.444220 140521708918656 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  initializer=tf.constant_initializer(0.0))\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/base_model.py:206: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","W0207 13:25:27.836204 140521708918656 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not call `graph_parents`.\n","/content/drive/MyDrive/University of Alberta/Thesis/Code/Magenta/magenta/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  name=name),\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0207 13:25:28.193640 140521708918656 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","INFO:tensorflow:Starting evaluation at 2022-02-07T13:25:28\n","I0207 13:25:28.312571 140521708918656 evaluation.py:255] Starting evaluation at 2022-02-07T13:25:28\n","INFO:tensorflow:Graph was finalized.\n","I0207 13:25:28.391816 140521708918656 monitored_session.py:247] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001\n","I0207 13:25:28.396592 140521708918656 saver.py:1399] Restoring parameters from /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001\n","2022-02-07 13:25:28.733980: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","2022-02-07 13:25:28.735942: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","2022-02-07 13:25:28.736044: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at save_restore_tensor.cc:182 : DATA_LOSS: Unable to open table file /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1380, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1364, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1458, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.DataLossError: 2 root error(s) found.\n","  (0) DATA_LOSS: Unable to open table file /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","\t [[{{node save/RestoreV2}}]]\n","\t [[save/RestoreV2/_19]]\n","  (1) DATA_LOSS: Unable to open table file /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","\t [[{{node save/RestoreV2}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 368, in <module>\n","    console_entry_point()\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 364, in console_entry_point\n","    tf.app.run(main)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 359, in main\n","    run(configs.CONFIG_MAP)\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 353, in run\n","    master=FLAGS.master)\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 260, in evaluate\n","    hooks=hooks)\n","  File \"/usr/local/lib/python3.7/dist-packages/tf_slim/evaluation.py\", line 234, in evaluate_once\n","    config=session_config)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/evaluation.py\", line 269, in _evaluate_once\n","    session_creator=session_creator, hooks=hooks) as session:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1062, in __init__\n","    stop_grace_period_secs=stop_grace_period_secs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 761, in __init__\n","    self._sess = _RecoverableSession(self._coordinated_creator)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1267, in __init__\n","    _WrappedSession.__init__(self, self._create_session())\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1272, in _create_session\n","    return self._sess_creator.create_session()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 914, in create_session\n","    self.tf_sess = self._session_creator.create_session()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 681, in create_session\n","    init_fn=self._scaffold.init_fn)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/session_manager.py\", line 321, in prepare_session\n","    config=config)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/session_manager.py\", line 234, in _restore_checkpoint\n","    sess, saver, checkpoint_filename_with_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/session_manager.py\", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers\n","    saver.restore(sess, path)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 1405, in restore\n","    {self.saver_def.filename_tensor_name: save_path})\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 971, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1194, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1374, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1399, in _do_call\n","    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n","tensorflow.python.framework.errors_impl.DataLossError: 2 root error(s) found.\n","  (0) DATA_LOSS: Unable to open table file /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","\t [[node save/RestoreV2\n"," (defined at /usr/local/lib/python3.7/dist-packages/tf_slim/evaluation.py:234)\n","]]\n","\t [[save/RestoreV2/_19]]\n","  (1) DATA_LOSS: Unable to open table file /content/drive/MyDrive/Magenta/magenta/data/checkpoints/cat-mel_2bar_big.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n","\t [[node save/RestoreV2\n"," (defined at /usr/local/lib/python3.7/dist-packages/tf_slim/evaluation.py:234)\n","]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Errors may have originated from an input operation.\n","Input Source operations connected to node save/RestoreV2:\n","In[0] save/Const:\t\n","In[1] save/RestoreV2/tensor_names:\t\n","In[2] save/RestoreV2/shape_and_slices:\n","\n","Operation defined at: (most recent call last)\n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 368, in <module>\n",">>>     console_entry_point()\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 364, in console_entry_point\n",">>>     tf.app.run(main)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",">>>     _run_main(main, args)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",">>>     sys.exit(main(argv))\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 359, in main\n",">>>     run(configs.CONFIG_MAP)\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 353, in run\n",">>>     master=FLAGS.master)\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 260, in evaluate\n",">>>     hooks=hooks)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/tf_slim/evaluation.py\", line 234, in evaluate_once\n",">>>     config=session_config)\n",">>> \n","\n","Input Source operations connected to node save/RestoreV2:\n","In[0] save/Const:\t\n","In[1] save/RestoreV2/tensor_names:\t\n","In[2] save/RestoreV2/shape_and_slices:\n","\n","Operation defined at: (most recent call last)\n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 368, in <module>\n",">>>     console_entry_point()\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 364, in console_entry_point\n",">>>     tf.app.run(main)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",">>>     _run_main(main, args)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",">>>     sys.exit(main(argv))\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 359, in main\n",">>>     run(configs.CONFIG_MAP)\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 353, in run\n",">>>     master=FLAGS.master)\n",">>> \n",">>>   File \"magenta/models/music_vae/music_vae_train_modified.py\", line 260, in evaluate\n",">>>     hooks=hooks)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/tf_slim/evaluation.py\", line 234, in evaluate_once\n",">>>     config=session_config)\n",">>> \n","\n","Original stack trace for 'save/RestoreV2':\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 368, in <module>\n","    console_entry_point()\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 364, in console_entry_point\n","    tf.app.run(main)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 359, in main\n","    run(configs.CONFIG_MAP)\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 353, in run\n","    master=FLAGS.master)\n","  File \"magenta/models/music_vae/music_vae_train_modified.py\", line 260, in evaluate\n","    hooks=hooks)\n","  File \"/usr/local/lib/python3.7/dist-packages/tf_slim/evaluation.py\", line 234, in evaluate_once\n","    config=session_config)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/evaluation.py\", line 269, in _evaluate_once\n","    session_creator=session_creator, hooks=hooks) as session:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1062, in __init__\n","    stop_grace_period_secs=stop_grace_period_secs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 761, in __init__\n","    self._sess = _RecoverableSession(self._coordinated_creator)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1267, in __init__\n","    _WrappedSession.__init__(self, self._create_session())\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1272, in _create_session\n","    return self._sess_creator.create_session()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 914, in create_session\n","    self.tf_sess = self._session_creator.create_session()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 672, in create_session\n","    self._scaffold.finalize()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 236, in finalize\n","    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 625, in _get_saver_or_default\n","    saver = Saver(sharded=True, allow_empty=True)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 923, in __init__\n","    self.build()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 935, in build\n","    self._build(self._filename, build_save=True, build_restore=True)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 973, in _build\n","    build_restore=build_restore)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 528, in _build_internal\n","    restore_sequentially, reshape)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 407, in _AddShardedRestoreOps\n","    name=\"restore_shard\"))\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\n","    restore_sequentially)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\", line 601, in bulk_restore\n","    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1504, in restore_v2\n","    name=name)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 746, in _apply_op_helper\n","    attrs=attr_protos, op_def=op_def)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3705, in _create_op_internal\n","    op_def=op_def)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n","    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"9-bT0ulxO-lX"},"source":["# Data Setup "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"_ndFE5GYWhfb","executionInfo":{"status":"ok","timestamp":1644238146213,"user_tz":420,"elapsed":175,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"outputs":[],"source":["tf.enable_eager_execution()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PK8ify-aPQv3"},"outputs":[],"source":["from magenta.models.music_vae import data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1644237090847,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"tm_EnovSJzTA","outputId":"61d56fff-2ead-4a3b-b7df-9827107c98a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fly_me_to_the_Moon.tfrecord  Scarborough_Fair.tfrecord\tTake_on_me.tfrecord\n"]}],"source":["!ls ./data/tfrecord/melody/"]},{"cell_type":"code","source":["data_path = './data/tfrecord/Bo_Burnham_eval.tfrecord'\n","tf_file_reader = tf.data.TFRecordDataset\n","file_reader = tf.python_io.tf_record_iterator\n","mel_2bar_config_base = configs.CONFIG_MAP['cat-mel_2bar_big']\n","mel_2bar_config_sky1 = configs.CONFIG_MAP['cat-mel_2bar_big_sky1']"],"metadata":{"id":"hPwMHVYzCDzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXSzZcOURO2Q"},"outputs":[],"source":["mel_2bar_config_base = configs.update_config(mel_2bar_config_base, dict(eval_examples_path=data_path))\n","mel_2bar_config_sky1 = configs.update_config(mel_2bar_config_sky1, dict(eval_examples_path=data_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHvrCOmUT_mA"},"outputs":[],"source":["mel_2bar_config_base.hparams.batch_size = 1\n","mel_2bar_config_base.data_converter._min_unique_pitches = 1\n","\n","mel_2bar_config_sky1.hparams.batch_size = 1\n","mel_2bar_config_sky1.data_converter._min_unique_pitches = 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1110,"status":"ok","timestamp":1644237091928,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"bMGRDM-8QKgw","outputId":"d845de74-10de-46a1-8f42-3b5a50835813"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n","INFO:tensorflow:Reading examples from file: ./data/tfrecord/Bo_Burnham_eval.tfrecord\n"]}],"source":["dataset_base = data.get_dataset(\n","    mel_2bar_config_base,\n","    tf_file_reader=tf_file_reader,\n","    is_training=False,\n","    cache_dataset=False)\n","\n","dataset_sky1 = data.get_dataset(\n","    mel_2bar_config_sky1,\n","    tf_file_reader=tf_file_reader,\n","    is_training=False,\n","    cache_dataset=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_w2hY2uTTH8d"},"outputs":[],"source":["dataset_base = dataset_base.take(-1)\n","dataset_sky1 = dataset_sky1.take(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1644237091930,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"q8qegDjNbFAo","outputId":"766df94b-8f22-4343-f81f-d2eb03fe5900"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset shapes: ((1, ?, 90), (1, ?, 90), (1, ?, 0), (1,)), types: (tf.bool, tf.bool, tf.bool, tf.int32)>"]},"metadata":{},"execution_count":21}],"source":["dataset_base"]},{"cell_type":"code","source":["dataset_sky1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DekbKa4pEC-1","executionInfo":{"status":"ok","timestamp":1644237091931,"user_tz":420,"elapsed":12,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"c7979d5e-1f05-41a9-b0a0-ff6a0400f908"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset shapes: ((1, ?, 90), (1, ?, 90), (1, ?, 0), (1,)), types: (tf.bool, tf.bool, tf.bool, tf.int32)>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9Cm_GLTURip","executionInfo":{"status":"ok","timestamp":1644237093722,"user_tz":420,"elapsed":1799,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"db0e06b5-7f30-4654-d961-40b9364a1054"},"outputs":[{"output_type":"stream","name":"stdout","text":["unique pitches 4\n","unique pitches 2\n","unique pitches 4\n","unique pitches 6\n","unique pitches 6\n","unique pitches 7\n","unique pitches 7\n","unique pitches 6\n","unique pitches 1\n","unique pitches 6\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 2\n","unique pitches 2\n","unique pitches 2\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 7\n","unique pitches 7\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 6\n","unique pitches 6\n","unique pitches 2\n","unique pitches 4\n","unique pitches 1\n","unique pitches 1\n","unique pitches 3\n","unique pitches 2\n","unique pitches 1\n","unique pitches 2\n","unique pitches 1\n","unique pitches 2\n","unique pitches 1\n","unique pitches 2\n","unique pitches 2\n","unique pitches 2\n","unique pitches 6\n","unique pitches 2\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n","unique pitches 1\n"]}],"source":["batch_size_base = mel_2bar_config_base.hparams.batch_size\n","iterator_base = tf.data.make_one_shot_iterator(dataset_base)\n","input_seqs_base, output_seqs_base, control_seqs_base, sequence_lengths_base = [], [], [], []\n","\n","for i, o, c, sl in iterator_base:\n","  input_seqs_base.append(mel_2bar_config_base.data_converter.from_tensors(i)[0])\n","  # input_seqs.append(i)\n","  sequence_lengths_base.append(sl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rM2Y6m_62bvv","executionInfo":{"status":"ok","timestamp":1644237093725,"user_tz":420,"elapsed":45,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a94cdf5d-e9dc-40d3-948c-90fe755bf1c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["unique pitchesunique pitches 7\n","-------------\n","\n","-------------\n","\n"," 6\n","unique pitches 6\n","unique pitches 4\n","unique pitches 3\n","-------------\n","\n","-------------\n","\n","unique pitchesunique pitches 6\n","-------------\n","\n","-------------\n","\n"," 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","-------------\n","\n","-------------\n","\n","unique pitches 7\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","-------------\n","\n","-------------\n","\n","unique pitches 7\n","-------------\n","\n","-------------\n","\n","unique pitches 5\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 4\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n","unique pitches 7\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 1\n","-------------\n","\n","-------------\n","\n","unique pitches 2\n","-------------\n","\n","-------------\n","\n"]}],"source":["batch_size_sky1 = mel_2bar_config_sky1.hparams.batch_size\n","iterator_sky1 = tf.data.make_one_shot_iterator(dataset_sky1)\n","input_seqs_sky1, output_seqs_sky1, control_seqs_sky1, sequence_lengths_sky1 = [], [], [], []\n","\n","for i, o, c, sl in iterator_sky1:\n","  input_seqs_sky1.append(mel_2bar_config_sky1.data_converter.from_tensors(i)[0])\n","  # input_seqs.append(i)\n","  sequence_lengths_sky1.append(sl)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1644237093727,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"},"user_tz":420},"id":"mtBeL4sy75Cv","outputId":"e918f41b-a12a-4066-9e04-9bb0cf72f9f6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":25}],"source":["len(input_seqs_base)"]},{"cell_type":"code","source":["len(input_seqs_sky1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKVYVe7pFxiU","executionInfo":{"status":"ok","timestamp":1644237093731,"user_tz":420,"elapsed":40,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}},"outputId":"d8a56e36-3c2c-477a-c963-0c0c5e56240b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# len(input_seqs_sky1[5].notes)"],"metadata":{"id":"mz4WkrMgALPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from note_seq import Melody, sequences_lib, events_lib"],"metadata":{"id":"LATlEzu0IbLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mel = Melody()\n","# target = input_seqs_base[7]"],"metadata":{"id":"fTAC72hTIyf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target_quantized = sequences_lib.quantize_note_sequence(target, 4)"],"metadata":{"id":"RL3AoUVST7mP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"gcEKwRO_iFwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# play(target_quantized)"],"metadata":{"id":"8OzfLUDCh9Dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target_quantized"],"metadata":{"id":"f4L6lyR2hPgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# steps_per_bar_float = sequences_lib.steps_per_bar_in_quantized_sequence(target_quantized)\n","# if steps_per_bar_float % 1 != 0:\n","#       raise events_lib.NonIntegerStepsPerBarError(\n","#           'There are %f timesteps per bar. Time signature: %d/%d' %\n","#           (steps_per_bar_float, target.time_signatures[0].numerator,\n","#            target.time_signatures[0].denominator))\n","# mel._steps_per_bar = steps_per_bar = int(steps_per_bar_float)\n","# mel._steps_per_quarter = (target_quantized.quantization_info.steps_per_quarter)\n","\n","# notes = target_quantized.notes\n"],"metadata":{"id":"0kJyVh7sTB0b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# search_start_step = 0\n","# melody_start_step = 0"],"metadata":{"id":"IQYr9we6g3EE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for note in notes:\n","#   start_index = note.quantized_start_step - melody_start_step\n","#   end_index = note.quantized_end_step - melody_start_step\n","#   mel._add_note(note.pitch, start_index, end_index)\n","      "],"metadata":{"id":"pguM6Ff3habM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mel._events"],"metadata":{"id":"rM36UHophxhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hist = mel.get_note_histogram()"],"metadata":{"id":"Px6M-g1aigmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwFoqWt4t41k"},"outputs":[],"source":["# input_seqs_new = list()\n","# for i in input_seqs:\n","#   # try:\n","#   #   a, b, c = mel_2bar.encode([i])\n","#   # except:\n","#   #   print(\"invalid\")\n","#   # else:\n","#     input_seqs_new.append(i)"]},{"cell_type":"markdown","metadata":{"id":"A1hy_Jrf8CVK"},"source":["# Reconstruction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SobeqCss8IqC"},"outputs":[],"source":["# # plain model\n","# z1, mu1, sigma1 = mel_2bar.encode(input_seqs_new)\n","# z1 = [z1[i] for i in range(z1.shape[0])]\n","# output_seqs1 = mel_2bar.decode(z1, length=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5hleuQH-SQI"},"outputs":[],"source":["# # fine-tuned model\n","# z2, mu2, sigma2 = mel_2bar_finetune.encode(input_seqs_new)\n","# z2 = [z2[i] for i in range(z2.shape[0])]\n","# output_seqs2 = mel_2bar_finetune.decode(z2, length=32)"]},{"cell_type":"markdown","metadata":{"id":"oIrM_m2n_xQs"},"source":["# Comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ae2cAbN-_7uN","outputId":"22173b2e-11b2-45a0-a982-1c8e5152b98d","executionInfo":{"status":"ok","timestamp":1644237122054,"user_tz":420,"elapsed":28354,"user":{"displayName":"Anahita Doosti Sanjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuC5ydWhsFH_bKze2iVn93Z5BW8mlDDwhN12E6vg=s64","userId":"11525648660123849199"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Base sample 1: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_1\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 1: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_2\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 2: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_3\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 2: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_4\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 3: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_5\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 3: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_6\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 4: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_7\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 4: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_8\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 5: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_9\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 5: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_10\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 6: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_11\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 6: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_12\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 7: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_13\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 7: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_14\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 8: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_15\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 8: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_16\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 9: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_17\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 9: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_18\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 10: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_19\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 10: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_20\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 11: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_21\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 11: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_22\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 12: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_23\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 12: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_24\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 13: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_25\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 13: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_26\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 14: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_27\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 14: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_28\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n","Base sample 15: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_29\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Sky1 sample 15: \n"]},{"output_type":"display_data","data":{"text/html":["<div id=\"id_30\"> </div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------\n"]}],"source":["for i in range(max(len(input_seqs_base), len(input_seqs_sky1))):\n","  if i in range(len(input_seqs_base)):\n","    print(\"Base sample {}: \".format(i+1))\n","    play(input_seqs_base[i])\n","  if i in range(len(input_seqs_sky1)):\n","    print(\"Sky1 sample {}: \".format(i+1))\n","    play(input_seqs_sky1[i])\n","  print(\"----------------------------------\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["hYaJ6dvF0v7g"],"name":"Persian_reconstruction_sky1.ipynb","provenance":[{"file_id":"https://github.com/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb","timestamp":1631852135633}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}